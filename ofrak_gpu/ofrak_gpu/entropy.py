# Generated by Futhark 0.25.17.
# Compiled with GHC 9.8.2.
import sys
import numpy as np
import ctypes as ct

# Stub code for OpenCL setup.

import pyopencl as cl
import numpy as np
import sys

if cl.version.VERSION < (2015, 2):
    raise Exception(
        "Futhark requires at least PyOpenCL version 2015.2.  Installed version is %s."
        % cl.version.VERSION_TEXT
    )

TR_BLOCK_DIM = 16
TR_TILE_DIM = TR_BLOCK_DIM * 2
TR_ELEMS_PER_THREAD = 8


def parse_preferred_device(s):
    pref_num = 0
    if len(s) > 1 and s[0] == "#":
        i = 1
        while i < len(s):
            if not s[i].isdigit():
                break
            else:
                pref_num = pref_num * 10 + int(s[i])
            i += 1
        while i < len(s) and s[i].isspace():
            i += 1
        return (s[i:], pref_num)
    else:
        return (s, 0)


def get_prefered_context(interactive=False, platform_pref=None, device_pref=None):
    if device_pref != None:
        (device_pref, device_num) = parse_preferred_device(device_pref)
    else:
        device_num = 0

    if interactive:
        return cl.create_some_context(interactive=True)

    def blacklisted(p, d):
        return (
            platform_pref == None
            and device_pref == None
            and p.name == "Apple"
            and d.name.find("Intel(R) Core(TM)") >= 0
        )

    def platform_ok(p):
        return not platform_pref or p.name.find(platform_pref) >= 0

    def device_ok(d):
        return not device_pref or d.name.find(device_pref) >= 0

    device_matches = 0

    for p in cl.get_platforms():
        if not platform_ok(p):
            continue
        for d in p.get_devices():
            if blacklisted(p, d) or not device_ok(d):
                continue
            if device_matches == device_num:
                return cl.Context(devices=[d])
            else:
                device_matches += 1
    raise Exception("No OpenCL platform and device matching constraints found.")


def param_assignment(s):
    name, value = s.split("=")
    return (name, int(value))


def check_types(self, required_types):
    if "f64" in required_types:
        if self.device.get_info(cl.device_info.PREFERRED_VECTOR_WIDTH_DOUBLE) == 0:
            raise Exception(
                "Program uses double-precision floats, but this is not supported on chosen device: %s"
                % self.device.name
            )


def apply_size_heuristics(self, size_heuristics, sizes):
    for platform_name, device_type, size, valuef in size_heuristics:
        if (
            sizes[size] == None
            and self.platform.name.find(platform_name) >= 0
            and (self.device.type & device_type) == device_type
        ):
            sizes[size] = valuef(self.device)
    return sizes


def to_c_str_rep(x):
    if type(x) is bool or type(x) is np.bool_:
        if x:
            return "true"
        else:
            return "false"
    else:
        return str(x)


def initialise_opencl_object(
    self,
    program_src="",
    build_options=[],
    command_queue=None,
    interactive=False,
    platform_pref=None,
    device_pref=None,
    default_group_size=None,
    default_num_groups=None,
    default_tile_size=None,
    default_reg_tile_size=None,
    default_threshold=None,
    size_heuristics=[],
    required_types=[],
    all_sizes={},
    user_sizes={},
    constants=[],
):
    if command_queue is None:
        self.ctx = get_prefered_context(interactive, platform_pref, device_pref)
        self.queue = cl.CommandQueue(self.ctx)
    else:
        self.ctx = command_queue.context
        self.queue = command_queue
    self.device = self.queue.device
    self.platform = self.device.platform
    self.pool = cl.tools.MemoryPool(cl.tools.ImmediateAllocator(self.queue))
    device_type = self.device.type

    check_types(self, required_types)

    max_group_size = int(self.device.max_work_group_size)
    max_tile_size = int(np.sqrt(self.device.max_work_group_size))

    self.max_thread_block_size = max_group_size
    self.max_tile_size = max_tile_size
    self.max_threshold = 0
    self.max_grid_size = 0

    self.max_shared_memory = int(self.device.local_mem_size)

    # Futhark reserves 4 bytes of local memory for its own purposes.
    self.max_shared_memory -= 4

    # See comment in rts/c/opencl.h.
    if self.platform.name.find("NVIDIA CUDA") >= 0:
        self.max_shared_memory -= 12
    elif self.platform.name.find("AMD") >= 0:
        self.max_shared_memory -= 16

    self.max_registers = int(2**16)  # Not sure how to query for this.

    self.max_cache = self.device.get_info(cl.device_info.GLOBAL_MEM_CACHE_SIZE)

    if self.max_cache == 0:
        self.max_cache = 1024 * 1024

    self.free_list = {}

    self.global_failure = self.pool.allocate(np.int32().itemsize)
    cl.enqueue_fill_buffer(self.queue, self.global_failure, np.int32(-1), 0, np.int32().itemsize)
    self.global_failure_args = self.pool.allocate(
        np.int64().itemsize * (self.global_failure_args_max + 1)
    )
    self.failure_is_an_option = np.int32(0)

    if "default_group_size" in sizes:
        default_group_size = sizes["default_group_size"]
        del sizes["default_group_size"]

    if "default_num_groups" in sizes:
        default_num_groups = sizes["default_num_groups"]
        del sizes["default_num_groups"]

    if "default_tile_size" in sizes:
        default_tile_size = sizes["default_tile_size"]
        del sizes["default_tile_size"]

    if "default_reg_tile_size" in sizes:
        default_reg_tile_size = sizes["default_reg_tile_size"]
        del sizes["default_reg_tile_size"]

    if "default_threshold" in sizes:
        default_threshold = sizes["default_threshold"]
        del sizes["default_threshold"]

    default_group_size_set = default_group_size != None
    default_tile_size_set = default_tile_size != None
    default_sizes = apply_size_heuristics(
        self,
        size_heuristics,
        {
            "group_size": default_group_size,
            "tile_size": default_tile_size,
            "reg_tile_size": default_reg_tile_size,
            "num_groups": default_num_groups,
            "lockstep_width": None,
            "threshold": default_threshold,
        },
    )
    default_group_size = default_sizes["group_size"]
    default_num_groups = default_sizes["num_groups"]
    default_threshold = default_sizes["threshold"]
    default_tile_size = default_sizes["tile_size"]
    default_reg_tile_size = default_sizes["reg_tile_size"]
    lockstep_width = default_sizes["lockstep_width"]

    if default_group_size > max_group_size:
        if default_group_size_set:
            sys.stderr.write(
                "Note: Device limits group size to {} (down from {})\n".format(
                    max_tile_size, default_group_size
                )
            )
        default_group_size = max_group_size

    if default_tile_size > max_tile_size:
        if default_tile_size_set:
            sys.stderr.write(
                "Note: Device limits tile size to {} (down from {})\n".format(
                    max_tile_size, default_tile_size
                )
            )
        default_tile_size = max_tile_size

    for k, v in user_sizes.items():
        if k in all_sizes:
            all_sizes[k]["value"] = v
        else:
            raise Exception(
                "Unknown size: {}\nKnown sizes: {}".format(k, " ".join(all_sizes.keys()))
            )

    self.sizes = {}
    for k, v in all_sizes.items():
        if v["class"] == "thread_block_size":
            max_value = max_group_size
            default_value = default_group_size
        elif v["class"] == "grid_size":
            max_value = max_group_size  # Intentional!
            default_value = default_num_groups
        elif v["class"] == "tile_size":
            max_value = max_tile_size
            default_value = default_tile_size
        elif v["class"] == "reg_tile_size":
            max_value = None
            default_value = default_reg_tile_size
        elif v["class"].startswith("threshold"):
            max_value = None
            default_value = default_threshold
        else:
            # Bespoke sizes have no limit or default.
            max_value = None
        if v["value"] == None:
            self.sizes[k] = default_value
        elif max_value != None and v["value"] > max_value:
            sys.stderr.write(
                "Note: Device limits {} to {} (down from {}\n".format(k, max_value, v["value"])
            )
            self.sizes[k] = max_value
        else:
            self.sizes[k] = v["value"]

    # XXX: we perform only a subset of z-encoding here.  Really, the
    # compiler should provide us with the variables to which
    # parameters are mapped.
    if len(program_src) >= 0:
        build_options += [f"-DLOCKSTEP_WIDTH={lockstep_width}"]

        build_options += ["-D{}={}".format("max_thread_block_size", max_group_size)]

        build_options += [
            "-D{}={}".format(
                s.replace("z", "zz").replace(".", "zi").replace("#", "zh").replace("'", "zq"),
                v,
            )
            for (s, v) in self.sizes.items()
        ]

        build_options += [f"-D{s}={to_c_str_rep(f())}" for (s, f) in constants]

        if self.platform.name == "Oclgrind":
            build_options += ["-DEMULATE_F16"]

        build_options += [
            f"-DTR_BLOCK_DIM={TR_BLOCK_DIM}",
            f"-DTR_TILE_DIM={TR_TILE_DIM}",
            f"-DTR_ELEMS_PER_THREAD={TR_ELEMS_PER_THREAD}",
        ]

        program = cl.Program(self.ctx, program_src).build(build_options)

        self.transpose_kernels = {
            1: {
                "default": program.map_transpose_1b,
                "low_height": program.map_transpose_1b_low_height,
                "low_width": program.map_transpose_1b_low_width,
                "small": program.map_transpose_1b_small,
                "large": program.map_transpose_1b_large,
            },
            2: {
                "default": program.map_transpose_2b,
                "low_height": program.map_transpose_2b_low_height,
                "low_width": program.map_transpose_2b_low_width,
                "small": program.map_transpose_2b_small,
                "large": program.map_transpose_2b_large,
            },
            4: {
                "default": program.map_transpose_4b,
                "low_height": program.map_transpose_4b_low_height,
                "low_width": program.map_transpose_4b_low_width,
                "small": program.map_transpose_4b_small,
                "large": program.map_transpose_4b_large,
            },
            8: {
                "default": program.map_transpose_8b,
                "low_height": program.map_transpose_8b_low_height,
                "low_width": program.map_transpose_8b_low_width,
                "small": program.map_transpose_8b_small,
                "large": program.map_transpose_8b_large,
            },
        }

        self.copy_kernels = {
            1: program.lmad_copy_1b,
            2: program.lmad_copy_2b,
            4: program.lmad_copy_4b,
            8: program.lmad_copy_8b,
        }

        return program


def opencl_alloc(self, min_size, tag):
    min_size = 1 if min_size == 0 else min_size
    assert min_size > 0
    return self.pool.allocate(min_size)


def opencl_free_all(self):
    self.pool.free_held()


def sync(self):
    failure = np.empty(1, dtype=np.int32)
    cl.enqueue_copy(self.queue, failure, self.global_failure, is_blocking=True)
    self.failure_is_an_option = np.int32(0)
    if failure[0] >= 0:
        # Reset failure information.
        cl.enqueue_fill_buffer(
            self.queue,
            self.global_failure,
            np.int32(-1),
            0,
            np.int32().itemsize,
        )

        # Read failure args.
        failure_args = np.empty(self.global_failure_args_max + 1, dtype=np.int64)
        cl.enqueue_copy(
            self.queue,
            failure_args,
            self.global_failure_args,
            is_blocking=True,
        )

        raise Exception(self.failure_msgs[failure[0]].format(*failure_args))


def map_transpose_gpu2gpu(self, elem_size, dst, dst_offset, src, src_offset, k, n, m):
    kernels = self.transpose_kernels[elem_size]
    kernel = kernels["default"]
    mulx = TR_BLOCK_DIM / n
    muly = TR_BLOCK_DIM / m

    group_dims = (TR_TILE_DIM, TR_TILE_DIM // TR_ELEMS_PER_THREAD, 1)
    dims = (
        (m + TR_TILE_DIM - 1) // TR_TILE_DIM * group_dims[0],
        (n + TR_TILE_DIM - 1) // TR_TILE_DIM * group_dims[1],
        k,
    )

    k32 = np.int32(k)
    n32 = np.int32(n)
    m32 = np.int32(m)
    mulx32 = np.int32(mulx)
    muly32 = np.int32(muly)

    kernel.set_args(
        cl.LocalMemory(TR_TILE_DIM * (TR_TILE_DIM + 1) * elem_size),
        dst,
        dst_offset,
        src,
        src_offset,
        k32,
        m32,
        n32,
        mulx32,
        muly32,
        np.int32(0),
        np.int32(0),
    )
    cl.enqueue_nd_range_kernel(self.queue, kernel, dims, group_dims)


def copy_elements_gpu2gpu(
    self,
    elem_size,
    dst,
    dst_offset,
    dst_strides,
    src,
    src_offset,
    src_strides,
    shape,
):
    r = len(shape)
    if r > 8:
        raise Exception("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n")

    n = np.prod(shape)
    zero = np.int64(0)
    layout_args = [None] * (8 * 3)
    for i in range(8):
        if i < r:
            layout_args[i * 3 + 0] = shape[i]
            layout_args[i * 3 + 1] = dst_strides[i]
            layout_args[i * 3 + 2] = src_strides[i]
        else:
            layout_args[i * 3 + 0] = zero
            layout_args[i * 3 + 1] = zero
            layout_args[i * 3 + 2] = zero

    kernel = self.copy_kernels[elem_size]
    kernel.set_args(
        cl.LocalMemory(1),
        dst,
        dst_offset,
        src,
        src_offset,
        n,
        np.int32(r),
        *layout_args,
    )
    w = 256
    dims = ((n + w - 1) // w * w,)
    group_dims = (w,)
    cl.enqueue_nd_range_kernel(self.queue, kernel, dims, group_dims)


def lmad_copy_gpu2gpu(self, pt, dst, dst_offset, dst_strides, src, src_offset, src_strides, shape):
    elem_size = ct.sizeof(pt)
    nbytes = np.prod(shape) * elem_size
    if nbytes == 0:
        return None
    if lmad_memcpyable(dst_strides, src_strides, shape):
        cl.enqueue_copy(
            self.queue,
            dst,
            src,
            dst_offset=dst_offset * elem_size,
            src_offset=src_offset * elem_size,
            byte_count=nbytes,
        )
    else:
        tr = lmad_map_tr(dst_strides, src_strides, shape)
        if tr is not None:
            (k, n, m) = tr
            map_transpose_gpu2gpu(self, elem_size, dst, dst_offset, src, src_offset, k, m, n)
        else:
            copy_elements_gpu2gpu(
                self,
                elem_size,
                dst,
                dst_offset,
                dst_strides,
                src,
                src_offset,
                src_strides,
                shape,
            )


import pyopencl.array
import time

sizes = {}
synchronous = False
preferred_platform = None
build_options = []
preferred_device = None
default_threshold = None
default_group_size = None
default_num_groups = None
default_tile_size = None
default_reg_tile_size = None
fut_opencl_src = """#define FUTHARK_OPENCL
// Start of prelude.cl

#define SCALAR_FUN_ATTR static inline
#define FUTHARK_FUN_ATTR static

typedef char int8_t;
typedef short int16_t;
typedef int int32_t;
typedef long int64_t;

typedef uchar uint8_t;
typedef ushort uint16_t;
typedef uint uint32_t;
typedef ulong uint64_t;

#define get_tblock_id(d) get_group_id(d)
#define get_num_tblocks(d) get_num_groups(d)

// Clang-based OpenCL implementations need this for 'static' to work.
#ifdef cl_clang_storage_class_specifiers
#pragma OPENCL EXTENSION cl_clang_storage_class_specifiers : enable
#endif
#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable

#ifdef FUTHARK_F64_ENABLED
#pragma OPENCL EXTENSION cl_khr_fp64 : enable
#endif

#pragma OPENCL EXTENSION cl_khr_int64_base_atomics : enable
#pragma OPENCL EXTENSION cl_khr_int64_extended_atomics : enable

// NVIDIAs OpenCL does not create device-wide memory fences (see #734), so we
// use inline assembly if we detect we are on an NVIDIA GPU.
#ifdef cl_nv_pragma_unroll
static inline void mem_fence_global() {
  asm("membar.gl;");
}
#else
static inline void mem_fence_global() {
  mem_fence(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);
}
#endif
static inline void mem_fence_local() {
  mem_fence(CLK_LOCAL_MEM_FENCE);
}

static inline void barrier_local() {
  barrier(CLK_LOCAL_MEM_FENCE);
}

// Important for this to be int64_t so it has proper alignment for any type.
#define SHARED_MEM_PARAM __local uint64_t* shared_mem,
#define FUTHARK_KERNEL __kernel
#define FUTHARK_KERNEL_SIZED(a,b,c) __attribute__((reqd_work_group_size(a, b, c))) __kernel

// End of prelude.cl
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x);
SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x);

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  int32_t xb = futrts_to_bits32(x);
  int32_t yb = futrts_to_bits32(y);
  return futrts_from_bits32((xb & ~(1<<31)) | (yb & (1<<31)));
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_ldexp32(float x, int32_t y) {
  return ldexpf(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign32(float x, float y) {
  return copysignf(x, y);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x);
SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x);

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return x * pow((double)2.0, (double)y);
}

SCALAR_FUN_ATTR double futrts_copysign64(double x, double y) {
  int64_t xb = futrts_to_bits64(x);
  int64_t yb = futrts_to_bits64(y);
  return futrts_from_bits64((xb & ~(((int64_t)1)<<63)) | (yb & (((int64_t)1)<<63)));
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_ldexp64(double x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR float futrts_copysign64(double x, double y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return ldexp(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return copysign(x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_ldexp16(f16 x, int32_t y) {
  return futrts_ldexp32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_copysign16(f16 x, f16 y) {
  return futrts_copysign32((float)x, y);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.
// Start of atomics.h

SCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,
                                                         int32_t cmp, int32_t val);
SCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,
                                                        int32_t cmp, int32_t val);
SCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);
SCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x);
SCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);
SCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x);
SCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);
SCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x);
SCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);
SCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x);

SCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicExch((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_xchg_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicExch((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,
                                                         int32_t cmp, int32_t val) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicCAS((int32_t*)p, cmp, val);
#else
  return atomic_cmpxchg(p, cmp, val);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_shared(volatile __local int32_t *p,
                                                        int32_t cmp, int32_t val) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicCAS((int32_t*)p, cmp, val);
#else
  return atomic_cmpxchg(p, cmp, val);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((int32_t*)p, x);
#else
  return atomic_add(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_add_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((int32_t*)p, x);
#else
  return atomic_add(p, x);
#endif
}

SCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((float*)p, x);
#else
  union { int32_t i; float f; } old;
  union { int32_t i; float f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

SCALAR_FUN_ATTR float atomic_fadd_f32_shared(volatile __local float *p, float x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((float*)p, x);
#else
  union { int32_t i; float f; } old;
  union { int32_t i; float f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i32_shared((volatile __local int32_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

SCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((int32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_smax_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((int32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((int32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_smin_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((int32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

SCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((uint32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

SCALAR_FUN_ATTR uint32_t atomic_umax_i32_shared(volatile __local uint32_t *p, uint32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((uint32_t*)p, x);
#else
  return atomic_max(p, x);
#endif
}

SCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((uint32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

SCALAR_FUN_ATTR uint32_t atomic_umin_i32_shared(volatile __local uint32_t *p, uint32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((uint32_t*)p, x);
#else
  return atomic_min(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAnd((int32_t*)p, x);
#else
  return atomic_and(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_and_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAnd((int32_t*)p, x);
#else
  return atomic_and(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicOr((int32_t*)p, x);
#else
  return atomic_or(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_or_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicOr((int32_t*)p, x);
#else
  return atomic_or(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicXor((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int32_t atomic_xor_i32_shared(volatile __local int32_t *p, int32_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicXor((int32_t*)p, x);
#else
  return atomic_xor(p, x);
#endif
}

// Start of 64 bit atomics

#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)

SCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,
                                                         int64_t cmp, int64_t val);
SCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,
                                                        int64_t cmp, int64_t val);
SCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);
SCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x);
SCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);
SCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x);
SCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);
SCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x);

#ifdef FUTHARK_F64_ENABLED
SCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);
SCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x);
#endif

SCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicExch((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_xchg_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicExch((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,
                                                         int64_t cmp, int64_t val) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicCAS((uint64_t*)p, cmp, val);
#else
  return atom_cmpxchg(p, cmp, val);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_shared(volatile __local int64_t *p,
                                                        int64_t cmp, int64_t val) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicCAS((uint64_t*)p, cmp, val);
#else
  return atom_cmpxchg(p, cmp, val);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((uint64_t*)p, x);
#else
  return atom_add(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_add_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAdd((uint64_t*)p, x);
#else
  return atom_add(p, x);
#endif
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {
#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)
  return atomicAdd((double*)p, x);
#else
  union { int64_t i; double f; } old;
  union { int64_t i; double f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

SCALAR_FUN_ATTR double atomic_fadd_f64_shared(volatile __local double *p, double x) {
#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)
  return atomicAdd((double*)p, x);
#else
  union { int64_t i; double f; } old;
  union { int64_t i; double f; } assumed;
  old.f = *p;
  do {
    assumed.f = old.f;
    old.f = old.f + x;
    old.i = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed.i, old.i);
  } while (assumed.i != old.i);
  return old.f;
#endif
}

#endif

SCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA)
  return atomicMax((int64_t*)p, x);
#elif defined(FUTHARK_HIP)
  // Currentely missing in HIP; probably a temporary oversight.
  int64_t old = *p, assumed;
  do {
    assumed = old;
    old = smax64(old, x);
    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);
  } while (assumed != old);
  return old;
#else
  return atom_max(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_smax_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA)
  return atomicMax((int64_t*)p, x);
#elif defined(FUTHARK_HIP)
  // Currentely missing in HIP; probably a temporary oversight.
  int64_t old = *p, assumed;
  do {
    assumed = old;
    old = smax64(old, x);
    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);
  } while (assumed != old);
  return old;
#else
  return atom_max(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA)
  return atomicMin((int64_t*)p, x);
#elif defined(FUTHARK_HIP)
  // Currentely missing in HIP; probably a temporary oversight.
  int64_t old = *p, assumed;
  do {
    assumed = old;
    old = smin64(old, x);
    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);
  } while (assumed != old);
  return old;
#else
  return atom_min(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_smin_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA)
  return atomicMin((int64_t*)p, x);
#elif defined(FUTHARK_HIP)
  // Currentely missing in HIP; probably a temporary oversight.
  int64_t old = *p, assumed;
  do {
    assumed = old;
    old = smin64(old, x);
    old = atomic_cmpxchg_i64_shared((volatile __local int64_t*)p, assumed, old);
  } while (assumed != old);
  return old;
#else
  return atom_min(p, x);
#endif
}

SCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((uint64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

SCALAR_FUN_ATTR uint64_t atomic_umax_i64_shared(volatile __local uint64_t *p, uint64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMax((uint64_t*)p, x);
#else
  return atom_max(p, x);
#endif
}

SCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((uint64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

SCALAR_FUN_ATTR uint64_t atomic_umin_i64_shared(volatile __local uint64_t *p, uint64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicMin((uint64_t*)p, x);
#else
  return atom_min(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAnd((uint64_t*)p, x);
#else
  return atom_and(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_and_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicAnd((uint64_t*)p, x);
#else
  return atom_and(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicOr((uint64_t*)p, x);
#else
  return atom_or(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_or_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicOr((uint64_t*)p, x);
#else
  return atom_or(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicXor((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

SCALAR_FUN_ATTR int64_t atomic_xor_i64_shared(volatile __local int64_t *p, int64_t x) {
#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)
  return atomicXor((uint64_t*)p, x);
#else
  return atom_xor(p, x);
#endif
}

#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)

// End of atomics.h
// Start of transpose.cl

#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \
FUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\
void map_transpose_##NAME(SHARED_MEM_PARAM                              \
                          __global ELEM_TYPE *dst_mem,                  \
                          int64_t dst_offset,                           \
                          __global ELEM_TYPE *src_mem,                  \
                          int64_t src_offset,                           \
                          int32_t num_arrays,                           \
                          int32_t x_elems,                              \
                          int32_t y_elems,                              \
                          int32_t mulx,                                 \
                          int32_t muly,                                 \
                          int32_t repeat_1,                             \
                          int32_t repeat_2) {                           \
  (void)mulx; (void)muly;                                               \
  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \
  int tblock_id_0 = get_tblock_id(0);                                   \
  int global_id_0 = get_global_id(0);                                   \
  int tblock_id_1 = get_tblock_id(1);                                   \
  int global_id_1 = get_global_id(1);                                   \
  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \
    int tblock_id_2 = get_tblock_id(2);                                 \
    int global_id_2 = get_global_id(2);                                 \
    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \
      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \
      int32_t odata_offset = dst_offset + our_array_offset;             \
      int32_t idata_offset = src_offset + our_array_offset;             \
      int32_t x_index = global_id_0;                                    \
      int32_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \
      if (x_index < x_elems) {                                          \
        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \
          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \
          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \
            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \
                  get_local_id(0)] =                                    \
              src_mem[idata_offset + index_i];                          \
          }                                                             \
        }                                                               \
      }                                                                 \
      barrier_local();                                                  \
      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \
      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \
      if (x_index < y_elems) {                                          \
        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \
          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \
          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \
            dst_mem[(odata_offset + index_out)] =                       \
              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \
                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \
          }                                                             \
        }                                                               \
      }                                                                 \
      tblock_id_2 += get_num_tblocks(2);                                \
      global_id_2 += get_global_size(2);                                \
    }                                                                   \
    tblock_id_1 += get_num_tblocks(1);                                  \
    global_id_1 += get_global_size(1);                                  \
  }                                                                     \
}                                                                       \
                                                                        \
FUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \
void map_transpose_##NAME##_low_height(SHARED_MEM_PARAM                 \
                                                __global ELEM_TYPE *dst_mem, \
                                                int64_t dst_offset,     \
                                                __global ELEM_TYPE *src_mem, \
                                                int64_t src_offset,     \
                                                int32_t num_arrays,     \
                                                int32_t x_elems,        \
                                                int32_t y_elems,        \
                                                int32_t mulx,           \
                                                int32_t muly,           \
                                                int32_t repeat_1,       \
                                                int32_t repeat_2) {     \
  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \
  int tblock_id_0 = get_tblock_id(0);                                   \
  int global_id_0 = get_global_id(0);                                   \
  int tblock_id_1 = get_tblock_id(1);                                   \
  int global_id_1 = get_global_id(1);                                   \
  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \
    int tblock_id_2 = get_tblock_id(2);                                 \
    int global_id_2 = get_global_id(2);                                 \
    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \
      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \
      int32_t odata_offset = dst_offset + our_array_offset;             \
      int32_t idata_offset = src_offset + our_array_offset;             \
      int32_t x_index =                                                 \
        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \
        get_local_id(0) +                                               \
        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \
      int32_t y_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \
      int32_t index_in = y_index * x_elems + x_index;                   \
      if (x_index < x_elems && y_index < y_elems) {                     \
        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \
          src_mem[idata_offset + index_in];                             \
      }                                                                 \
      barrier_local();                                                  \
      x_index = tblock_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;      \
      y_index =                                                         \
        tblock_id_0 * TR_BLOCK_DIM * mulx +                             \
        get_local_id(1) +                                               \
        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \
      int32_t index_out = y_index * y_elems + x_index;                  \
      if (x_index < y_elems && y_index < x_elems) {                     \
        dst_mem[odata_offset + index_out] =                             \
          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \
      }                                                                 \
      tblock_id_2 += get_num_tblocks(2);                                \
      global_id_2 += get_global_size(2);                                \
    }                                                                   \
    tblock_id_1 += get_num_tblocks(1);                                  \
    global_id_1 += get_global_size(1);                                  \
  }                                                                     \
}                                                                       \
                                                                        \
FUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \
void map_transpose_##NAME##_low_width(SHARED_MEM_PARAM                  \
                                      __global ELEM_TYPE *dst_mem,      \
                                      int64_t dst_offset,               \
                                      __global ELEM_TYPE *src_mem,      \
                                      int64_t src_offset,               \
                                      int32_t num_arrays,               \
                                      int32_t x_elems,                  \
                                      int32_t y_elems,                  \
                                      int32_t mulx,                     \
                                      int32_t muly,                     \
                                      int32_t repeat_1,                 \
                                      int32_t repeat_2) {               \
  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \
  int tblock_id_0 = get_tblock_id(0);                                   \
  int global_id_0 = get_global_id(0);                                   \
  int tblock_id_1 = get_tblock_id(1);                                   \
  int global_id_1 = get_global_id(1);                                   \
  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \
    int tblock_id_2 = get_tblock_id(2);                                 \
    int global_id_2 = get_global_id(2);                                 \
    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \
      int32_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \
      int32_t odata_offset = dst_offset + our_array_offset;             \
      int32_t idata_offset = src_offset + our_array_offset;             \
      int32_t x_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \
      int32_t y_index =                                                 \
        tblock_id_1 * TR_BLOCK_DIM * muly +                             \
        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \
      int32_t index_in = y_index * x_elems + x_index;                   \
      if (x_index < x_elems && y_index < y_elems) {                     \
        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \
          src_mem[idata_offset + index_in];                             \
      }                                                                 \
      barrier_local();                                                  \
      x_index = tblock_id_1 * TR_BLOCK_DIM * muly +                     \
        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \
      y_index = tblock_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;      \
      int32_t index_out = y_index * y_elems + x_index;                  \
      if (x_index < y_elems && y_index < x_elems) {                     \
        dst_mem[odata_offset + index_out] =                             \
          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \
      }                                                                 \
      tblock_id_2 += get_num_tblocks(2);                                \
      global_id_2 += get_num_tblocks(2) * get_local_size(2);            \
    }                                                                   \
    tblock_id_1 += get_num_tblocks(1);                                  \
    global_id_1 += get_num_tblocks(1) * get_local_size(1);              \
  }                                                                     \
}                                                                       \
                                                                        \
FUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \
void map_transpose_##NAME##_small(SHARED_MEM_PARAM                       \
                                  __global ELEM_TYPE *dst_mem,          \
                                  int64_t dst_offset,                   \
                                  __global ELEM_TYPE *src_mem,          \
                                  int64_t src_offset,                   \
                                  int32_t num_arrays,                   \
                                  int32_t x_elems,                      \
                                  int32_t y_elems,                      \
                                  int32_t mulx,                         \
                                  int32_t muly,                         \
                                  int32_t repeat_1,                     \
                                  int32_t repeat_2) {                   \
  (void)mulx; (void)muly;                                               \
  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;            \
  int tblock_id_0 = get_tblock_id(0);                                   \
  int global_id_0 = get_global_id(0);                                   \
  int tblock_id_1 = get_tblock_id(1);                                   \
  int global_id_1 = get_global_id(1);                                   \
  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \
    int tblock_id_2 = get_tblock_id(2);                                 \
    int global_id_2 = get_global_id(2);                                 \
    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \
      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \
      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \
      int32_t y_index = global_id_0%y_elems;                            \
      int32_t odata_offset = dst_offset + our_array_offset;             \
      int32_t idata_offset = src_offset + our_array_offset;             \
      int32_t index_in = y_index * x_elems + x_index;                   \
      int32_t index_out = x_index * y_elems + y_index;                  \
      if (global_id_0 < x_elems * y_elems * num_arrays) {               \
        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \
      }                                                                 \
      tblock_id_2 += get_num_tblocks(2);                                \
      global_id_2 += get_global_size(2);                                \
    }                                                                   \
    tblock_id_1 += get_num_tblocks(1);                                  \
    global_id_1 += get_global_size(1);                                  \
  }                                                                     \
}                                                                       \
                                                                        \
FUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\
void map_transpose_##NAME##_large(SHARED_MEM_PARAM                      \
                                  __global ELEM_TYPE *dst_mem,          \
                                  int64_t dst_offset,                   \
                                  __global ELEM_TYPE *src_mem,          \
                                  int64_t src_offset,                   \
                                  int64_t num_arrays,                   \
                                  int64_t x_elems,                      \
                                  int64_t y_elems,                      \
                                  int64_t mulx,                         \
                                  int64_t muly,                         \
                                  int32_t repeat_1,                     \
                                  int32_t repeat_2) {                   \
  (void)mulx; (void)muly;                                               \
  __local ELEM_TYPE* block = (__local ELEM_TYPE*)shared_mem;             \
  int tblock_id_0 = get_tblock_id(0);                                   \
  int global_id_0 = get_global_id(0);                                   \
  int tblock_id_1 = get_tblock_id(1);                                   \
  int global_id_1 = get_global_id(1);                                   \
  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \
    int tblock_id_2 = get_tblock_id(2);                                 \
    int global_id_2 = get_global_id(2);                                 \
    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \
      int64_t our_array_offset = tblock_id_2 * x_elems * y_elems;       \
      int64_t odata_offset = dst_offset + our_array_offset;             \
      int64_t idata_offset = src_offset + our_array_offset;             \
      int64_t x_index = global_id_0;                                    \
      int64_t y_index = tblock_id_1 * TR_TILE_DIM + get_local_id(1);    \
      if (x_index < x_elems) {                                          \
        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \
          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \
          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \
            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \
                  get_local_id(0)] =                                    \
              src_mem[idata_offset + index_i];                          \
          }                                                             \
        }                                                               \
      }                                                                 \
      barrier_local();                                                  \
      x_index = tblock_id_1 * TR_TILE_DIM + get_local_id(0);            \
      y_index = tblock_id_0 * TR_TILE_DIM + get_local_id(1);            \
      if (x_index < y_elems) {                                          \
        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \
          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \
          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \
            dst_mem[(odata_offset + index_out)] =                       \
              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \
                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \
          }                                                             \
        }                                                               \
      }                                                                 \
      tblock_id_2 += get_num_tblocks(2);                                \
      global_id_2 += get_global_size(2);                                \
    }                                                                   \
    tblock_id_1 += get_num_tblocks(1);                                  \
    global_id_1 += get_global_size(1);                                  \
  }                                                                     \
}                                                                       \

GEN_TRANSPOSE_KERNELS(1b, uint8_t)
GEN_TRANSPOSE_KERNELS(2b, uint16_t)
GEN_TRANSPOSE_KERNELS(4b, uint32_t)
GEN_TRANSPOSE_KERNELS(8b, uint64_t)

// End of transpose.cl
// Start of copy.cl

#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \
FUTHARK_KERNEL void lmad_copy_##NAME(SHARED_MEM_PARAM                   \
                               __global ELEM_TYPE *dst_mem,             \
                               int64_t dst_offset,                      \
                               __global ELEM_TYPE *src_mem,             \
                               int64_t src_offset,                      \
                               int64_t n,                               \
                               int r,                                   \
                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \
                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \
                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \
                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \
                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \
                               int64_t shape5, int64_t dst_stride5, int64_t src_stride5, \
                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \
                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \
  int64_t gtid = get_global_id(0);                                      \
  int64_t remainder = gtid;                                             \
                                                                        \
  if (gtid >= n) {                                                      \
    return;                                                             \
  }                                                                     \
                                                                        \
  if (r > 0) {                                                          \
    int64_t i = remainder % shape0;                                     \
    dst_offset += i * dst_stride0;                                      \
    src_offset += i * src_stride0;                                      \
    remainder /= shape0;                                                \
  }                                                                     \
  if (r > 1) {                                                          \
    int64_t i = remainder % shape1;                                     \
    dst_offset += i * dst_stride1;                                      \
    src_offset += i * src_stride1;                                      \
    remainder /= shape1;                                                \
  }                                                                     \
  if (r > 2) {                                                          \
    int64_t i = remainder % shape2;                                     \
    dst_offset += i * dst_stride2;                                      \
    src_offset += i * src_stride2;                                      \
    remainder /= shape2;                                                \
  }                                                                     \
  if (r > 3) {                                                          \
    int64_t i = remainder % shape3;                                     \
    dst_offset += i * dst_stride3;                                      \
    src_offset += i * src_stride3;                                      \
    remainder /= shape3;                                                \
  }                                                                     \
  if (r > 4) {                                                          \
    int64_t i = remainder % shape4;                                     \
    dst_offset += i * dst_stride4;                                      \
    src_offset += i * src_stride4;                                      \
    remainder /= shape4;                                                \
  }                                                                     \
  if (r > 5) {                                                          \
    int64_t i = remainder % shape5;                                     \
    dst_offset += i * dst_stride5;                                      \
    src_offset += i * src_stride5;                                      \
    remainder /= shape5;                                                \
  }                                                                     \
  if (r > 6) {                                                          \
    int64_t i = remainder % shape6;                                     \
    dst_offset += i * dst_stride6;                                      \
    src_offset += i * src_stride6;                                      \
    remainder /= shape6;                                                \
  }                                                                     \
  if (r > 7) {                                                          \
    int64_t i = remainder % shape7;                                     \
    dst_offset += i * dst_stride7;                                      \
    src_offset += i * src_stride7;                                      \
    remainder /= shape7;                                                \
  }                                                                     \
                                                                        \
  dst_mem[dst_offset] = src_mem[src_offset];                            \
}

GEN_COPY_KERNEL(1b, uint8_t)
GEN_COPY_KERNEL(2b, uint16_t)
GEN_COPY_KERNEL(4b, uint32_t)
GEN_COPY_KERNEL(8b, uint64_t)

// End of copy.cl



FUTHARK_KERNEL
void builtinzhreplicate_i32zireplicate_6861(__local uint64_t *shared_mem_aligned, int64_t num_elems_6857, int32_t val_6858, int64_t replicate_n_6860, int64_t virt_num_tblocks_6866, int64_t num_tblocks_6867, __global unsigned char *mem_6856)
{
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    int32_t replicate_ltid_6862;
    int32_t tblock_sizze_6864;
    int32_t replicate_gid_6863;
    int32_t replicate_gtid_6861;
    int32_t phys_tblock_id_6868;
    int32_t iterations_6869;
    
    replicate_ltid_6862 = get_local_id(0);
    tblock_sizze_6864 = get_local_size(0);
    replicate_gid_6863 = get_tblock_id(0);
    replicate_gtid_6861 = replicate_gid_6863 * tblock_sizze_6864 + replicate_ltid_6862;
    phys_tblock_id_6868 = get_tblock_id(0);
    iterations_6869 = sdiv_up32(sext_i64_i32(virt_num_tblocks_6866) - phys_tblock_id_6868, sext_i64_i32(num_tblocks_6867));
    for (int32_t i_6870 = 0; i_6870 < iterations_6869; i_6870++) {
        int32_t virt_tblock_id_6871;
        int64_t global_tid_6872;
        int64_t slice_6874;
        int64_t rep_i_6873;
        int64_t remnant_6875;
        
        virt_tblock_id_6871 = phys_tblock_id_6868 + i_6870 * sext_i64_i32(num_tblocks_6867);
        global_tid_6872 = sext_i32_i64(virt_tblock_id_6871) * sext_i32_i64(tblock_sizze_6864) + sext_i32_i64(replicate_ltid_6862);
        slice_6874 = num_elems_6857;
        rep_i_6873 = global_tid_6872;
        remnant_6875 = global_tid_6872 - rep_i_6873;
        if (slt64(global_tid_6872, replicate_n_6860)) {
            ((__global int32_t *) mem_6856)[rep_i_6873] = val_6858;
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
}
FUTHARK_KERNEL
void builtinzhreplicate_i64zireplicate_6785(__local uint64_t *shared_mem_aligned, int64_t num_elems_6781, int64_t val_6782, int64_t replicate_n_6784, int64_t virt_num_tblocks_6790, int64_t num_tblocks_6791, __global unsigned char *mem_6780)
{
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    int32_t replicate_ltid_6786;
    int32_t tblock_sizze_6788;
    int32_t replicate_gid_6787;
    int32_t replicate_gtid_6785;
    int32_t phys_tblock_id_6792;
    int32_t iterations_6793;
    
    replicate_ltid_6786 = get_local_id(0);
    tblock_sizze_6788 = get_local_size(0);
    replicate_gid_6787 = get_tblock_id(0);
    replicate_gtid_6785 = replicate_gid_6787 * tblock_sizze_6788 + replicate_ltid_6786;
    phys_tblock_id_6792 = get_tblock_id(0);
    iterations_6793 = sdiv_up32(sext_i64_i32(virt_num_tblocks_6790) - phys_tblock_id_6792, sext_i64_i32(num_tblocks_6791));
    for (int32_t i_6794 = 0; i_6794 < iterations_6793; i_6794++) {
        int32_t virt_tblock_id_6795;
        int64_t global_tid_6796;
        int64_t slice_6798;
        int64_t rep_i_6797;
        int64_t remnant_6799;
        
        virt_tblock_id_6795 = phys_tblock_id_6792 + i_6794 * sext_i64_i32(num_tblocks_6791);
        global_tid_6796 = sext_i32_i64(virt_tblock_id_6795) * sext_i32_i64(tblock_sizze_6788) + sext_i32_i64(replicate_ltid_6786);
        slice_6798 = num_elems_6781;
        rep_i_6797 = global_tid_6796;
        remnant_6799 = global_tid_6796 - rep_i_6797;
        if (slt64(global_tid_6796, replicate_n_6784)) {
            ((__global int64_t *) mem_6780)[rep_i_6797] = val_6782;
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
}
FUTHARK_KERNEL_SIZED(byte_histogramziseghist_global_6302_dim1, 1, 1)
void byte_histogramziseghist_global_6302(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t n_5761, int64_t num_tblocks_6297, int64_t num_subhistos_6801, int32_t chk_i_6871, int64_t hist_H_chk_6872, __global unsigned char *xs_mem_6743, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define seghist_tblock_sizze_6295 (byte_histogramziseghist_global_6302ziseghist_tblock_sizze_6295)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6874;
    int32_t tblock_sizze_6877;
    int32_t wave_sizze_6876;
    int32_t block_id_6875;
    int32_t global_tid_6873;
    int64_t phys_tid_6302;
    int32_t subhisto_ind_6878;
    int64_t num_chunks_6879;
    
    local_tid_6874 = get_local_id(0);
    tblock_sizze_6877 = get_local_size(0);
    wave_sizze_6876 = LOCKSTEP_WIDTH;
    block_id_6875 = get_tblock_id(0);
    global_tid_6873 = block_id_6875 * tblock_sizze_6877 + local_tid_6874;
    phys_tid_6302 = sext_i32_i64(global_tid_6873);
    subhisto_ind_6878 = squot32(global_tid_6873, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_6295 * num_tblocks_6297), sext_i64_i32(num_subhistos_6801)));
    num_chunks_6879 = sdiv_up64(n_5761, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_6295 * num_tblocks_6297)));
    for (int64_t chunk_i_6880 = 0; chunk_i_6880 < num_chunks_6879; chunk_i_6880++) {
        int64_t i_6881 = chunk_i_6880 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_6295 * num_tblocks_6297)) + sext_i32_i64(global_tid_6873);
        
        if (slt64(i_6881, n_5761)) {
            int64_t slice_6882;
            int64_t gtid_6301;
            int64_t remnant_6883;
            
            slice_6882 = n_5761;
            gtid_6301 = i_6881;
            remnant_6883 = i_6881 - gtid_6301;
            if (slt64(i_6881, n_5761)) {
                int8_t eta_p_6306;
                int64_t u8_res_6308;
                
                eta_p_6306 = ((__global int8_t *) xs_mem_6743)[gtid_6301];
                u8_res_6308 = zext_i8_i64(eta_p_6306);
                // save map-out results
                { }
                // perform atomic updates
                {
                    if (sle64(sext_i32_i64(chk_i_6871) * hist_H_chk_6872, u8_res_6308) && (slt64(u8_res_6308, sext_i32_i64(chk_i_6871) * hist_H_chk_6872 + hist_H_chk_6872) && (sle64((int64_t) 0, u8_res_6308) && slt64(u8_res_6308, (int64_t) 256)))) {
                        int64_t eta_p_6303;
                        int64_t eta_p_6304 = (int64_t) 1;
                        int64_t old_6884;
                        
                        old_6884 = atomic_add_i64_global(&((volatile __global int64_t *) defunc_0_map_res_subhistos_mem_6802)[sext_i32_i64(subhisto_ind_6878) * (int64_t) 256 + u8_res_6308], (int64_t) eta_p_6304);
                    }
                }
            }
        }
    }
    
  error_0:
    return;
    #undef seghist_tblock_sizze_6295
}
FUTHARK_KERNEL_SIZED(byte_histogramziseghist_local_6302_dim1, 1, 1)
void byte_histogramziseghist_local_6302(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t n_5761, int64_t num_subhistos_6801, int64_t num_tblocks_6812, int32_t hist_M_6818, int32_t chk_i_6822, int64_t num_segments_6823, int64_t hist_H_chk_6824, int64_t histo_sizze_6825, int32_t init_per_thread_6826, __global unsigned char *xs_mem_6743, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define max_tblock_sizze_6811 (byte_histogramziseghist_local_6302zimax_tblock_sizze_6811)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *subhistogram_local_mem_6840_backing_0 = &shared_mem[0];
    const int64_t subhistogram_local_mem_6840_backing_0_offset = 0 + ((int64_t) 8 * (hist_M_6818 * hist_H_chk_6824) + srem64((int64_t) 8 - srem64((int64_t) 8 * (hist_M_6818 * hist_H_chk_6824), (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6828;
    int32_t tblock_sizze_6831;
    int32_t wave_sizze_6830;
    int32_t block_id_6829;
    int32_t global_tid_6827;
    int64_t phys_tid_6302;
    int32_t phys_tblock_id_6832;
    int32_t iterations_6833;
    
    local_tid_6828 = get_local_id(0);
    tblock_sizze_6831 = get_local_size(0);
    wave_sizze_6830 = LOCKSTEP_WIDTH;
    block_id_6829 = get_tblock_id(0);
    global_tid_6827 = block_id_6829 * tblock_sizze_6831 + local_tid_6828;
    phys_tid_6302 = sext_i32_i64(global_tid_6827);
    phys_tblock_id_6832 = get_tblock_id(0);
    iterations_6833 = sdiv_up32(sext_i64_i32(num_tblocks_6812 * num_segments_6823) - phys_tblock_id_6832, sext_i64_i32(num_tblocks_6812));
    for (int32_t i_6834 = 0; i_6834 < iterations_6833; i_6834++) {
        int32_t virt_tblock_id_6835;
        int32_t flat_segment_id_6836;
        int32_t gid_in_segment_6837;
        int32_t pgtid_in_segment_6838;
        int32_t threads_per_segment_6839;
        __local unsigned char *subhistogram_local_mem_6840;
        int32_t thread_local_subhisto_i_6842;
        int64_t num_chunks_6849;
        
        virt_tblock_id_6835 = phys_tblock_id_6832 + i_6834 * sext_i64_i32(num_tblocks_6812);
        flat_segment_id_6836 = squot32(virt_tblock_id_6835, sext_i64_i32(num_tblocks_6812));
        gid_in_segment_6837 = srem32(virt_tblock_id_6835, sext_i64_i32(num_tblocks_6812));
        pgtid_in_segment_6838 = gid_in_segment_6837 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
        threads_per_segment_6839 = sext_i64_i32(num_tblocks_6812 * max_tblock_sizze_6811);
        subhistogram_local_mem_6840 = (__local unsigned char *) subhistogram_local_mem_6840_backing_0;
        thread_local_subhisto_i_6842 = srem32(local_tid_6828, hist_M_6818);
        // initialize histograms in shared memory
        {
            for (int32_t local_i_6843 = 0; local_i_6843 < init_per_thread_6826; local_i_6843++) {
                int32_t j_6844 = local_i_6843 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
                int32_t j_offset_6845 = hist_M_6818 * sext_i64_i32(histo_sizze_6825) * gid_in_segment_6837 + j_6844;
                int32_t local_subhisto_i_6846 = squot32(j_6844, sext_i64_i32(histo_sizze_6825));
                int32_t global_subhisto_i_6847 = squot32(j_offset_6845, sext_i64_i32(histo_sizze_6825));
                
                if (slt32(j_6844, hist_M_6818 * sext_i64_i32(histo_sizze_6825))) {
                    // First subhistogram is initialised from global memory; others with neutral element.
                    {
                        if (global_subhisto_i_6847 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_6801)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824) && slt64(sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824, (int64_t) 256)))) {
                            int64_t tmp_6848 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824];
                            
                            ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(local_subhisto_i_6846) * hist_H_chk_6824 + sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825)))] = tmp_6848;
                        } else {
                            ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(local_subhisto_i_6846) * hist_H_chk_6824 + sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825)))] = (int64_t) 0;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        num_chunks_6849 = sdiv_up64(n_5761, sext_i32_i64(threads_per_segment_6839));
        for (int64_t chunk_i_6850 = 0; chunk_i_6850 < num_chunks_6849; chunk_i_6850++) {
            int64_t i_6851 = chunk_i_6850 * sext_i32_i64(threads_per_segment_6839) + sext_i32_i64(pgtid_in_segment_6838);
            
            if (slt64(i_6851, n_5761)) {
                int64_t gtid_6301;
                int8_t eta_p_6306;
                int64_t u8_res_6308;
                
                gtid_6301 = i_6851;
                eta_p_6306 = ((__global int8_t *) xs_mem_6743)[gtid_6301];
                u8_res_6308 = zext_i8_i64(eta_p_6306);
                if (chk_i_6822 == 0) {
                    // save map-out results
                    { }
                }
                // perform atomic updates
                {
                    if ((sle64((int64_t) 0, u8_res_6308) && slt64(u8_res_6308, (int64_t) 256)) && (sle64(sext_i32_i64(chk_i_6822) * hist_H_chk_6824, u8_res_6308) && slt64(u8_res_6308, sext_i32_i64(chk_i_6822) * hist_H_chk_6824 + hist_H_chk_6824))) {
                        int64_t eta_p_6303;
                        int64_t eta_p_6304 = (int64_t) 1;
                        int64_t old_6852;
                        
                        old_6852 = atomic_add_i64_shared(&((volatile __local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(thread_local_subhisto_i_6842) * hist_H_chk_6824 + (u8_res_6308 - sext_i32_i64(chk_i_6822) * hist_H_chk_6824)], (int64_t) eta_p_6304);
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
        // Compact the multiple shared memory subhistograms to result in global memory
        {
            int64_t trunc_H_6853 = smin64(hist_H_chk_6824, (int64_t) 256 - sext_i32_i64(chk_i_6822) * hist_H_chk_6824);
            int32_t histo_sizze_6854 = sext_i64_i32(trunc_H_6853);
            
            for (int32_t local_i_6855 = 0; local_i_6855 < init_per_thread_6826; local_i_6855++) {
                int32_t j_6856 = local_i_6855 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
                
                if (slt32(j_6856, histo_sizze_6854)) {
                    int64_t eta_p_6303;
                    int64_t eta_p_6304;
                    
                    // Read values from subhistogram 0.
                    {
                        eta_p_6303 = ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(j_6856)];
                    }
                    // Accumulate based on values in other subhistograms.
                    {
                        for (int32_t subhisto_id_6857 = 0; subhisto_id_6857 < hist_M_6818 - 1; subhisto_id_6857++) {
                            eta_p_6304 = ((__local int64_t *) subhistogram_local_mem_6840)[(sext_i32_i64(subhisto_id_6857) + (int64_t) 1) * hist_H_chk_6824 + sext_i32_i64(j_6856)];
                            
                            int64_t defunc_0_op_res_6305 = add64(eta_p_6303, eta_p_6304);
                            
                            eta_p_6303 = defunc_0_op_res_6305;
                        }
                    }
                    // Put final bucket value in global memory.
                    {
                        ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[srem64(sext_i32_i64(virt_tblock_id_6835), num_tblocks_6812) * (int64_t) 256 + (sext_i32_i64(j_6856) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824)] = eta_p_6303;
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_2:
    return;
    #undef max_tblock_sizze_6811
}
FUTHARK_KERNEL_SIZED(byte_histogramzisegred_large_6887_dim1, 1, 1)
void byte_histogramzisegred_large_6887(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_tblocks_6297, int64_t num_subhistos_6801, int64_t blocks_per_segment_6918, int64_t q_6919, int64_t num_virtblocks_6920, int64_t threads_per_segment_6921, __global unsigned char *mem_6744, __global unsigned char *defunc_0_map_res_subhistos_mem_6802, __global unsigned char *segred_tmp_mem_6922, __global unsigned char *counters_mem_6924)
{
    #define seghist_tblock_sizze_6295 (byte_histogramzisegred_large_6887ziseghist_tblock_sizze_6295)
    #define chunk_sizze_6888 (byte_histogramzisegred_large_6887zichunk_sizze_6888)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *sync_arr_mem_6953_backing_1 = &shared_mem[0];
    const int64_t sync_arr_mem_6953_backing_1_offset = 0 + 8;
    volatile __local unsigned char *red_arr_i64_mem_6951_backing_0 = &shared_mem[sync_arr_mem_6953_backing_1_offset];
    const int64_t red_arr_i64_mem_6951_backing_0_offset = sync_arr_mem_6953_backing_1_offset + ((int64_t) 8 * seghist_tblock_sizze_6295 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_6295, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6947;
    int32_t tblock_sizze_6950;
    int32_t wave_sizze_6949;
    int32_t block_id_6948;
    int32_t global_tid_6946;
    int64_t flat_gtid_6887;
    __local unsigned char *red_arr_i64_mem_6951;
    __local unsigned char *sync_arr_mem_6953;
    int32_t phys_tblock_id_6955;
    int32_t iterations_6956;
    
    local_tid_6947 = get_local_id(0);
    tblock_sizze_6950 = get_local_size(0);
    wave_sizze_6949 = LOCKSTEP_WIDTH;
    block_id_6948 = get_tblock_id(0);
    global_tid_6946 = block_id_6948 * tblock_sizze_6950 + local_tid_6947;
    flat_gtid_6887 = sext_i32_i64(global_tid_6946);
    red_arr_i64_mem_6951 = (__local unsigned char *) red_arr_i64_mem_6951_backing_0;
    sync_arr_mem_6953 = (__local unsigned char *) sync_arr_mem_6953_backing_1;
    phys_tblock_id_6955 = get_tblock_id(0);
    iterations_6956 = sdiv_up32(sext_i64_i32(num_virtblocks_6920) - phys_tblock_id_6955, sext_i64_i32(num_tblocks_6297));
    for (int32_t i_6957 = 0; i_6957 < iterations_6956; i_6957++) {
        int32_t virt_tblock_id_6958;
        int64_t flat_segment_id_6959;
        int64_t global_tid_6960;
        int64_t slice_6961;
        int64_t bucket_id_6885;
        int64_t remnant_6962;
        int64_t subhistogram_id_6886;
        int64_t eta_p_block_res_acc_6963;
        int64_t eta_p_6303;
        int64_t eta_p_6304;
        int64_t tblock_id_in_segment_6967;
        int64_t block_base_offset_6968;
        int32_t offset_6971;
        int32_t skip_waves_6972;
        int64_t eta_p_6964;
        int64_t eta_p_6965;
        
        virt_tblock_id_6958 = phys_tblock_id_6955 + i_6957 * sext_i64_i32(num_tblocks_6297);
        flat_segment_id_6959 = squot64(sext_i32_i64(virt_tblock_id_6958), blocks_per_segment_6918);
        global_tid_6960 = srem64(sext_i32_i64(virt_tblock_id_6958) * seghist_tblock_sizze_6295 + sext_i32_i64(local_tid_6947), threads_per_segment_6921);
        slice_6961 = (int64_t) 256;
        bucket_id_6885 = flat_segment_id_6959;
        remnant_6962 = flat_segment_id_6959 - bucket_id_6885;
        // ne-initialise the outer (per-block) accumulator(s)
        {
            eta_p_block_res_acc_6963 = (int64_t) 0;
        }
        tblock_id_in_segment_6967 = squot64(global_tid_6960, seghist_tblock_sizze_6295);
        block_base_offset_6968 = tblock_id_in_segment_6967 * q_6919 * seghist_tblock_sizze_6295;
        for (int64_t i_6969 = 0; i_6969 < q_6919; i_6969++) {
            int64_t block_offset_6970 = block_base_offset_6968 + i_6969 * seghist_tblock_sizze_6295;
            
            subhistogram_id_6886 = global_tid_6960 + threads_per_segment_6921 * i_6969;
            if (slt64(subhistogram_id_6886, num_subhistos_6801)) {
                // apply map function(s)
                {
                    // load accumulator(s)
                    {
                        eta_p_6303 = eta_p_block_res_acc_6963;
                    }
                    // load next value(s)
                    {
                        eta_p_6304 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[subhistogram_id_6886 * (int64_t) 256 + bucket_id_6885];
                    }
                    // apply reduction operator(s)
                    {
                        int64_t defunc_0_op_res_6305 = add64(eta_p_6303, eta_p_6304);
                        
                        // store in accumulator(s)
                        {
                            eta_p_block_res_acc_6963 = defunc_0_op_res_6305;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // store accs. prims go in lmem; non-prims in params (in global mem)
        {
            ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_block_res_acc_6963;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        skip_waves_6972 = 1;
        offset_6971 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_6947, sext_i64_i32(seghist_tblock_sizze_6295))) {
                eta_p_6964 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
            }
        }
        offset_6971 = 1;
        while (slt32(offset_6971, wave_sizze_6949)) {
            if (slt32(local_tid_6947 + offset_6971, sext_i64_i32(seghist_tblock_sizze_6295)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) & (2 * offset_6971 - 1)) == 0) {
                // read array element
                {
                    eta_p_6965 = ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
                }
                // apply reduction operation
                {
                    int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                    
                    eta_p_6964 = defunc_0_op_res_6966;
                }
                // write result of operation
                {
                    ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                }
            }
            offset_6971 *= 2;
        }
        while (slt32(skip_waves_6972, squot32(sext_i64_i32(seghist_tblock_sizze_6295) + wave_sizze_6949 - 1, wave_sizze_6949))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_6971 = skip_waves_6972 * wave_sizze_6949;
            if (slt32(local_tid_6947 + offset_6971, sext_i64_i32(seghist_tblock_sizze_6295)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) == 0 && (squot32(local_tid_6947, wave_sizze_6949) & (2 * skip_waves_6972 - 1)) == 0)) {
                // read array element
                {
                    eta_p_6965 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
                }
                // apply reduction operation
                {
                    int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                    
                    eta_p_6964 = defunc_0_op_res_6966;
                }
                // write result of operation
                {
                    ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                }
            }
            skip_waves_6972 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_LOCAL_MEM_FENCE);
        // thread 0 updates per-block acc(s); rest reset to ne
        {
            if (sext_i32_i64(local_tid_6947) == (int64_t) 0) {
                eta_p_block_res_acc_6963 = eta_p_6964;
            } else {
                eta_p_block_res_acc_6963 = (int64_t) 0;
            }
        }
        if (blocks_per_segment_6918 == (int64_t) 1) {
            // first thread in block saves final result to memory
            {
                if (local_tid_6947 == 0) {
                    ((__global int64_t *) mem_6744)[bucket_id_6885] = eta_p_block_res_acc_6963;
                }
            }
        } else {
            int32_t old_counter_6973;
            bool is_last_block_6974;
            
            // first thread in block saves block result to global memory
            {
                if (local_tid_6947 == 0) {
                    ((__global int64_t *) segred_tmp_mem_6922)[sext_i32_i64(virt_tblock_id_6958)] = eta_p_block_res_acc_6963;
                    mem_fence_global();
                    old_counter_6973 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6924)[srem64(flat_segment_id_6959, (int64_t) 20480)], (int) 1);
                    ((__local bool *) sync_arr_mem_6953)[(int64_t) 0] = old_counter_6973 == sext_i64_i32(blocks_per_segment_6918 - (int64_t) 1);
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            is_last_block_6974 = ((__local bool *) sync_arr_mem_6953)[(int64_t) 0];
            if (is_last_block_6974) {
                if (local_tid_6947 == 0) {
                    old_counter_6973 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6924)[srem64(flat_segment_id_6959, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_6918));
                }
                // read in the per-block-results
                {
                    int64_t read_per_thread_6975 = sdiv_up64(blocks_per_segment_6918, seghist_tblock_sizze_6295);
                    
                    eta_p_6303 = (int64_t) 0;
                    for (int64_t i_6976 = 0; i_6976 < read_per_thread_6975; i_6976++) {
                        int64_t block_res_id_6977 = sext_i32_i64(local_tid_6947) * read_per_thread_6975 + i_6976;
                        int64_t index_of_block_res_6978 = flat_segment_id_6959 * blocks_per_segment_6918 + block_res_id_6977;
                        
                        if (slt64(block_res_id_6977, blocks_per_segment_6918)) {
                            eta_p_6304 = ((__global int64_t *) segred_tmp_mem_6922)[index_of_block_res_6978];
                            
                            int64_t defunc_0_op_res_6305 = add64(eta_p_6303, eta_p_6304);
                            
                            eta_p_6303 = defunc_0_op_res_6305;
                        }
                    }
                }
                ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6303;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-block results
                {
                    int32_t offset_6979;
                    int32_t skip_waves_6980 = 1;
                    int64_t eta_p_6964;
                    int64_t eta_p_6965;
                    
                    offset_6979 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_6947, sext_i64_i32(seghist_tblock_sizze_6295))) {
                            eta_p_6964 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                        }
                    }
                    offset_6979 = 1;
                    while (slt32(offset_6979, wave_sizze_6949)) {
                        if (slt32(local_tid_6947 + offset_6979, sext_i64_i32(seghist_tblock_sizze_6295)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) & (2 * offset_6979 - 1)) == 0) {
                            // read array element
                            {
                                eta_p_6965 = ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                                
                                eta_p_6964 = defunc_0_op_res_6966;
                            }
                            // write result of operation
                            {
                                ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                            }
                        }
                        offset_6979 *= 2;
                    }
                    while (slt32(skip_waves_6980, squot32(sext_i64_i32(seghist_tblock_sizze_6295) + wave_sizze_6949 - 1, wave_sizze_6949))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_6979 = skip_waves_6980 * wave_sizze_6949;
                        if (slt32(local_tid_6947 + offset_6979, sext_i64_i32(seghist_tblock_sizze_6295)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) == 0 && (squot32(local_tid_6947, wave_sizze_6949) & (2 * skip_waves_6980 - 1)) == 0)) {
                            // read array element
                            {
                                eta_p_6965 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                                
                                eta_p_6964 = defunc_0_op_res_6966;
                            }
                            // write result of operation
                            {
                                ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                            }
                        }
                        skip_waves_6980 *= 2;
                    }
                    barrier(CLK_LOCAL_MEM_FENCE);
                    // and back to memory with the final result
                    {
                        if (local_tid_6947 == 0) {
                            ((__global int64_t *) mem_6744)[bucket_id_6885] = eta_p_6964;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_6:
    return;
    #undef seghist_tblock_sizze_6295
    #undef chunk_sizze_6888
}
FUTHARK_KERNEL_SIZED(byte_histogramzisegred_small_6887_dim1, 1, 1)
void byte_histogramzisegred_small_6887(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_tblocks_6297, int64_t num_subhistos_6801, int64_t segment_sizze_nonzzero_6889, __global unsigned char *mem_6744, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define seghist_tblock_sizze_6295 (byte_histogramzisegred_small_6887ziseghist_tblock_sizze_6295)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *red_arr_i64_mem_6896_backing_0 = &shared_mem[0];
    const int64_t red_arr_i64_mem_6896_backing_0_offset = 0 + ((int64_t) 8 * seghist_tblock_sizze_6295 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_6295, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6892;
    int32_t tblock_sizze_6895;
    int32_t wave_sizze_6894;
    int32_t block_id_6893;
    int32_t global_tid_6891;
    int64_t flat_gtid_6887;
    __local unsigned char *red_arr_i64_mem_6896;
    int32_t phys_tblock_id_6898;
    int32_t iterations_6899;
    
    local_tid_6892 = get_local_id(0);
    tblock_sizze_6895 = get_local_size(0);
    wave_sizze_6894 = LOCKSTEP_WIDTH;
    block_id_6893 = get_tblock_id(0);
    global_tid_6891 = block_id_6893 * tblock_sizze_6895 + local_tid_6892;
    flat_gtid_6887 = sext_i32_i64(global_tid_6891);
    red_arr_i64_mem_6896 = (__local unsigned char *) red_arr_i64_mem_6896_backing_0;
    phys_tblock_id_6898 = get_tblock_id(0);
    iterations_6899 = sdiv_up32(sext_i64_i32(sdiv_up64((int64_t) 256, squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889))) - phys_tblock_id_6898, sext_i64_i32(num_tblocks_6297));
    for (int32_t i_6900 = 0; i_6900 < iterations_6899; i_6900++) {
        int32_t virt_tblock_id_6901;
        int64_t slice_6902;
        int64_t bucket_id_6885;
        int64_t remnant_6903;
        int64_t subhistogram_id_6886;
        
        virt_tblock_id_6901 = phys_tblock_id_6898 + i_6900 * sext_i64_i32(num_tblocks_6297);
        slice_6902 = (int64_t) 256;
        bucket_id_6885 = squot64(sext_i32_i64(local_tid_6892), segment_sizze_nonzzero_6889) + sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889);
        remnant_6903 = squot64(sext_i32_i64(local_tid_6892), segment_sizze_nonzzero_6889) + sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889) - bucket_id_6885;
        subhistogram_id_6886 = srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801);
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, num_subhistos_6801) && (slt64(bucket_id_6885, (int64_t) 256) && slt64(sext_i32_i64(local_tid_6892), num_subhistos_6801 * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889)))) {
                // save results to be reduced
                {
                    int64_t tmp_6904 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[subhistogram_id_6886 * (int64_t) 256 + bucket_id_6885];
                    
                    ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = tmp_6904;
                }
            } else {
                ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = (int64_t) 0;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, num_subhistos_6801)) {
            // perform segmented scan to imitate reduction
            {
                int64_t eta_p_6303;
                int64_t eta_p_6304;
                int64_t eta_p_6905;
                int64_t eta_p_6906;
                bool ltid_in_bounds_6908 = slt64(sext_i32_i64(local_tid_6892), num_subhistos_6801 * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889));
                int32_t skip_threads_6909;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_6908) {
                        eta_p_6304 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)];
                        if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 0) {
                            eta_p_6303 = eta_p_6304;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_6909 = 1;
                    while (slt32(skip_threads_6909, 32)) {
                        bool thread_active_6910 = sle32(skip_threads_6909, local_tid_6892 - squot32(local_tid_6892, 32) * 32) && ltid_in_bounds_6908;
                        
                        if (thread_active_6910) {
                            // read operands
                            {
                                eta_p_6303 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892) - sext_i32_i64(skip_threads_6909)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_6911 = slt64(srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801), sext_i32_i64(local_tid_6892) - sext_i32_i64(local_tid_6892 - skip_threads_6909));
                            
                            if (thread_active_6910 && inactive_6911) {
                                eta_p_6303 = eta_p_6304;
                            }
                            if (thread_active_6910) {
                                if (!inactive_6911) {
                                    int64_t defunc_0_op_res_6305 = add64(eta_p_6303, eta_p_6304);
                                    
                                    eta_p_6303 = defunc_0_op_res_6305;
                                }
                            }
                        }
                        if (sle32(wave_sizze_6894, skip_threads_6909)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_6910) {
                            // write result
                            {
                                ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6303;
                                eta_p_6304 = eta_p_6303;
                            }
                        }
                        if (sle32(wave_sizze_6894, skip_threads_6909)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_6909 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 31 && ltid_in_bounds_6908) {
                        ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(squot32(local_tid_6892, 32))] = eta_p_6303;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_6912;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908) {
                            eta_p_6906 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)];
                            if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 0) {
                                eta_p_6905 = eta_p_6906;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_6912 = 1;
                        while (slt32(skip_threads_6912, 32)) {
                            bool thread_active_6913 = sle32(skip_threads_6912, local_tid_6892 - squot32(local_tid_6892, 32) * 32) && (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908);
                            
                            if (thread_active_6913) {
                                // read operands
                                {
                                    eta_p_6905 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892) - sext_i32_i64(skip_threads_6912)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_6914 = slt64(srem64(sext_i32_i64(local_tid_6892 * 32 + 32 - 1), num_subhistos_6801), sext_i32_i64(local_tid_6892 * 32 + 32 - 1) - sext_i32_i64((local_tid_6892 - skip_threads_6912) * 32 + 32 - 1));
                                
                                if (thread_active_6913 && inactive_6914) {
                                    eta_p_6905 = eta_p_6906;
                                }
                                if (thread_active_6913) {
                                    if (!inactive_6914) {
                                        int64_t defunc_0_op_res_6907 = add64(eta_p_6905, eta_p_6906);
                                        
                                        eta_p_6905 = defunc_0_op_res_6907;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_6894, skip_threads_6912)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_6913) {
                                // write result
                                {
                                    ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6905;
                                    eta_p_6906 = eta_p_6905;
                                }
                            }
                            if (sle32(wave_sizze_6894, skip_threads_6912)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_6912 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_6915 = squot32(local_tid_6892, 32) == 0 || !ltid_in_bounds_6908;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_6915) {
                            eta_p_6304 = eta_p_6303;
                            eta_p_6303 = ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(squot32(local_tid_6892, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_6916 = slt64(srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801), sext_i32_i64(local_tid_6892) - sext_i32_i64(squot32(local_tid_6892, 32) * 32 - 1));
                        
                        if (!no_carry_in_6915) {
                            if (inactive_6916) {
                                eta_p_6303 = eta_p_6304;
                            }
                        }
                        if (!no_carry_in_6915) {
                            if (!inactive_6916) {
                                int64_t defunc_0_op_res_6305 = add64(eta_p_6303, eta_p_6304);
                                
                                eta_p_6303 = defunc_0_op_res_6305;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_6915) {
                            ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6303;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908) {
                        ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6304;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889) + sext_i32_i64(local_tid_6892), (int64_t) 256) && slt64(sext_i32_i64(local_tid_6892), squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889))) {
                int64_t tmp_6917 = ((__local int64_t *) red_arr_i64_mem_6896)[(sext_i32_i64(local_tid_6892) + (int64_t) 1) * segment_sizze_nonzzero_6889 - (int64_t) 1];
                
                ((__global int64_t *) mem_6744)[sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6295, segment_sizze_nonzzero_6889) + sext_i32_i64(local_tid_6892)] = tmp_6917;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_3:
    return;
    #undef seghist_tblock_sizze_6295
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegmap_6394_dim1, 1, 1)
void chunked_entropyzisegmap_6394(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_6040, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, __global unsigned char *xs_mem_6743, __global unsigned char *mem_6777)
{
    #define segmap_tblock_sizze_6390 (chunked_entropyzisegmap_6394zisegmap_tblock_sizze_6390)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6785;
    int32_t tblock_sizze_6788;
    int32_t wave_sizze_6787;
    int32_t block_id_6786;
    int32_t global_tid_6784;
    int64_t phys_tid_6394;
    int64_t global_tid_6789;
    int64_t slice_6790;
    int64_t gtid_6393;
    int64_t remnant_6791;
    
    local_tid_6785 = get_local_id(0);
    tblock_sizze_6788 = get_local_size(0);
    wave_sizze_6787 = LOCKSTEP_WIDTH;
    block_id_6786 = get_tblock_id(0);
    global_tid_6784 = block_id_6786 * tblock_sizze_6788 + local_tid_6785;
    phys_tid_6394 = sext_i32_i64(global_tid_6784);
    global_tid_6789 = sext_i32_i64(block_id_6786) * segmap_tblock_sizze_6390 + sext_i32_i64(local_tid_6785);
    slice_6790 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
    gtid_6393 = global_tid_6789;
    remnant_6791 = global_tid_6789 - gtid_6393;
    if (slt64(gtid_6393, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188)) {
        int64_t entropy_arg0_6396;
        int64_t zt_lhs_6397;
        int64_t entropy_arg0_6398;
        int64_t j_m_i_6399;
        bool empty_slice_6400;
        int64_t m_6401;
        int64_t i_p_m_t_s_6402;
        bool zzero_leq_i_p_m_t_s_6403;
        bool i_p_m_t_s_leq_w_6404;
        bool zzero_lte_i_6405;
        bool i_lte_j_6406;
        bool y_6407;
        bool y_6408;
        bool forwards_ok_6409;
        bool ok_or_empty_6410;
        bool index_certs_6411;
        int64_t mem_6774[(int64_t) 256];
        float i64_res_6422;
        float defunc_0_f_res_6423;
        float redout_6728;
        float zs_lhs_6434;
        float log2_res_6435;
        float lifted_lambda_res_6436;
        float floor_res_6437;
        int8_t unsign_arg0_6438;
        
        entropy_arg0_6396 = mul64(chunk_sizze_6041, gtid_6393);
        zt_lhs_6397 = add64((int64_t) 1, gtid_6393);
        entropy_arg0_6398 = mul64(chunk_sizze_6041, zt_lhs_6397);
        j_m_i_6399 = sub64(entropy_arg0_6398, entropy_arg0_6396);
        empty_slice_6400 = j_m_i_6399 == (int64_t) 0;
        m_6401 = sub64(j_m_i_6399, (int64_t) 1);
        i_p_m_t_s_6402 = add64(entropy_arg0_6396, m_6401);
        zzero_leq_i_p_m_t_s_6403 = sle64((int64_t) 0, i_p_m_t_s_6402);
        i_p_m_t_s_leq_w_6404 = slt64(i_p_m_t_s_6402, n_6040);
        zzero_lte_i_6405 = sle64((int64_t) 0, entropy_arg0_6396);
        i_lte_j_6406 = sle64(entropy_arg0_6396, entropy_arg0_6398);
        y_6407 = i_p_m_t_s_leq_w_6404 && zzero_lte_i_6405;
        y_6408 = zzero_leq_i_p_m_t_s_6403 && y_6407;
        forwards_ok_6409 = i_lte_j_6406 && y_6408;
        ok_or_empty_6410 = empty_slice_6400 || forwards_ok_6409;
        if (!ok_or_empty_6410) {
            {
                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {
                    global_failure_args[0] = (int64_t) entropy_arg0_6396;
                    global_failure_args[1] = (int64_t) entropy_arg0_6398;
                    global_failure_args[2] = (int64_t) n_6040;
                    ;
                }
                return;
            }
        }
        for (int64_t nest_i_6792 = 0; nest_i_6792 < (int64_t) 256; nest_i_6792++) {
            mem_6774[nest_i_6792] = (int64_t) 0;
        }
        for (int64_t iter_6717 = 0; iter_6717 < j_m_i_6399; iter_6717++) {
            int64_t slice_6741;
            int8_t pixel_6719;
            int64_t u8_res_6421;
            bool less_than_zzero_6721;
            bool greater_than_sizze_6722;
            bool outside_bounds_dim_6723;
            
            slice_6741 = entropy_arg0_6396 + iter_6717;
            pixel_6719 = ((__global int8_t *) xs_mem_6743)[slice_6741];
            u8_res_6421 = zext_i8_i64(pixel_6719);
            less_than_zzero_6721 = slt64(u8_res_6421, (int64_t) 0);
            greater_than_sizze_6722 = sle64((int64_t) 256, u8_res_6421);
            outside_bounds_dim_6723 = less_than_zzero_6721 || greater_than_sizze_6722;
            if (!outside_bounds_dim_6723) {
                int64_t read_hist_6725;
                int64_t defunc_0_op_res_6418;
                
                read_hist_6725 = mem_6774[u8_res_6421];
                defunc_0_op_res_6418 = add64((int64_t) 1, read_hist_6725);
                mem_6774[u8_res_6421] = defunc_0_op_res_6418;
            }
        }
        i64_res_6422 = sitofp_i64_f32(j_m_i_6399);
        redout_6728 = 0.0F;
        for (int64_t i_6729 = 0; i_6729 < (int64_t) 256; i_6729++) {
            int64_t eta_p_6427;
            float i64_res_6428;
            float lifted_lambda_res_6429;
            bool cond_6430;
            float lifted_lambda_res_6431;
            float defunc_0_op_res_6426;
            float redout_tmp_6794;
            
            eta_p_6427 = mem_6774[i_6729];
            i64_res_6428 = sitofp_i64_f32(eta_p_6427);
            lifted_lambda_res_6429 = i64_res_6428 / i64_res_6422;
            cond_6430 = lifted_lambda_res_6429 == 0.0F;
            if (cond_6430) {
                lifted_lambda_res_6431 = 0.0F;
            } else {
                float log2_res_6432;
                float lifted_lambda_res_f_res_6433;
                
                log2_res_6432 = futrts_log2_32(lifted_lambda_res_6429);
                lifted_lambda_res_f_res_6433 = lifted_lambda_res_6429 * log2_res_6432;
                lifted_lambda_res_6431 = lifted_lambda_res_f_res_6433;
            }
            defunc_0_op_res_6426 = lifted_lambda_res_6431 + redout_6728;
            redout_tmp_6794 = defunc_0_op_res_6426;
            redout_6728 = redout_tmp_6794;
        }
        defunc_0_f_res_6423 = redout_6728;
        zs_lhs_6434 = -1.0F * defunc_0_f_res_6423;
        log2_res_6435 = futrts_log2_32(i64_res_6422);
        lifted_lambda_res_6436 = zs_lhs_6434 / log2_res_6435;
        floor_res_6437 = futrts_floor32(lifted_lambda_res_6436);
        unsign_arg0_6438 = fptoui_f32_i8(floor_res_6437);
        ((__global int8_t *) mem_6777)[gtid_6393] = unsign_arg0_6438;
    }
    
  error_0:
    return;
    #undef segmap_tblock_sizze_6390
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegmap_6593_dim1, 1, 1)
void chunked_entropyzisegmap_6593(__local uint64_t *shared_mem_aligned, __global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_6040, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, __global unsigned char *mem_6745)
{
    #define segmap_tblock_sizze_6587 (chunked_entropyzisegmap_6593zisegmap_tblock_sizze_6587)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6797;
    int32_t tblock_sizze_6800;
    int32_t wave_sizze_6799;
    int32_t block_id_6798;
    int32_t global_tid_6796;
    int64_t phys_tid_6593;
    int64_t global_tid_6801;
    int64_t slice_6802;
    int64_t gtid_6592;
    int64_t remnant_6803;
    
    local_tid_6797 = get_local_id(0);
    tblock_sizze_6800 = get_local_size(0);
    wave_sizze_6799 = LOCKSTEP_WIDTH;
    block_id_6798 = get_tblock_id(0);
    global_tid_6796 = block_id_6798 * tblock_sizze_6800 + local_tid_6797;
    phys_tid_6593 = sext_i32_i64(global_tid_6796);
    global_tid_6801 = sext_i32_i64(block_id_6798) * segmap_tblock_sizze_6587 + sext_i32_i64(local_tid_6797);
    slice_6802 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
    gtid_6592 = global_tid_6801;
    remnant_6803 = global_tid_6801 - gtid_6592;
    if (slt64(gtid_6592, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188)) {
        int64_t entropy_arg0_6595;
        int64_t zt_lhs_6596;
        int64_t entropy_arg0_6597;
        int64_t j_m_i_6598;
        bool empty_slice_6599;
        int64_t m_6600;
        int64_t i_p_m_t_s_6601;
        bool zzero_leq_i_p_m_t_s_6602;
        bool i_p_m_t_s_leq_w_6603;
        bool zzero_lte_i_6604;
        bool i_lte_j_6605;
        bool y_6606;
        bool y_6607;
        bool forwards_ok_6608;
        bool ok_or_empty_6609;
        bool index_certs_6610;
        
        entropy_arg0_6595 = mul64(chunk_sizze_6041, gtid_6592);
        zt_lhs_6596 = add64((int64_t) 1, gtid_6592);
        entropy_arg0_6597 = mul64(chunk_sizze_6041, zt_lhs_6596);
        j_m_i_6598 = sub64(entropy_arg0_6597, entropy_arg0_6595);
        empty_slice_6599 = j_m_i_6598 == (int64_t) 0;
        m_6600 = sub64(j_m_i_6598, (int64_t) 1);
        i_p_m_t_s_6601 = add64(entropy_arg0_6595, m_6600);
        zzero_leq_i_p_m_t_s_6602 = sle64((int64_t) 0, i_p_m_t_s_6601);
        i_p_m_t_s_leq_w_6603 = slt64(i_p_m_t_s_6601, n_6040);
        zzero_lte_i_6604 = sle64((int64_t) 0, entropy_arg0_6595);
        i_lte_j_6605 = sle64(entropy_arg0_6595, entropy_arg0_6597);
        y_6606 = i_p_m_t_s_leq_w_6603 && zzero_lte_i_6604;
        y_6607 = zzero_leq_i_p_m_t_s_6602 && y_6606;
        forwards_ok_6608 = i_lte_j_6605 && y_6607;
        ok_or_empty_6609 = empty_slice_6599 || forwards_ok_6608;
        if (!ok_or_empty_6609) {
            {
                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {
                    global_failure_args[0] = (int64_t) entropy_arg0_6595;
                    global_failure_args[1] = (int64_t) entropy_arg0_6597;
                    global_failure_args[2] = (int64_t) n_6040;
                    ;
                }
                return;
            }
        }
    }
    
  error_0:
    return;
    #undef segmap_tblock_sizze_6587
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegmap_6632_dim1, 1, 1)
void chunked_entropyzisegmap_6632(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, int64_t num_tblocks_6627, int32_t virt_num_tblocks_6804, __global unsigned char *xs_mem_6743, __global unsigned char *mem_6745, __global unsigned char *mem_6763)
{
    #define segmap_tblock_sizze_6626 (chunked_entropyzisegmap_6632zisegmap_tblock_sizze_6626)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6806;
    int32_t tblock_sizze_6809;
    int32_t wave_sizze_6808;
    int32_t block_id_6807;
    int32_t global_tid_6805;
    int64_t phys_tid_6632;
    int32_t phys_tblock_id_6810;
    int32_t iterations_6811;
    
    local_tid_6806 = get_local_id(0);
    tblock_sizze_6809 = get_local_size(0);
    wave_sizze_6808 = LOCKSTEP_WIDTH;
    block_id_6807 = get_tblock_id(0);
    global_tid_6805 = block_id_6807 * tblock_sizze_6809 + local_tid_6806;
    phys_tid_6632 = sext_i32_i64(global_tid_6805);
    phys_tblock_id_6810 = get_tblock_id(0);
    iterations_6811 = sdiv_up32(virt_num_tblocks_6804 - phys_tblock_id_6810, sext_i64_i32(num_tblocks_6627));
    for (int32_t i_6812 = 0; i_6812 < iterations_6811; i_6812++) {
        int32_t virt_tblock_id_6813;
        int64_t global_tid_6814;
        int64_t slice_6815;
        int64_t gtid_6631;
        int64_t remnant_6816;
        
        virt_tblock_id_6813 = phys_tblock_id_6810 + i_6812 * sext_i64_i32(num_tblocks_6627);
        global_tid_6814 = sext_i32_i64(virt_tblock_id_6813) * segmap_tblock_sizze_6626 + sext_i32_i64(local_tid_6806);
        slice_6815 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
        gtid_6631 = global_tid_6814;
        remnant_6816 = global_tid_6814 - gtid_6631;
        if (slt64(gtid_6631, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188)) {
            int64_t index_primexp_6698;
            int64_t binop_y_6690;
            int64_t binop_x_6691;
            int64_t index_primexp_6695;
            bool index_certs_6635;
            int64_t mem_6751[(int64_t) 256];
            
            index_primexp_6698 = mul64(chunk_sizze_6041, gtid_6631);
            binop_y_6690 = add64((int64_t) 1, gtid_6631);
            binop_x_6691 = mul64(chunk_sizze_6041, binop_y_6690);
            index_primexp_6695 = sub64(binop_x_6691, index_primexp_6698);
            index_certs_6635 = 0;
            for (int64_t nest_i_6817 = 0; nest_i_6817 < (int64_t) 256; nest_i_6817++) {
                mem_6751[nest_i_6817] = (int64_t) 0;
            }
            for (int64_t iter_6730 = 0; iter_6730 < index_primexp_6695; iter_6730++) {
                int64_t slice_6742;
                int8_t pixel_6732;
                int64_t u8_res_6646;
                bool less_than_zzero_6734;
                bool greater_than_sizze_6735;
                bool outside_bounds_dim_6736;
                
                slice_6742 = index_primexp_6698 + iter_6730;
                pixel_6732 = ((__global int8_t *) xs_mem_6743)[slice_6742];
                u8_res_6646 = zext_i8_i64(pixel_6732);
                less_than_zzero_6734 = slt64(u8_res_6646, (int64_t) 0);
                greater_than_sizze_6735 = sle64((int64_t) 256, u8_res_6646);
                outside_bounds_dim_6736 = less_than_zzero_6734 || greater_than_sizze_6735;
                if (!outside_bounds_dim_6736) {
                    int64_t read_hist_6738;
                    int64_t defunc_0_op_res_6643;
                    
                    read_hist_6738 = mem_6751[u8_res_6646];
                    defunc_0_op_res_6643 = add64((int64_t) 1, read_hist_6738);
                    mem_6751[u8_res_6646] = defunc_0_op_res_6643;
                }
            }
            for (int64_t i_0 = 0; i_0 < (int64_t) 256; i_0++) {
                ((__global int64_t *) mem_6763)[gtid_6631 + i_0 * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188] = mem_6751[i_0];
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_1:
    return;
    #undef segmap_tblock_sizze_6626
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegmap_6674_dim1, 1, 1)
void chunked_entropyzisegmap_6674(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, __global unsigned char *mem_6766, __global unsigned char *mem_6768)
{
    #define segmap_tblock_sizze_6670 (chunked_entropyzisegmap_6674zisegmap_tblock_sizze_6670)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6913;
    int32_t tblock_sizze_6916;
    int32_t wave_sizze_6915;
    int32_t block_id_6914;
    int32_t global_tid_6912;
    int64_t phys_tid_6674;
    int64_t global_tid_6917;
    int64_t slice_6918;
    int64_t gtid_6673;
    int64_t remnant_6919;
    
    local_tid_6913 = get_local_id(0);
    tblock_sizze_6916 = get_local_size(0);
    wave_sizze_6915 = LOCKSTEP_WIDTH;
    block_id_6914 = get_tblock_id(0);
    global_tid_6912 = block_id_6914 * tblock_sizze_6916 + local_tid_6913;
    phys_tid_6674 = sext_i32_i64(global_tid_6912);
    global_tid_6917 = sext_i32_i64(block_id_6914) * segmap_tblock_sizze_6670 + sext_i32_i64(local_tid_6913);
    slice_6918 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
    gtid_6673 = global_tid_6917;
    remnant_6919 = global_tid_6917 - gtid_6673;
    if (slt64(gtid_6673, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188)) {
        int64_t binop_y_6701;
        int64_t binop_x_6702;
        int64_t binop_y_6705;
        int64_t convop_x_6706;
        float index_primexp_6707;
        float defunc_0_f_res_6676;
        float zs_lhs_6677;
        float log2_res_6678;
        float lifted_lambda_res_6679;
        float floor_res_6680;
        int8_t unsign_arg0_6681;
        
        binop_y_6701 = add64((int64_t) 1, gtid_6673);
        binop_x_6702 = mul64(chunk_sizze_6041, binop_y_6701);
        binop_y_6705 = mul64(chunk_sizze_6041, gtid_6673);
        convop_x_6706 = sub64(binop_x_6702, binop_y_6705);
        index_primexp_6707 = sitofp_i64_f32(convop_x_6706);
        defunc_0_f_res_6676 = ((__global float *) mem_6766)[gtid_6673];
        zs_lhs_6677 = -1.0F * defunc_0_f_res_6676;
        log2_res_6678 = futrts_log2_32(index_primexp_6707);
        lifted_lambda_res_6679 = zs_lhs_6677 / log2_res_6678;
        floor_res_6680 = futrts_floor32(lifted_lambda_res_6679);
        unsign_arg0_6681 = fptoui_f32_i8(floor_res_6680);
        ((__global int8_t *) mem_6768)[gtid_6673] = unsign_arg0_6681;
    }
    
  error_0:
    return;
    #undef segmap_tblock_sizze_6670
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegred_large_6656_dim1, 1, 1)
void chunked_entropyzisegred_large_6656(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, int64_t num_tblocks_6651, int64_t blocks_per_segment_6848, int64_t q_6849, int64_t num_virtblocks_6850, int64_t threads_per_segment_6851, __global unsigned char *mem_6763, __global unsigned char *mem_6766, __global unsigned char *segred_tmp_mem_6852, __global unsigned char *counters_mem_6854)
{
    #define segred_tblock_sizze_6650 (chunked_entropyzisegred_large_6656zisegred_tblock_sizze_6650)
    #define chunk_sizze_6819 (chunked_entropyzisegred_large_6656zichunk_sizze_6819)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *sync_arr_mem_6883_backing_1 = &shared_mem[0];
    const int64_t sync_arr_mem_6883_backing_1_offset = 0 + 8;
    volatile __local unsigned char *red_arr_f32_mem_6881_backing_0 = &shared_mem[sync_arr_mem_6883_backing_1_offset];
    const int64_t red_arr_f32_mem_6881_backing_0_offset = sync_arr_mem_6883_backing_1_offset + ((int64_t) 4 * segred_tblock_sizze_6650 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_6650, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6877;
    int32_t tblock_sizze_6880;
    int32_t wave_sizze_6879;
    int32_t block_id_6878;
    int32_t global_tid_6876;
    int64_t phys_tid_6656;
    __local unsigned char *red_arr_f32_mem_6881;
    __local unsigned char *sync_arr_mem_6883;
    int32_t phys_tblock_id_6885;
    int32_t iterations_6886;
    
    local_tid_6877 = get_local_id(0);
    tblock_sizze_6880 = get_local_size(0);
    wave_sizze_6879 = LOCKSTEP_WIDTH;
    block_id_6878 = get_tblock_id(0);
    global_tid_6876 = block_id_6878 * tblock_sizze_6880 + local_tid_6877;
    phys_tid_6656 = sext_i32_i64(global_tid_6876);
    red_arr_f32_mem_6881 = (__local unsigned char *) red_arr_f32_mem_6881_backing_0;
    sync_arr_mem_6883 = (__local unsigned char *) sync_arr_mem_6883_backing_1;
    phys_tblock_id_6885 = get_tblock_id(0);
    iterations_6886 = sdiv_up32(sext_i64_i32(num_virtblocks_6850) - phys_tblock_id_6885, sext_i64_i32(num_tblocks_6651));
    for (int32_t i_6887 = 0; i_6887 < iterations_6886; i_6887++) {
        int32_t virt_tblock_id_6888;
        int64_t flat_segment_id_6889;
        int64_t global_tid_6890;
        int64_t slice_6891;
        int64_t gtid_6654;
        int64_t remnant_6892;
        int64_t gtid_6655;
        float eta_p_block_res_acc_6893;
        float eta_p_6657;
        float eta_p_6658;
        int64_t tblock_id_in_segment_6897;
        int64_t block_base_offset_6898;
        int32_t offset_6901;
        int32_t skip_waves_6902;
        float eta_p_6894;
        float eta_p_6895;
        
        virt_tblock_id_6888 = phys_tblock_id_6885 + i_6887 * sext_i64_i32(num_tblocks_6651);
        flat_segment_id_6889 = squot64(sext_i32_i64(virt_tblock_id_6888), blocks_per_segment_6848);
        global_tid_6890 = srem64(sext_i32_i64(virt_tblock_id_6888) * segred_tblock_sizze_6650 + sext_i32_i64(local_tid_6877), threads_per_segment_6851);
        slice_6891 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
        gtid_6654 = flat_segment_id_6889;
        remnant_6892 = flat_segment_id_6889 - gtid_6654;
        // ne-initialise the outer (per-block) accumulator(s)
        {
            eta_p_block_res_acc_6893 = 0.0F;
        }
        tblock_id_in_segment_6897 = squot64(global_tid_6890, segred_tblock_sizze_6650);
        block_base_offset_6898 = tblock_id_in_segment_6897 * q_6849 * segred_tblock_sizze_6650;
        for (int64_t i_6899 = 0; i_6899 < q_6849; i_6899++) {
            int64_t block_offset_6900 = block_base_offset_6898 + i_6899 * segred_tblock_sizze_6650;
            
            gtid_6655 = global_tid_6890 + threads_per_segment_6851 * i_6899;
            if (slt64(gtid_6655, (int64_t) 256)) {
                // apply map function(s)
                {
                    // apply map function
                    {
                        int64_t binop_y_6710 = add64((int64_t) 1, gtid_6654);
                        int64_t binop_x_6711 = mul64(chunk_sizze_6041, binop_y_6710);
                        int64_t binop_y_6714 = mul64(chunk_sizze_6041, gtid_6654);
                        int64_t convop_x_6715 = sub64(binop_x_6711, binop_y_6714);
                        float index_primexp_6716 = sitofp_i64_f32(convop_x_6715);
                        int64_t eta_p_6662 = ((__global int64_t *) mem_6763)[gtid_6654 + gtid_6655 * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188];
                        float i64_res_6663 = sitofp_i64_f32(eta_p_6662);
                        float lifted_lambda_res_6664 = i64_res_6663 / index_primexp_6716;
                        bool cond_6665 = lifted_lambda_res_6664 == 0.0F;
                        float lifted_lambda_res_6666;
                        
                        if (cond_6665) {
                            lifted_lambda_res_6666 = 0.0F;
                        } else {
                            float log2_res_6667 = futrts_log2_32(lifted_lambda_res_6664);
                            float lifted_lambda_res_f_res_6668 = lifted_lambda_res_6664 * log2_res_6667;
                            
                            lifted_lambda_res_6666 = lifted_lambda_res_f_res_6668;
                        }
                        // load accumulator(s)
                        {
                            eta_p_6657 = eta_p_block_res_acc_6893;
                        }
                        // load next value(s)
                        {
                            eta_p_6658 = lifted_lambda_res_6666;
                        }
                        // apply reduction operator(s)
                        {
                            float defunc_0_op_res_6659 = eta_p_6657 + eta_p_6658;
                            
                            // store in accumulator(s)
                            {
                                eta_p_block_res_acc_6893 = defunc_0_op_res_6659;
                            }
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // store accs. prims go in lmem; non-prims in params (in global mem)
        {
            ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_block_res_acc_6893;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        skip_waves_6902 = 1;
        offset_6901 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_6877, sext_i64_i32(segred_tblock_sizze_6650))) {
                eta_p_6894 = ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6901)];
            }
        }
        offset_6901 = 1;
        while (slt32(offset_6901, wave_sizze_6879)) {
            if (slt32(local_tid_6877 + offset_6901, sext_i64_i32(segred_tblock_sizze_6650)) && ((local_tid_6877 - squot32(local_tid_6877, wave_sizze_6879) * wave_sizze_6879) & (2 * offset_6901 - 1)) == 0) {
                // read array element
                {
                    eta_p_6895 = ((volatile __local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6901)];
                }
                // apply reduction operation
                {
                    float defunc_0_op_res_6896 = eta_p_6894 + eta_p_6895;
                    
                    eta_p_6894 = defunc_0_op_res_6896;
                }
                // write result of operation
                {
                    ((volatile __local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_6894;
                }
            }
            offset_6901 *= 2;
        }
        while (slt32(skip_waves_6902, squot32(sext_i64_i32(segred_tblock_sizze_6650) + wave_sizze_6879 - 1, wave_sizze_6879))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_6901 = skip_waves_6902 * wave_sizze_6879;
            if (slt32(local_tid_6877 + offset_6901, sext_i64_i32(segred_tblock_sizze_6650)) && ((local_tid_6877 - squot32(local_tid_6877, wave_sizze_6879) * wave_sizze_6879) == 0 && (squot32(local_tid_6877, wave_sizze_6879) & (2 * skip_waves_6902 - 1)) == 0)) {
                // read array element
                {
                    eta_p_6895 = ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6901)];
                }
                // apply reduction operation
                {
                    float defunc_0_op_res_6896 = eta_p_6894 + eta_p_6895;
                    
                    eta_p_6894 = defunc_0_op_res_6896;
                }
                // write result of operation
                {
                    ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_6894;
                }
            }
            skip_waves_6902 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_LOCAL_MEM_FENCE);
        // thread 0 updates per-block acc(s); rest reset to ne
        {
            if (sext_i32_i64(local_tid_6877) == (int64_t) 0) {
                eta_p_block_res_acc_6893 = eta_p_6894;
            } else {
                eta_p_block_res_acc_6893 = 0.0F;
            }
        }
        if (blocks_per_segment_6848 == (int64_t) 1) {
            // first thread in block saves final result to memory
            {
                if (local_tid_6877 == 0) {
                    ((__global float *) mem_6766)[gtid_6654] = eta_p_block_res_acc_6893;
                }
            }
        } else {
            int32_t old_counter_6903;
            bool is_last_block_6904;
            
            // first thread in block saves block result to global memory
            {
                if (local_tid_6877 == 0) {
                    ((__global float *) segred_tmp_mem_6852)[sext_i32_i64(virt_tblock_id_6888)] = eta_p_block_res_acc_6893;
                    mem_fence_global();
                    old_counter_6903 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6854)[srem64(flat_segment_id_6889, (int64_t) 20480)], (int) 1);
                    ((__local bool *) sync_arr_mem_6883)[(int64_t) 0] = old_counter_6903 == sext_i64_i32(blocks_per_segment_6848 - (int64_t) 1);
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            is_last_block_6904 = ((__local bool *) sync_arr_mem_6883)[(int64_t) 0];
            if (is_last_block_6904) {
                if (local_tid_6877 == 0) {
                    old_counter_6903 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6854)[srem64(flat_segment_id_6889, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_6848));
                }
                // read in the per-block-results
                {
                    int64_t read_per_thread_6905 = sdiv_up64(blocks_per_segment_6848, segred_tblock_sizze_6650);
                    
                    eta_p_6657 = 0.0F;
                    for (int64_t i_6906 = 0; i_6906 < read_per_thread_6905; i_6906++) {
                        int64_t block_res_id_6907 = sext_i32_i64(local_tid_6877) * read_per_thread_6905 + i_6906;
                        int64_t index_of_block_res_6908 = flat_segment_id_6889 * blocks_per_segment_6848 + block_res_id_6907;
                        
                        if (slt64(block_res_id_6907, blocks_per_segment_6848)) {
                            eta_p_6658 = ((__global float *) segred_tmp_mem_6852)[index_of_block_res_6908];
                            
                            float defunc_0_op_res_6659 = eta_p_6657 + eta_p_6658;
                            
                            eta_p_6657 = defunc_0_op_res_6659;
                        }
                    }
                }
                ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_6657;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-block results
                {
                    int32_t offset_6909;
                    int32_t skip_waves_6910 = 1;
                    float eta_p_6894;
                    float eta_p_6895;
                    
                    offset_6909 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_6877, sext_i64_i32(segred_tblock_sizze_6650))) {
                            eta_p_6894 = ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6909)];
                        }
                    }
                    offset_6909 = 1;
                    while (slt32(offset_6909, wave_sizze_6879)) {
                        if (slt32(local_tid_6877 + offset_6909, sext_i64_i32(segred_tblock_sizze_6650)) && ((local_tid_6877 - squot32(local_tid_6877, wave_sizze_6879) * wave_sizze_6879) & (2 * offset_6909 - 1)) == 0) {
                            // read array element
                            {
                                eta_p_6895 = ((volatile __local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6909)];
                            }
                            // apply reduction operation
                            {
                                float defunc_0_op_res_6896 = eta_p_6894 + eta_p_6895;
                                
                                eta_p_6894 = defunc_0_op_res_6896;
                            }
                            // write result of operation
                            {
                                ((volatile __local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_6894;
                            }
                        }
                        offset_6909 *= 2;
                    }
                    while (slt32(skip_waves_6910, squot32(sext_i64_i32(segred_tblock_sizze_6650) + wave_sizze_6879 - 1, wave_sizze_6879))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_6909 = skip_waves_6910 * wave_sizze_6879;
                        if (slt32(local_tid_6877 + offset_6909, sext_i64_i32(segred_tblock_sizze_6650)) && ((local_tid_6877 - squot32(local_tid_6877, wave_sizze_6879) * wave_sizze_6879) == 0 && (squot32(local_tid_6877, wave_sizze_6879) & (2 * skip_waves_6910 - 1)) == 0)) {
                            // read array element
                            {
                                eta_p_6895 = ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877 + offset_6909)];
                            }
                            // apply reduction operation
                            {
                                float defunc_0_op_res_6896 = eta_p_6894 + eta_p_6895;
                                
                                eta_p_6894 = defunc_0_op_res_6896;
                            }
                            // write result of operation
                            {
                                ((__local float *) red_arr_f32_mem_6881)[sext_i32_i64(local_tid_6877)] = eta_p_6894;
                            }
                        }
                        skip_waves_6910 *= 2;
                    }
                    barrier(CLK_LOCAL_MEM_FENCE);
                    // and back to memory with the final result
                    {
                        if (local_tid_6877 == 0) {
                            ((__global float *) mem_6766)[gtid_6654] = eta_p_6894;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_6:
    return;
    #undef segred_tblock_sizze_6650
    #undef chunk_sizze_6819
}
FUTHARK_KERNEL_SIZED(chunked_entropyzisegred_small_6656_dim1, 1, 1)
void chunked_entropyzisegred_small_6656(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t chunk_sizze_6041, int64_t dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, int64_t num_tblocks_6651, int64_t segment_sizze_nonzzero_6820, __global unsigned char *mem_6763, __global unsigned char *mem_6766)
{
    #define segred_tblock_sizze_6650 (chunked_entropyzisegred_small_6656zisegred_tblock_sizze_6650)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *red_arr_f32_mem_6827_backing_0 = &shared_mem[0];
    const int64_t red_arr_f32_mem_6827_backing_0_offset = 0 + ((int64_t) 4 * segred_tblock_sizze_6650 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_6650, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6823;
    int32_t tblock_sizze_6826;
    int32_t wave_sizze_6825;
    int32_t block_id_6824;
    int32_t global_tid_6822;
    int64_t phys_tid_6656;
    __local unsigned char *red_arr_f32_mem_6827;
    int32_t phys_tblock_id_6829;
    int32_t iterations_6830;
    
    local_tid_6823 = get_local_id(0);
    tblock_sizze_6826 = get_local_size(0);
    wave_sizze_6825 = LOCKSTEP_WIDTH;
    block_id_6824 = get_tblock_id(0);
    global_tid_6822 = block_id_6824 * tblock_sizze_6826 + local_tid_6823;
    phys_tid_6656 = sext_i32_i64(global_tid_6822);
    red_arr_f32_mem_6827 = (__local unsigned char *) red_arr_f32_mem_6827_backing_0;
    phys_tblock_id_6829 = get_tblock_id(0);
    iterations_6830 = sdiv_up32(sext_i64_i32(sdiv_up64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820))) - phys_tblock_id_6829, sext_i64_i32(num_tblocks_6651));
    for (int32_t i_6831 = 0; i_6831 < iterations_6830; i_6831++) {
        int32_t virt_tblock_id_6832;
        int64_t slice_6833;
        int64_t gtid_6654;
        int64_t remnant_6834;
        int64_t gtid_6655;
        
        virt_tblock_id_6832 = phys_tblock_id_6829 + i_6831 * sext_i64_i32(num_tblocks_6651);
        slice_6833 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188;
        gtid_6654 = squot64(sext_i32_i64(local_tid_6823), segment_sizze_nonzzero_6820) + sext_i32_i64(virt_tblock_id_6832) * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820);
        remnant_6834 = squot64(sext_i32_i64(local_tid_6823), segment_sizze_nonzzero_6820) + sext_i32_i64(virt_tblock_id_6832) * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820) - gtid_6654;
        gtid_6655 = srem64(sext_i32_i64(local_tid_6823), (int64_t) 256);
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, (int64_t) 256) && (slt64(gtid_6654, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188) && slt64(sext_i32_i64(local_tid_6823), (int64_t) 256 * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820)))) {
                // apply map function
                {
                    int64_t binop_y_6710 = add64((int64_t) 1, gtid_6654);
                    int64_t binop_x_6711 = mul64(chunk_sizze_6041, binop_y_6710);
                    int64_t binop_y_6714 = mul64(chunk_sizze_6041, gtid_6654);
                    int64_t convop_x_6715 = sub64(binop_x_6711, binop_y_6714);
                    float index_primexp_6716 = sitofp_i64_f32(convop_x_6715);
                    int64_t eta_p_6662 = ((__global int64_t *) mem_6763)[gtid_6654 + gtid_6655 * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188];
                    float i64_res_6663 = sitofp_i64_f32(eta_p_6662);
                    float lifted_lambda_res_6664 = i64_res_6663 / index_primexp_6716;
                    bool cond_6665 = lifted_lambda_res_6664 == 0.0F;
                    float lifted_lambda_res_6666;
                    
                    if (cond_6665) {
                        lifted_lambda_res_6666 = 0.0F;
                    } else {
                        float log2_res_6667 = futrts_log2_32(lifted_lambda_res_6664);
                        float lifted_lambda_res_f_res_6668 = lifted_lambda_res_6664 * log2_res_6667;
                        
                        lifted_lambda_res_6666 = lifted_lambda_res_f_res_6668;
                    }
                    // save results to be reduced
                    {
                        ((__local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = lifted_lambda_res_6666;
                    }
                }
            } else {
                ((__local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = 0.0F;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, (int64_t) 256)) {
            // perform segmented scan to imitate reduction
            {
                float eta_p_6657;
                float eta_p_6658;
                float eta_p_6835;
                float eta_p_6836;
                bool ltid_in_bounds_6838 = slt64(sext_i32_i64(local_tid_6823), (int64_t) 256 * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820));
                int32_t skip_threads_6839;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_6838) {
                        eta_p_6658 = ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)];
                        if ((local_tid_6823 - squot32(local_tid_6823, 32) * 32) == 0) {
                            eta_p_6657 = eta_p_6658;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_6839 = 1;
                    while (slt32(skip_threads_6839, 32)) {
                        bool thread_active_6840 = sle32(skip_threads_6839, local_tid_6823 - squot32(local_tid_6823, 32) * 32) && ltid_in_bounds_6838;
                        
                        if (thread_active_6840) {
                            // read operands
                            {
                                eta_p_6657 = ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823) - sext_i32_i64(skip_threads_6839)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_6841 = slt64(srem64(sext_i32_i64(local_tid_6823), (int64_t) 256), sext_i32_i64(local_tid_6823) - sext_i32_i64(local_tid_6823 - skip_threads_6839));
                            
                            if (thread_active_6840 && inactive_6841) {
                                eta_p_6657 = eta_p_6658;
                            }
                            if (thread_active_6840) {
                                if (!inactive_6841) {
                                    float defunc_0_op_res_6659 = eta_p_6657 + eta_p_6658;
                                    
                                    eta_p_6657 = defunc_0_op_res_6659;
                                }
                            }
                        }
                        if (sle32(wave_sizze_6825, skip_threads_6839)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_6840) {
                            // write result
                            {
                                ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = eta_p_6657;
                                eta_p_6658 = eta_p_6657;
                            }
                        }
                        if (sle32(wave_sizze_6825, skip_threads_6839)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_6839 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_6823 - squot32(local_tid_6823, 32) * 32) == 31 && ltid_in_bounds_6838) {
                        ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(squot32(local_tid_6823, 32))] = eta_p_6657;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_6842;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_6823, 32) == 0 && ltid_in_bounds_6838) {
                            eta_p_6836 = ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)];
                            if ((local_tid_6823 - squot32(local_tid_6823, 32) * 32) == 0) {
                                eta_p_6835 = eta_p_6836;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_6842 = 1;
                        while (slt32(skip_threads_6842, 32)) {
                            bool thread_active_6843 = sle32(skip_threads_6842, local_tid_6823 - squot32(local_tid_6823, 32) * 32) && (squot32(local_tid_6823, 32) == 0 && ltid_in_bounds_6838);
                            
                            if (thread_active_6843) {
                                // read operands
                                {
                                    eta_p_6835 = ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823) - sext_i32_i64(skip_threads_6842)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_6844 = slt64(srem64(sext_i32_i64(local_tid_6823 * 32 + 32 - 1), (int64_t) 256), sext_i32_i64(local_tid_6823 * 32 + 32 - 1) - sext_i32_i64((local_tid_6823 - skip_threads_6842) * 32 + 32 - 1));
                                
                                if (thread_active_6843 && inactive_6844) {
                                    eta_p_6835 = eta_p_6836;
                                }
                                if (thread_active_6843) {
                                    if (!inactive_6844) {
                                        float defunc_0_op_res_6837 = eta_p_6835 + eta_p_6836;
                                        
                                        eta_p_6835 = defunc_0_op_res_6837;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_6825, skip_threads_6842)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_6843) {
                                // write result
                                {
                                    ((volatile __local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = eta_p_6835;
                                    eta_p_6836 = eta_p_6835;
                                }
                            }
                            if (sle32(wave_sizze_6825, skip_threads_6842)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_6842 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_6845 = squot32(local_tid_6823, 32) == 0 || !ltid_in_bounds_6838;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_6845) {
                            eta_p_6658 = eta_p_6657;
                            eta_p_6657 = ((__local float *) red_arr_f32_mem_6827)[sext_i32_i64(squot32(local_tid_6823, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_6846 = slt64(srem64(sext_i32_i64(local_tid_6823), (int64_t) 256), sext_i32_i64(local_tid_6823) - sext_i32_i64(squot32(local_tid_6823, 32) * 32 - 1));
                        
                        if (!no_carry_in_6845) {
                            if (inactive_6846) {
                                eta_p_6657 = eta_p_6658;
                            }
                        }
                        if (!no_carry_in_6845) {
                            if (!inactive_6846) {
                                float defunc_0_op_res_6659 = eta_p_6657 + eta_p_6658;
                                
                                eta_p_6657 = defunc_0_op_res_6659;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_6845) {
                            ((__local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = eta_p_6657;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_6823, 32) == 0 && ltid_in_bounds_6838) {
                        ((__local float *) red_arr_f32_mem_6827)[sext_i32_i64(local_tid_6823)] = eta_p_6658;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_tblock_id_6832) * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820) + sext_i32_i64(local_tid_6823), dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188) && slt64(sext_i32_i64(local_tid_6823), squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820))) {
                float tmp_6847 = ((__local float *) red_arr_f32_mem_6827)[(sext_i32_i64(local_tid_6823) + (int64_t) 1) * segment_sizze_nonzzero_6820 - (int64_t) 1];
                
                ((__global float *) mem_6766)[sext_i32_i64(virt_tblock_id_6832) * squot64(segred_tblock_sizze_6650, segment_sizze_nonzzero_6820) + sext_i32_i64(local_tid_6823)] = tmp_6847;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_3:
    return;
    #undef segred_tblock_sizze_6650
}
FUTHARK_KERNEL_SIZED(entropyziseghist_global_6318_dim1, 1, 1)
void entropyziseghist_global_6318(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t n_5903, int64_t num_tblocks_6313, int64_t num_subhistos_6801, int32_t chk_i_6871, int64_t hist_H_chk_6872, __global unsigned char *xs_mem_6743, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define seghist_tblock_sizze_6311 (entropyziseghist_global_6318ziseghist_tblock_sizze_6311)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6874;
    int32_t tblock_sizze_6877;
    int32_t wave_sizze_6876;
    int32_t block_id_6875;
    int32_t global_tid_6873;
    int64_t phys_tid_6318;
    int32_t subhisto_ind_6878;
    int64_t num_chunks_6879;
    
    local_tid_6874 = get_local_id(0);
    tblock_sizze_6877 = get_local_size(0);
    wave_sizze_6876 = LOCKSTEP_WIDTH;
    block_id_6875 = get_tblock_id(0);
    global_tid_6873 = block_id_6875 * tblock_sizze_6877 + local_tid_6874;
    phys_tid_6318 = sext_i32_i64(global_tid_6873);
    subhisto_ind_6878 = squot32(global_tid_6873, sdiv_up32(sext_i64_i32(seghist_tblock_sizze_6311 * num_tblocks_6313), sext_i64_i32(num_subhistos_6801)));
    num_chunks_6879 = sdiv_up64(n_5903, sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_6311 * num_tblocks_6313)));
    for (int64_t chunk_i_6880 = 0; chunk_i_6880 < num_chunks_6879; chunk_i_6880++) {
        int64_t i_6881 = chunk_i_6880 * sext_i32_i64(sext_i64_i32(seghist_tblock_sizze_6311 * num_tblocks_6313)) + sext_i32_i64(global_tid_6873);
        
        if (slt64(i_6881, n_5903)) {
            int64_t slice_6882;
            int64_t gtid_6317;
            int64_t remnant_6883;
            
            slice_6882 = n_5903;
            gtid_6317 = i_6881;
            remnant_6883 = i_6881 - gtid_6317;
            if (slt64(i_6881, n_5903)) {
                int8_t eta_p_6322;
                int64_t u8_res_6324;
                
                eta_p_6322 = ((__global int8_t *) xs_mem_6743)[gtid_6317];
                u8_res_6324 = zext_i8_i64(eta_p_6322);
                // save map-out results
                { }
                // perform atomic updates
                {
                    if (sle64(sext_i32_i64(chk_i_6871) * hist_H_chk_6872, u8_res_6324) && (slt64(u8_res_6324, sext_i32_i64(chk_i_6871) * hist_H_chk_6872 + hist_H_chk_6872) && (sle64((int64_t) 0, u8_res_6324) && slt64(u8_res_6324, (int64_t) 256)))) {
                        int64_t eta_p_6319;
                        int64_t eta_p_6320 = (int64_t) 1;
                        int64_t old_6884;
                        
                        old_6884 = atomic_add_i64_global(&((volatile __global int64_t *) defunc_0_map_res_subhistos_mem_6802)[sext_i32_i64(subhisto_ind_6878) * (int64_t) 256 + u8_res_6324], (int64_t) eta_p_6320);
                    }
                }
            }
        }
    }
    
  error_0:
    return;
    #undef seghist_tblock_sizze_6311
}
FUTHARK_KERNEL_SIZED(entropyziseghist_local_6318_dim1, 1, 1)
void entropyziseghist_local_6318(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t n_5903, int64_t num_subhistos_6801, int64_t num_tblocks_6812, int32_t hist_M_6818, int32_t chk_i_6822, int64_t num_segments_6823, int64_t hist_H_chk_6824, int64_t histo_sizze_6825, int32_t init_per_thread_6826, __global unsigned char *xs_mem_6743, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define max_tblock_sizze_6811 (entropyziseghist_local_6318zimax_tblock_sizze_6811)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *subhistogram_local_mem_6840_backing_0 = &shared_mem[0];
    const int64_t subhistogram_local_mem_6840_backing_0_offset = 0 + ((int64_t) 8 * (hist_M_6818 * hist_H_chk_6824) + srem64((int64_t) 8 - srem64((int64_t) 8 * (hist_M_6818 * hist_H_chk_6824), (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6828;
    int32_t tblock_sizze_6831;
    int32_t wave_sizze_6830;
    int32_t block_id_6829;
    int32_t global_tid_6827;
    int64_t phys_tid_6318;
    int32_t phys_tblock_id_6832;
    int32_t iterations_6833;
    
    local_tid_6828 = get_local_id(0);
    tblock_sizze_6831 = get_local_size(0);
    wave_sizze_6830 = LOCKSTEP_WIDTH;
    block_id_6829 = get_tblock_id(0);
    global_tid_6827 = block_id_6829 * tblock_sizze_6831 + local_tid_6828;
    phys_tid_6318 = sext_i32_i64(global_tid_6827);
    phys_tblock_id_6832 = get_tblock_id(0);
    iterations_6833 = sdiv_up32(sext_i64_i32(num_tblocks_6812 * num_segments_6823) - phys_tblock_id_6832, sext_i64_i32(num_tblocks_6812));
    for (int32_t i_6834 = 0; i_6834 < iterations_6833; i_6834++) {
        int32_t virt_tblock_id_6835;
        int32_t flat_segment_id_6836;
        int32_t gid_in_segment_6837;
        int32_t pgtid_in_segment_6838;
        int32_t threads_per_segment_6839;
        __local unsigned char *subhistogram_local_mem_6840;
        int32_t thread_local_subhisto_i_6842;
        int64_t num_chunks_6849;
        
        virt_tblock_id_6835 = phys_tblock_id_6832 + i_6834 * sext_i64_i32(num_tblocks_6812);
        flat_segment_id_6836 = squot32(virt_tblock_id_6835, sext_i64_i32(num_tblocks_6812));
        gid_in_segment_6837 = srem32(virt_tblock_id_6835, sext_i64_i32(num_tblocks_6812));
        pgtid_in_segment_6838 = gid_in_segment_6837 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
        threads_per_segment_6839 = sext_i64_i32(num_tblocks_6812 * max_tblock_sizze_6811);
        subhistogram_local_mem_6840 = (__local unsigned char *) subhistogram_local_mem_6840_backing_0;
        thread_local_subhisto_i_6842 = srem32(local_tid_6828, hist_M_6818);
        // initialize histograms in shared memory
        {
            for (int32_t local_i_6843 = 0; local_i_6843 < init_per_thread_6826; local_i_6843++) {
                int32_t j_6844 = local_i_6843 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
                int32_t j_offset_6845 = hist_M_6818 * sext_i64_i32(histo_sizze_6825) * gid_in_segment_6837 + j_6844;
                int32_t local_subhisto_i_6846 = squot32(j_6844, sext_i64_i32(histo_sizze_6825));
                int32_t global_subhisto_i_6847 = squot32(j_offset_6845, sext_i64_i32(histo_sizze_6825));
                
                if (slt32(j_6844, hist_M_6818 * sext_i64_i32(histo_sizze_6825))) {
                    // First subhistogram is initialised from global memory; others with neutral element.
                    {
                        if (global_subhisto_i_6847 == 0 && ((sle64((int64_t) 0, (int64_t) 0) && slt64((int64_t) 0, num_subhistos_6801)) && (sle64((int64_t) 0, sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824) && slt64(sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824, (int64_t) 256)))) {
                            int64_t tmp_6848 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825))) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824];
                            
                            ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(local_subhisto_i_6846) * hist_H_chk_6824 + sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825)))] = tmp_6848;
                        } else {
                            ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(local_subhisto_i_6846) * hist_H_chk_6824 + sext_i32_i64(srem32(j_6844, sext_i64_i32(histo_sizze_6825)))] = (int64_t) 0;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        num_chunks_6849 = sdiv_up64(n_5903, sext_i32_i64(threads_per_segment_6839));
        for (int64_t chunk_i_6850 = 0; chunk_i_6850 < num_chunks_6849; chunk_i_6850++) {
            int64_t i_6851 = chunk_i_6850 * sext_i32_i64(threads_per_segment_6839) + sext_i32_i64(pgtid_in_segment_6838);
            
            if (slt64(i_6851, n_5903)) {
                int64_t gtid_6317;
                int8_t eta_p_6322;
                int64_t u8_res_6324;
                
                gtid_6317 = i_6851;
                eta_p_6322 = ((__global int8_t *) xs_mem_6743)[gtid_6317];
                u8_res_6324 = zext_i8_i64(eta_p_6322);
                if (chk_i_6822 == 0) {
                    // save map-out results
                    { }
                }
                // perform atomic updates
                {
                    if ((sle64((int64_t) 0, u8_res_6324) && slt64(u8_res_6324, (int64_t) 256)) && (sle64(sext_i32_i64(chk_i_6822) * hist_H_chk_6824, u8_res_6324) && slt64(u8_res_6324, sext_i32_i64(chk_i_6822) * hist_H_chk_6824 + hist_H_chk_6824))) {
                        int64_t eta_p_6319;
                        int64_t eta_p_6320 = (int64_t) 1;
                        int64_t old_6852;
                        
                        old_6852 = atomic_add_i64_shared(&((volatile __local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(thread_local_subhisto_i_6842) * hist_H_chk_6824 + (u8_res_6324 - sext_i32_i64(chk_i_6822) * hist_H_chk_6824)], (int64_t) eta_p_6320);
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
        // Compact the multiple shared memory subhistograms to result in global memory
        {
            int64_t trunc_H_6853 = smin64(hist_H_chk_6824, (int64_t) 256 - sext_i32_i64(chk_i_6822) * hist_H_chk_6824);
            int32_t histo_sizze_6854 = sext_i64_i32(trunc_H_6853);
            
            for (int32_t local_i_6855 = 0; local_i_6855 < init_per_thread_6826; local_i_6855++) {
                int32_t j_6856 = local_i_6855 * sext_i64_i32(max_tblock_sizze_6811) + local_tid_6828;
                
                if (slt32(j_6856, histo_sizze_6854)) {
                    int64_t eta_p_6319;
                    int64_t eta_p_6320;
                    
                    // Read values from subhistogram 0.
                    {
                        eta_p_6319 = ((__local int64_t *) subhistogram_local_mem_6840)[sext_i32_i64(j_6856)];
                    }
                    // Accumulate based on values in other subhistograms.
                    {
                        for (int32_t subhisto_id_6857 = 0; subhisto_id_6857 < hist_M_6818 - 1; subhisto_id_6857++) {
                            eta_p_6320 = ((__local int64_t *) subhistogram_local_mem_6840)[(sext_i32_i64(subhisto_id_6857) + (int64_t) 1) * hist_H_chk_6824 + sext_i32_i64(j_6856)];
                            
                            int64_t defunc_0_op_res_6321 = add64(eta_p_6319, eta_p_6320);
                            
                            eta_p_6319 = defunc_0_op_res_6321;
                        }
                    }
                    // Put final bucket value in global memory.
                    {
                        ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[srem64(sext_i32_i64(virt_tblock_id_6835), num_tblocks_6812) * (int64_t) 256 + (sext_i32_i64(j_6856) + sext_i32_i64(chk_i_6822) * hist_H_chk_6824)] = eta_p_6319;
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_2:
    return;
    #undef max_tblock_sizze_6811
}
FUTHARK_KERNEL_SIZED(entropyzisegred_large_6887_dim1, 1, 1)
void entropyzisegred_large_6887(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_tblocks_6313, int64_t num_subhistos_6801, int64_t blocks_per_segment_6918, int64_t q_6919, int64_t num_virtblocks_6920, int64_t threads_per_segment_6921, __global unsigned char *mem_6744, __global unsigned char *defunc_0_map_res_subhistos_mem_6802, __global unsigned char *segred_tmp_mem_6922, __global unsigned char *counters_mem_6924)
{
    #define seghist_tblock_sizze_6311 (entropyzisegred_large_6887ziseghist_tblock_sizze_6311)
    #define chunk_sizze_6888 (entropyzisegred_large_6887zichunk_sizze_6888)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *sync_arr_mem_6953_backing_1 = &shared_mem[0];
    const int64_t sync_arr_mem_6953_backing_1_offset = 0 + 8;
    volatile __local unsigned char *red_arr_i64_mem_6951_backing_0 = &shared_mem[sync_arr_mem_6953_backing_1_offset];
    const int64_t red_arr_i64_mem_6951_backing_0_offset = sync_arr_mem_6953_backing_1_offset + ((int64_t) 8 * seghist_tblock_sizze_6311 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_6311, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6947;
    int32_t tblock_sizze_6950;
    int32_t wave_sizze_6949;
    int32_t block_id_6948;
    int32_t global_tid_6946;
    int64_t flat_gtid_6887;
    __local unsigned char *red_arr_i64_mem_6951;
    __local unsigned char *sync_arr_mem_6953;
    int32_t phys_tblock_id_6955;
    int32_t iterations_6956;
    
    local_tid_6947 = get_local_id(0);
    tblock_sizze_6950 = get_local_size(0);
    wave_sizze_6949 = LOCKSTEP_WIDTH;
    block_id_6948 = get_tblock_id(0);
    global_tid_6946 = block_id_6948 * tblock_sizze_6950 + local_tid_6947;
    flat_gtid_6887 = sext_i32_i64(global_tid_6946);
    red_arr_i64_mem_6951 = (__local unsigned char *) red_arr_i64_mem_6951_backing_0;
    sync_arr_mem_6953 = (__local unsigned char *) sync_arr_mem_6953_backing_1;
    phys_tblock_id_6955 = get_tblock_id(0);
    iterations_6956 = sdiv_up32(sext_i64_i32(num_virtblocks_6920) - phys_tblock_id_6955, sext_i64_i32(num_tblocks_6313));
    for (int32_t i_6957 = 0; i_6957 < iterations_6956; i_6957++) {
        int32_t virt_tblock_id_6958;
        int64_t flat_segment_id_6959;
        int64_t global_tid_6960;
        int64_t slice_6961;
        int64_t bucket_id_6885;
        int64_t remnant_6962;
        int64_t subhistogram_id_6886;
        int64_t eta_p_block_res_acc_6963;
        int64_t eta_p_6319;
        int64_t eta_p_6320;
        int64_t tblock_id_in_segment_6967;
        int64_t block_base_offset_6968;
        int32_t offset_6971;
        int32_t skip_waves_6972;
        int64_t eta_p_6964;
        int64_t eta_p_6965;
        
        virt_tblock_id_6958 = phys_tblock_id_6955 + i_6957 * sext_i64_i32(num_tblocks_6313);
        flat_segment_id_6959 = squot64(sext_i32_i64(virt_tblock_id_6958), blocks_per_segment_6918);
        global_tid_6960 = srem64(sext_i32_i64(virt_tblock_id_6958) * seghist_tblock_sizze_6311 + sext_i32_i64(local_tid_6947), threads_per_segment_6921);
        slice_6961 = (int64_t) 256;
        bucket_id_6885 = flat_segment_id_6959;
        remnant_6962 = flat_segment_id_6959 - bucket_id_6885;
        // ne-initialise the outer (per-block) accumulator(s)
        {
            eta_p_block_res_acc_6963 = (int64_t) 0;
        }
        tblock_id_in_segment_6967 = squot64(global_tid_6960, seghist_tblock_sizze_6311);
        block_base_offset_6968 = tblock_id_in_segment_6967 * q_6919 * seghist_tblock_sizze_6311;
        for (int64_t i_6969 = 0; i_6969 < q_6919; i_6969++) {
            int64_t block_offset_6970 = block_base_offset_6968 + i_6969 * seghist_tblock_sizze_6311;
            
            subhistogram_id_6886 = global_tid_6960 + threads_per_segment_6921 * i_6969;
            if (slt64(subhistogram_id_6886, num_subhistos_6801)) {
                // apply map function(s)
                {
                    // load accumulator(s)
                    {
                        eta_p_6319 = eta_p_block_res_acc_6963;
                    }
                    // load next value(s)
                    {
                        eta_p_6320 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[subhistogram_id_6886 * (int64_t) 256 + bucket_id_6885];
                    }
                    // apply reduction operator(s)
                    {
                        int64_t defunc_0_op_res_6321 = add64(eta_p_6319, eta_p_6320);
                        
                        // store in accumulator(s)
                        {
                            eta_p_block_res_acc_6963 = defunc_0_op_res_6321;
                        }
                    }
                }
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // store accs. prims go in lmem; non-prims in params (in global mem)
        {
            ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_block_res_acc_6963;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        skip_waves_6972 = 1;
        offset_6971 = 0;
        // participating threads read initial accumulator
        {
            if (slt32(local_tid_6947, sext_i64_i32(seghist_tblock_sizze_6311))) {
                eta_p_6964 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
            }
        }
        offset_6971 = 1;
        while (slt32(offset_6971, wave_sizze_6949)) {
            if (slt32(local_tid_6947 + offset_6971, sext_i64_i32(seghist_tblock_sizze_6311)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) & (2 * offset_6971 - 1)) == 0) {
                // read array element
                {
                    eta_p_6965 = ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
                }
                // apply reduction operation
                {
                    int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                    
                    eta_p_6964 = defunc_0_op_res_6966;
                }
                // write result of operation
                {
                    ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                }
            }
            offset_6971 *= 2;
        }
        while (slt32(skip_waves_6972, squot32(sext_i64_i32(seghist_tblock_sizze_6311) + wave_sizze_6949 - 1, wave_sizze_6949))) {
            barrier(CLK_LOCAL_MEM_FENCE);
            offset_6971 = skip_waves_6972 * wave_sizze_6949;
            if (slt32(local_tid_6947 + offset_6971, sext_i64_i32(seghist_tblock_sizze_6311)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) == 0 && (squot32(local_tid_6947, wave_sizze_6949) & (2 * skip_waves_6972 - 1)) == 0)) {
                // read array element
                {
                    eta_p_6965 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6971)];
                }
                // apply reduction operation
                {
                    int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                    
                    eta_p_6964 = defunc_0_op_res_6966;
                }
                // write result of operation
                {
                    ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                }
            }
            skip_waves_6972 *= 2;
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_LOCAL_MEM_FENCE);
        // thread 0 updates per-block acc(s); rest reset to ne
        {
            if (sext_i32_i64(local_tid_6947) == (int64_t) 0) {
                eta_p_block_res_acc_6963 = eta_p_6964;
            } else {
                eta_p_block_res_acc_6963 = (int64_t) 0;
            }
        }
        if (blocks_per_segment_6918 == (int64_t) 1) {
            // first thread in block saves final result to memory
            {
                if (local_tid_6947 == 0) {
                    ((__global int64_t *) mem_6744)[bucket_id_6885] = eta_p_block_res_acc_6963;
                }
            }
        } else {
            int32_t old_counter_6973;
            bool is_last_block_6974;
            
            // first thread in block saves block result to global memory
            {
                if (local_tid_6947 == 0) {
                    ((__global int64_t *) segred_tmp_mem_6922)[sext_i32_i64(virt_tblock_id_6958)] = eta_p_block_res_acc_6963;
                    mem_fence_global();
                    old_counter_6973 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6924)[srem64(flat_segment_id_6959, (int64_t) 20480)], (int) 1);
                    ((__local bool *) sync_arr_mem_6953)[(int64_t) 0] = old_counter_6973 == sext_i64_i32(blocks_per_segment_6918 - (int64_t) 1);
                }
            }
            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
            is_last_block_6974 = ((__local bool *) sync_arr_mem_6953)[(int64_t) 0];
            if (is_last_block_6974) {
                if (local_tid_6947 == 0) {
                    old_counter_6973 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6924)[srem64(flat_segment_id_6959, (int64_t) 20480)], (int) sext_i64_i32((int64_t) 0 - blocks_per_segment_6918));
                }
                // read in the per-block-results
                {
                    int64_t read_per_thread_6975 = sdiv_up64(blocks_per_segment_6918, seghist_tblock_sizze_6311);
                    
                    eta_p_6319 = (int64_t) 0;
                    for (int64_t i_6976 = 0; i_6976 < read_per_thread_6975; i_6976++) {
                        int64_t block_res_id_6977 = sext_i32_i64(local_tid_6947) * read_per_thread_6975 + i_6976;
                        int64_t index_of_block_res_6978 = flat_segment_id_6959 * blocks_per_segment_6918 + block_res_id_6977;
                        
                        if (slt64(block_res_id_6977, blocks_per_segment_6918)) {
                            eta_p_6320 = ((__global int64_t *) segred_tmp_mem_6922)[index_of_block_res_6978];
                            
                            int64_t defunc_0_op_res_6321 = add64(eta_p_6319, eta_p_6320);
                            
                            eta_p_6319 = defunc_0_op_res_6321;
                        }
                    }
                }
                ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6319;
                barrier(CLK_LOCAL_MEM_FENCE);
                // reduce the per-block results
                {
                    int32_t offset_6979;
                    int32_t skip_waves_6980 = 1;
                    int64_t eta_p_6964;
                    int64_t eta_p_6965;
                    
                    offset_6979 = 0;
                    // participating threads read initial accumulator
                    {
                        if (slt32(local_tid_6947, sext_i64_i32(seghist_tblock_sizze_6311))) {
                            eta_p_6964 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                        }
                    }
                    offset_6979 = 1;
                    while (slt32(offset_6979, wave_sizze_6949)) {
                        if (slt32(local_tid_6947 + offset_6979, sext_i64_i32(seghist_tblock_sizze_6311)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) & (2 * offset_6979 - 1)) == 0) {
                            // read array element
                            {
                                eta_p_6965 = ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                                
                                eta_p_6964 = defunc_0_op_res_6966;
                            }
                            // write result of operation
                            {
                                ((volatile __local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                            }
                        }
                        offset_6979 *= 2;
                    }
                    while (slt32(skip_waves_6980, squot32(sext_i64_i32(seghist_tblock_sizze_6311) + wave_sizze_6949 - 1, wave_sizze_6949))) {
                        barrier(CLK_LOCAL_MEM_FENCE);
                        offset_6979 = skip_waves_6980 * wave_sizze_6949;
                        if (slt32(local_tid_6947 + offset_6979, sext_i64_i32(seghist_tblock_sizze_6311)) && ((local_tid_6947 - squot32(local_tid_6947, wave_sizze_6949) * wave_sizze_6949) == 0 && (squot32(local_tid_6947, wave_sizze_6949) & (2 * skip_waves_6980 - 1)) == 0)) {
                            // read array element
                            {
                                eta_p_6965 = ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947 + offset_6979)];
                            }
                            // apply reduction operation
                            {
                                int64_t defunc_0_op_res_6966 = add64(eta_p_6964, eta_p_6965);
                                
                                eta_p_6964 = defunc_0_op_res_6966;
                            }
                            // write result of operation
                            {
                                ((__local int64_t *) red_arr_i64_mem_6951)[sext_i32_i64(local_tid_6947)] = eta_p_6964;
                            }
                        }
                        skip_waves_6980 *= 2;
                    }
                    barrier(CLK_LOCAL_MEM_FENCE);
                    // and back to memory with the final result
                    {
                        if (local_tid_6947 == 0) {
                            ((__global int64_t *) mem_6744)[bucket_id_6885] = eta_p_6964;
                        }
                    }
                }
            }
        }
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_6:
    return;
    #undef seghist_tblock_sizze_6311
    #undef chunk_sizze_6888
}
FUTHARK_KERNEL_SIZED(entropyzisegred_nonseg_6334_dim1, 1, 1)
void entropyzisegred_nonseg_6334(__local uint64_t *shared_mem_aligned, __global int *global_failure, float i64_res_6244, int64_t num_tblocks_6329, int64_t num_threads_6987, __global unsigned char *mem_6744, __global unsigned char *mem_6747, __global unsigned char *counters_mem_6983, __global unsigned char *segred_tmp_mem_6985)
{
    #define segred_tblock_sizze_6327 (entropyzisegred_nonseg_6334zisegred_tblock_sizze_6327)
    #define chunk_sizze_6982 (entropyzisegred_nonseg_6334zichunk_sizze_6982)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *sync_arr_mem_6995_backing_1 = &shared_mem[0];
    const int64_t sync_arr_mem_6995_backing_1_offset = 0 + 8;
    volatile __local unsigned char *red_arr_f32_mem_6993_backing_0 = &shared_mem[sync_arr_mem_6995_backing_1_offset];
    const int64_t red_arr_f32_mem_6993_backing_0_offset = sync_arr_mem_6995_backing_1_offset + ((int64_t) 4 * segred_tblock_sizze_6327 + srem64((int64_t) 8 - srem64((int64_t) 4 * segred_tblock_sizze_6327, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6989;
    int32_t tblock_sizze_6992;
    int32_t wave_sizze_6991;
    int32_t block_id_6990;
    int32_t global_tid_6988;
    int64_t phys_tid_6334;
    __local unsigned char *red_arr_f32_mem_6993;
    __local unsigned char *sync_arr_mem_6995;
    int64_t dummy_6332;
    int64_t gtid_6333;
    int64_t q_6997;
    float eta_p_block_res_acc_6998;
    float eta_p_6256;
    float eta_p_6257;
    int64_t tblock_id_in_segment_7002;
    int64_t block_base_offset_7003;
    int32_t offset_7006;
    int32_t skip_waves_7007;
    float eta_p_6999;
    float eta_p_7000;
    int32_t old_counter_7008;
    bool is_last_block_7009;
    
    local_tid_6989 = get_local_id(0);
    tblock_sizze_6992 = get_local_size(0);
    wave_sizze_6991 = LOCKSTEP_WIDTH;
    block_id_6990 = get_tblock_id(0);
    global_tid_6988 = block_id_6990 * tblock_sizze_6992 + local_tid_6989;
    phys_tid_6334 = sext_i32_i64(global_tid_6988);
    red_arr_f32_mem_6993 = (__local unsigned char *) red_arr_f32_mem_6993_backing_0;
    sync_arr_mem_6995 = (__local unsigned char *) sync_arr_mem_6995_backing_1;
    dummy_6332 = (int64_t) 0;
    gtid_6333 = (int64_t) 0;
    q_6997 = sdiv_up64((int64_t) 256, sext_i32_i64(sext_i64_i32(segred_tblock_sizze_6327 * num_tblocks_6329)) * chunk_sizze_6982);
    // ne-initialise the outer (per-block) accumulator(s)
    {
        eta_p_block_res_acc_6998 = 0.0F;
    }
    tblock_id_in_segment_7002 = squot64(phys_tid_6334, segred_tblock_sizze_6327);
    block_base_offset_7003 = tblock_id_in_segment_7002 * q_6997 * segred_tblock_sizze_6327;
    for (int64_t i_7004 = 0; i_7004 < q_6997; i_7004++) {
        int64_t block_offset_7005 = block_base_offset_7003 + i_7004 * segred_tblock_sizze_6327;
        
        gtid_6333 = phys_tid_6334 + num_threads_6987 * i_7004;
        if (slt64(gtid_6333, (int64_t) 256)) {
            // apply map function(s)
            {
                // apply map function
                {
                    int64_t eta_p_6272 = ((__global int64_t *) mem_6744)[gtid_6333];
                    float i64_res_6273 = sitofp_i64_f32(eta_p_6272);
                    float lifted_lambda_res_6274 = i64_res_6273 / i64_res_6244;
                    bool cond_6276 = lifted_lambda_res_6274 == 0.0F;
                    float lifted_lambda_res_6277;
                    
                    if (cond_6276) {
                        lifted_lambda_res_6277 = 0.0F;
                    } else {
                        float log2_res_6278 = futrts_log2_32(lifted_lambda_res_6274);
                        float lifted_lambda_res_f_res_6279 = lifted_lambda_res_6274 * log2_res_6278;
                        
                        lifted_lambda_res_6277 = lifted_lambda_res_f_res_6279;
                    }
                    // load accumulator(s)
                    {
                        eta_p_6256 = eta_p_block_res_acc_6998;
                    }
                    // load next value(s)
                    {
                        eta_p_6257 = lifted_lambda_res_6277;
                    }
                    // apply reduction operator(s)
                    {
                        float defunc_0_op_res_6258 = eta_p_6256 + eta_p_6257;
                        
                        // store in accumulator(s)
                        {
                            eta_p_block_res_acc_6998 = defunc_0_op_res_6258;
                        }
                    }
                }
            }
        }
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    // store accs. prims go in lmem; non-prims in params (in global mem)
    {
        ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_block_res_acc_6998;
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    skip_waves_7007 = 1;
    offset_7006 = 0;
    // participating threads read initial accumulator
    {
        if (slt32(local_tid_6989, sext_i64_i32(segred_tblock_sizze_6327))) {
            eta_p_6999 = ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7006)];
        }
    }
    offset_7006 = 1;
    while (slt32(offset_7006, wave_sizze_6991)) {
        if (slt32(local_tid_6989 + offset_7006, sext_i64_i32(segred_tblock_sizze_6327)) && ((local_tid_6989 - squot32(local_tid_6989, wave_sizze_6991) * wave_sizze_6991) & (2 * offset_7006 - 1)) == 0) {
            // read array element
            {
                eta_p_7000 = ((volatile __local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7006)];
            }
            // apply reduction operation
            {
                float defunc_0_op_res_7001 = eta_p_6999 + eta_p_7000;
                
                eta_p_6999 = defunc_0_op_res_7001;
            }
            // write result of operation
            {
                ((volatile __local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_6999;
            }
        }
        offset_7006 *= 2;
    }
    while (slt32(skip_waves_7007, squot32(sext_i64_i32(segred_tblock_sizze_6327) + wave_sizze_6991 - 1, wave_sizze_6991))) {
        barrier(CLK_LOCAL_MEM_FENCE);
        offset_7006 = skip_waves_7007 * wave_sizze_6991;
        if (slt32(local_tid_6989 + offset_7006, sext_i64_i32(segred_tblock_sizze_6327)) && ((local_tid_6989 - squot32(local_tid_6989, wave_sizze_6991) * wave_sizze_6991) == 0 && (squot32(local_tid_6989, wave_sizze_6991) & (2 * skip_waves_7007 - 1)) == 0)) {
            // read array element
            {
                eta_p_7000 = ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7006)];
            }
            // apply reduction operation
            {
                float defunc_0_op_res_7001 = eta_p_6999 + eta_p_7000;
                
                eta_p_6999 = defunc_0_op_res_7001;
            }
            // write result of operation
            {
                ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_6999;
            }
        }
        skip_waves_7007 *= 2;
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    barrier(CLK_LOCAL_MEM_FENCE);
    // thread 0 updates per-block acc(s); rest reset to ne
    {
        if (sext_i32_i64(local_tid_6989) == (int64_t) 0) {
            eta_p_block_res_acc_6998 = eta_p_6999;
        } else {
            eta_p_block_res_acc_6998 = 0.0F;
        }
    }
    // first thread in block saves block result to global memory
    {
        if (local_tid_6989 == 0) {
            ((__global float *) segred_tmp_mem_6985)[sext_i32_i64(block_id_6990)] = eta_p_block_res_acc_6998;
            mem_fence_global();
            old_counter_7008 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6983)[(int64_t) 0], (int) 1);
            ((__local bool *) sync_arr_mem_6995)[(int64_t) 0] = old_counter_7008 == sext_i64_i32(num_tblocks_6329 - (int64_t) 1);
        }
    }
    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    is_last_block_7009 = ((__local bool *) sync_arr_mem_6995)[(int64_t) 0];
    if (is_last_block_7009) {
        if (local_tid_6989 == 0) {
            old_counter_7008 = atomic_add_i32_global(&((volatile __global int *) counters_mem_6983)[(int64_t) 0], (int) sext_i64_i32((int64_t) 0 - num_tblocks_6329));
        }
        // read in the per-block-results
        {
            int64_t read_per_thread_7010 = sdiv_up64(num_tblocks_6329, segred_tblock_sizze_6327);
            
            eta_p_6256 = 0.0F;
            for (int64_t i_7011 = 0; i_7011 < read_per_thread_7010; i_7011++) {
                int64_t block_res_id_7012 = sext_i32_i64(local_tid_6989) * read_per_thread_7010 + i_7011;
                int64_t index_of_block_res_7013 = block_res_id_7012;
                
                if (slt64(block_res_id_7012, num_tblocks_6329)) {
                    eta_p_6257 = ((__global float *) segred_tmp_mem_6985)[index_of_block_res_7013];
                    
                    float defunc_0_op_res_6258 = eta_p_6256 + eta_p_6257;
                    
                    eta_p_6256 = defunc_0_op_res_6258;
                }
            }
        }
        ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_6256;
        barrier(CLK_LOCAL_MEM_FENCE);
        // reduce the per-block results
        {
            int32_t offset_7014;
            int32_t skip_waves_7015 = 1;
            float eta_p_6999;
            float eta_p_7000;
            
            offset_7014 = 0;
            // participating threads read initial accumulator
            {
                if (slt32(local_tid_6989, sext_i64_i32(segred_tblock_sizze_6327))) {
                    eta_p_6999 = ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7014)];
                }
            }
            offset_7014 = 1;
            while (slt32(offset_7014, wave_sizze_6991)) {
                if (slt32(local_tid_6989 + offset_7014, sext_i64_i32(segred_tblock_sizze_6327)) && ((local_tid_6989 - squot32(local_tid_6989, wave_sizze_6991) * wave_sizze_6991) & (2 * offset_7014 - 1)) == 0) {
                    // read array element
                    {
                        eta_p_7000 = ((volatile __local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7014)];
                    }
                    // apply reduction operation
                    {
                        float defunc_0_op_res_7001 = eta_p_6999 + eta_p_7000;
                        
                        eta_p_6999 = defunc_0_op_res_7001;
                    }
                    // write result of operation
                    {
                        ((volatile __local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_6999;
                    }
                }
                offset_7014 *= 2;
            }
            while (slt32(skip_waves_7015, squot32(sext_i64_i32(segred_tblock_sizze_6327) + wave_sizze_6991 - 1, wave_sizze_6991))) {
                barrier(CLK_LOCAL_MEM_FENCE);
                offset_7014 = skip_waves_7015 * wave_sizze_6991;
                if (slt32(local_tid_6989 + offset_7014, sext_i64_i32(segred_tblock_sizze_6327)) && ((local_tid_6989 - squot32(local_tid_6989, wave_sizze_6991) * wave_sizze_6991) == 0 && (squot32(local_tid_6989, wave_sizze_6991) & (2 * skip_waves_7015 - 1)) == 0)) {
                    // read array element
                    {
                        eta_p_7000 = ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989 + offset_7014)];
                    }
                    // apply reduction operation
                    {
                        float defunc_0_op_res_7001 = eta_p_6999 + eta_p_7000;
                        
                        eta_p_6999 = defunc_0_op_res_7001;
                    }
                    // write result of operation
                    {
                        ((__local float *) red_arr_f32_mem_6993)[sext_i32_i64(local_tid_6989)] = eta_p_6999;
                    }
                }
                skip_waves_7015 *= 2;
            }
            barrier(CLK_LOCAL_MEM_FENCE);
            // and back to memory with the final result
            {
                if (local_tid_6989 == 0) {
                    ((__global float *) mem_6747)[(int64_t) 0] = eta_p_6999;
                }
            }
        }
    }
    
  error_5:
    return;
    #undef segred_tblock_sizze_6327
    #undef chunk_sizze_6982
}
FUTHARK_KERNEL_SIZED(entropyzisegred_small_6887_dim1, 1, 1)
void entropyzisegred_small_6887(__local uint64_t *shared_mem_aligned, __global int *global_failure, int64_t num_tblocks_6313, int64_t num_subhistos_6801, int64_t segment_sizze_nonzzero_6889, __global unsigned char *mem_6744, __global unsigned char *defunc_0_map_res_subhistos_mem_6802)
{
    #define seghist_tblock_sizze_6311 (entropyzisegred_small_6887ziseghist_tblock_sizze_6311)
    
    __local unsigned char *shared_mem = (__local unsigned char *) shared_mem_aligned;
    volatile __local unsigned char *red_arr_i64_mem_6896_backing_0 = &shared_mem[0];
    const int64_t red_arr_i64_mem_6896_backing_0_offset = 0 + ((int64_t) 8 * seghist_tblock_sizze_6311 + srem64((int64_t) 8 - srem64((int64_t) 8 * seghist_tblock_sizze_6311, (int64_t) 8), (int64_t) 8));
    
    if (*global_failure >= 0)
        return;
    
    int32_t local_tid_6892;
    int32_t tblock_sizze_6895;
    int32_t wave_sizze_6894;
    int32_t block_id_6893;
    int32_t global_tid_6891;
    int64_t flat_gtid_6887;
    __local unsigned char *red_arr_i64_mem_6896;
    int32_t phys_tblock_id_6898;
    int32_t iterations_6899;
    
    local_tid_6892 = get_local_id(0);
    tblock_sizze_6895 = get_local_size(0);
    wave_sizze_6894 = LOCKSTEP_WIDTH;
    block_id_6893 = get_tblock_id(0);
    global_tid_6891 = block_id_6893 * tblock_sizze_6895 + local_tid_6892;
    flat_gtid_6887 = sext_i32_i64(global_tid_6891);
    red_arr_i64_mem_6896 = (__local unsigned char *) red_arr_i64_mem_6896_backing_0;
    phys_tblock_id_6898 = get_tblock_id(0);
    iterations_6899 = sdiv_up32(sext_i64_i32(sdiv_up64((int64_t) 256, squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889))) - phys_tblock_id_6898, sext_i64_i32(num_tblocks_6313));
    for (int32_t i_6900 = 0; i_6900 < iterations_6899; i_6900++) {
        int32_t virt_tblock_id_6901;
        int64_t slice_6902;
        int64_t bucket_id_6885;
        int64_t remnant_6903;
        int64_t subhistogram_id_6886;
        
        virt_tblock_id_6901 = phys_tblock_id_6898 + i_6900 * sext_i64_i32(num_tblocks_6313);
        slice_6902 = (int64_t) 256;
        bucket_id_6885 = squot64(sext_i32_i64(local_tid_6892), segment_sizze_nonzzero_6889) + sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889);
        remnant_6903 = squot64(sext_i32_i64(local_tid_6892), segment_sizze_nonzzero_6889) + sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889) - bucket_id_6885;
        subhistogram_id_6886 = srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801);
        // apply map function if in bounds
        {
            if (slt64((int64_t) 0, num_subhistos_6801) && (slt64(bucket_id_6885, (int64_t) 256) && slt64(sext_i32_i64(local_tid_6892), num_subhistos_6801 * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889)))) {
                // save results to be reduced
                {
                    int64_t tmp_6904 = ((__global int64_t *) defunc_0_map_res_subhistos_mem_6802)[subhistogram_id_6886 * (int64_t) 256 + bucket_id_6885];
                    
                    ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = tmp_6904;
                }
            } else {
                ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = (int64_t) 0;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        if (slt64((int64_t) 0, num_subhistos_6801)) {
            // perform segmented scan to imitate reduction
            {
                int64_t eta_p_6319;
                int64_t eta_p_6320;
                int64_t eta_p_6905;
                int64_t eta_p_6906;
                bool ltid_in_bounds_6908 = slt64(sext_i32_i64(local_tid_6892), num_subhistos_6801 * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889));
                int32_t skip_threads_6909;
                
                // read input for in-block scan
                {
                    if (ltid_in_bounds_6908) {
                        eta_p_6320 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)];
                        if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 0) {
                            eta_p_6319 = eta_p_6320;
                        }
                    }
                }
                // in-block scan (hopefully no barriers needed)
                {
                    skip_threads_6909 = 1;
                    while (slt32(skip_threads_6909, 32)) {
                        bool thread_active_6910 = sle32(skip_threads_6909, local_tid_6892 - squot32(local_tid_6892, 32) * 32) && ltid_in_bounds_6908;
                        
                        if (thread_active_6910) {
                            // read operands
                            {
                                eta_p_6319 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892) - sext_i32_i64(skip_threads_6909)];
                            }
                        }
                        // perform operation
                        {
                            bool inactive_6911 = slt64(srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801), sext_i32_i64(local_tid_6892) - sext_i32_i64(local_tid_6892 - skip_threads_6909));
                            
                            if (thread_active_6910 && inactive_6911) {
                                eta_p_6319 = eta_p_6320;
                            }
                            if (thread_active_6910) {
                                if (!inactive_6911) {
                                    int64_t defunc_0_op_res_6321 = add64(eta_p_6319, eta_p_6320);
                                    
                                    eta_p_6319 = defunc_0_op_res_6321;
                                }
                            }
                        }
                        if (sle32(wave_sizze_6894, skip_threads_6909)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        if (thread_active_6910) {
                            // write result
                            {
                                ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6319;
                                eta_p_6320 = eta_p_6319;
                            }
                        }
                        if (sle32(wave_sizze_6894, skip_threads_6909)) {
                            barrier(CLK_LOCAL_MEM_FENCE);
                        }
                        skip_threads_6909 *= 2;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // last thread of block 'i' writes its result to offset 'i'
                {
                    if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 31 && ltid_in_bounds_6908) {
                        ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(squot32(local_tid_6892, 32))] = eta_p_6319;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'
                {
                    int32_t skip_threads_6912;
                    
                    // read input for in-block scan
                    {
                        if (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908) {
                            eta_p_6906 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)];
                            if ((local_tid_6892 - squot32(local_tid_6892, 32) * 32) == 0) {
                                eta_p_6905 = eta_p_6906;
                            }
                        }
                    }
                    // in-block scan (hopefully no barriers needed)
                    {
                        skip_threads_6912 = 1;
                        while (slt32(skip_threads_6912, 32)) {
                            bool thread_active_6913 = sle32(skip_threads_6912, local_tid_6892 - squot32(local_tid_6892, 32) * 32) && (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908);
                            
                            if (thread_active_6913) {
                                // read operands
                                {
                                    eta_p_6905 = ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892) - sext_i32_i64(skip_threads_6912)];
                                }
                            }
                            // perform operation
                            {
                                bool inactive_6914 = slt64(srem64(sext_i32_i64(local_tid_6892 * 32 + 32 - 1), num_subhistos_6801), sext_i32_i64(local_tid_6892 * 32 + 32 - 1) - sext_i32_i64((local_tid_6892 - skip_threads_6912) * 32 + 32 - 1));
                                
                                if (thread_active_6913 && inactive_6914) {
                                    eta_p_6905 = eta_p_6906;
                                }
                                if (thread_active_6913) {
                                    if (!inactive_6914) {
                                        int64_t defunc_0_op_res_6907 = add64(eta_p_6905, eta_p_6906);
                                        
                                        eta_p_6905 = defunc_0_op_res_6907;
                                    }
                                }
                            }
                            if (sle32(wave_sizze_6894, skip_threads_6912)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            if (thread_active_6913) {
                                // write result
                                {
                                    ((volatile __local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6905;
                                    eta_p_6906 = eta_p_6905;
                                }
                            }
                            if (sle32(wave_sizze_6894, skip_threads_6912)) {
                                barrier(CLK_LOCAL_MEM_FENCE);
                            }
                            skip_threads_6912 *= 2;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                
                bool no_carry_in_6915 = squot32(local_tid_6892, 32) == 0 || !ltid_in_bounds_6908;
                
                // carry-in for every block except the first
                {
                    // read operands
                    {
                        if (!no_carry_in_6915) {
                            eta_p_6320 = eta_p_6319;
                            eta_p_6319 = ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(squot32(local_tid_6892, 32)) - (int64_t) 1];
                        }
                    }
                    // perform operation
                    {
                        bool inactive_6916 = slt64(srem64(sext_i32_i64(local_tid_6892), num_subhistos_6801), sext_i32_i64(local_tid_6892) - sext_i32_i64(squot32(local_tid_6892, 32) * 32 - 1));
                        
                        if (!no_carry_in_6915) {
                            if (inactive_6916) {
                                eta_p_6319 = eta_p_6320;
                            }
                        }
                        if (!no_carry_in_6915) {
                            if (!inactive_6916) {
                                int64_t defunc_0_op_res_6321 = add64(eta_p_6319, eta_p_6320);
                                
                                eta_p_6319 = defunc_0_op_res_6321;
                            }
                        }
                    }
                    // write final result
                    {
                        if (!no_carry_in_6915) {
                            ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6319;
                        }
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
                // restore correct values for first block
                {
                    if (squot32(local_tid_6892, 32) == 0 && ltid_in_bounds_6908) {
                        ((__local int64_t *) red_arr_i64_mem_6896)[sext_i32_i64(local_tid_6892)] = eta_p_6320;
                    }
                }
                barrier(CLK_LOCAL_MEM_FENCE);
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        // save final values of segments
        {
            if (slt64(sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889) + sext_i32_i64(local_tid_6892), (int64_t) 256) && slt64(sext_i32_i64(local_tid_6892), squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889))) {
                int64_t tmp_6917 = ((__local int64_t *) red_arr_i64_mem_6896)[(sext_i32_i64(local_tid_6892) + (int64_t) 1) * segment_sizze_nonzzero_6889 - (int64_t) 1];
                
                ((__global int64_t *) mem_6744)[sext_i32_i64(virt_tblock_id_6901) * squot64(seghist_tblock_sizze_6311, segment_sizze_nonzzero_6889) + sext_i32_i64(local_tid_6892)] = tmp_6917;
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);
    }
    
  error_3:
    return;
    #undef seghist_tblock_sizze_6311
}
"""
# Start of values.py.

# Hacky parser/reader/writer for values written in Futhark syntax.
# Used for reading stdin when compiling standalone programs with the
# Python code generator.

import numpy as np
import struct
import sys


class ReaderInput:
    def __init__(self, f):
        self.f = f
        self.lookahead_buffer = []

    def get_char(self):
        if len(self.lookahead_buffer) == 0:
            return self.f.read(1)
        else:
            c = self.lookahead_buffer[0]
            self.lookahead_buffer = self.lookahead_buffer[1:]
            return c

    def unget_char(self, c):
        self.lookahead_buffer = [c] + self.lookahead_buffer

    def get_chars(self, n):
        n1 = min(n, len(self.lookahead_buffer))
        s = b"".join(self.lookahead_buffer[:n1])
        self.lookahead_buffer = self.lookahead_buffer[n1:]
        n2 = n - n1
        if n2 > 0:
            s += self.f.read(n2)
        return s

    def peek_char(self):
        c = self.get_char()
        if c:
            self.unget_char(c)
        return c


def skip_spaces(f):
    c = f.get_char()
    while c != None:
        if c.isspace():
            c = f.get_char()
        elif c == b"-":
            # May be line comment.
            if f.peek_char() == b"-":
                # Yes, line comment. Skip to end of line.
                while c != b"\n" and c != None:
                    c = f.get_char()
            else:
                break
        else:
            break
    if c:
        f.unget_char(c)


def parse_specific_char(f, expected):
    got = f.get_char()
    if got != expected:
        f.unget_char(got)
        raise ValueError
    return True


def parse_specific_string(f, s):
    # This funky mess is intended, and is caused by the fact that if `type(b) ==
    # bytes` then `type(b[0]) == int`, but we need to match each element with a
    # `bytes`, so therefore we make each character an array element
    b = s.encode("utf8")
    bs = [b[i : i + 1] for i in range(len(b))]
    read = []
    try:
        for c in bs:
            parse_specific_char(f, c)
            read.append(c)
        return True
    except ValueError:
        for c in read[::-1]:
            f.unget_char(c)
        raise


def optional(p, *args):
    try:
        return p(*args)
    except ValueError:
        return None


def optional_specific_string(f, s):
    c = f.peek_char()
    # This funky mess is intended, and is caused by the fact that if `type(b) ==
    # bytes` then `type(b[0]) == int`, but we need to match each element with a
    # `bytes`, so therefore we make each character an array element
    b = s.encode("utf8")
    bs = [b[i : i + 1] for i in range(len(b))]
    if c == bs[0]:
        return parse_specific_string(f, s)
    else:
        return False


def sepBy(p, sep, *args):
    elems = []
    x = optional(p, *args)
    if x != None:
        elems += [x]
        while optional(sep, *args) != None:
            x = p(*args)
            elems += [x]
    return elems


# Assumes '0x' has already been read
def parse_hex_int(f):
    s = b""
    c = f.get_char()
    while c != None:
        if c in b"01234556789ABCDEFabcdef":
            s += c
            c = f.get_char()
        elif c == b"_":
            c = f.get_char()  # skip _
        else:
            f.unget_char(c)
            break
    return str(int(s, 16)).encode("utf8")  # ugh


def parse_int(f):
    s = b""
    c = f.get_char()
    if c == b"0" and f.peek_char() in b"xX":
        c = f.get_char()  # skip X
        return parse_hex_int(f)
    else:
        while c != None:
            if c.isdigit():
                s += c
                c = f.get_char()
            elif c == b"_":
                c = f.get_char()  # skip _
            else:
                f.unget_char(c)
                break
        if len(s) == 0:
            raise ValueError
        return s


def parse_int_signed(f):
    s = b""
    c = f.get_char()

    if c == b"-" and f.peek_char().isdigit():
        return c + parse_int(f)
    else:
        if c != b"+":
            f.unget_char(c)
        return parse_int(f)


def read_str_comma(f):
    skip_spaces(f)
    parse_specific_char(f, b",")
    return b","


def read_str_int(f, s):
    skip_spaces(f)
    x = int(parse_int_signed(f))
    optional_specific_string(f, s)
    return x


def read_str_uint(f, s):
    skip_spaces(f)
    x = int(parse_int(f))
    optional_specific_string(f, s)
    return x


def read_str_i8(f):
    return np.int8(read_str_int(f, "i8"))


def read_str_i16(f):
    return np.int16(read_str_int(f, "i16"))


def read_str_i32(f):
    return np.int32(read_str_int(f, "i32"))


def read_str_i64(f):
    return np.int64(read_str_int(f, "i64"))


def read_str_u8(f):
    return np.uint8(read_str_int(f, "u8"))


def read_str_u16(f):
    return np.uint16(read_str_int(f, "u16"))


def read_str_u32(f):
    return np.uint32(read_str_int(f, "u32"))


def read_str_u64(f):
    return np.uint64(read_str_int(f, "u64"))


def read_char(f):
    skip_spaces(f)
    parse_specific_char(f, b"'")
    c = f.get_char()
    parse_specific_char(f, b"'")
    return c


def read_str_hex_float(f, sign):
    int_part = parse_hex_int(f)
    parse_specific_char(f, b".")
    frac_part = parse_hex_int(f)
    parse_specific_char(f, b"p")
    exponent = parse_int(f)

    int_val = int(int_part, 16)
    frac_val = float(int(frac_part, 16)) / (16 ** len(frac_part))
    exp_val = int(exponent)

    total_val = (int_val + frac_val) * (2.0**exp_val)
    if sign == b"-":
        total_val = -1 * total_val

    return float(total_val)


def read_str_decimal(f):
    skip_spaces(f)
    c = f.get_char()
    if c == b"-":
        sign = b"-"
    else:
        f.unget_char(c)
        sign = b""

    # Check for hexadecimal float
    c = f.get_char()
    if c == "0" and (f.peek_char() in ["x", "X"]):
        f.get_char()
        return read_str_hex_float(f, sign)
    else:
        f.unget_char(c)

    bef = optional(parse_int, f)
    if bef == None:
        bef = b"0"
        parse_specific_char(f, b".")
        aft = parse_int(f)
    elif optional(parse_specific_char, f, b"."):
        aft = parse_int(f)
    else:
        aft = b"0"
    if optional(parse_specific_char, f, b"E") or optional(parse_specific_char, f, b"e"):
        expt = parse_int_signed(f)
    else:
        expt = b"0"
    return float(sign + bef + b"." + aft + b"E" + expt)


def read_str_f16(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f16.nan")
        return np.float32(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f16.inf")
            return np.float32(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f16.inf")
                return np.float32(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f16")
                return x


def read_str_f32(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f32.nan")
        return np.float32(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f32.inf")
            return np.float32(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f32.inf")
                return np.float32(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f32")
                return x


def read_str_f64(f):
    skip_spaces(f)
    try:
        parse_specific_string(f, "f64.nan")
        return np.float64(np.nan)
    except ValueError:
        try:
            parse_specific_string(f, "f64.inf")
            return np.float64(np.inf)
        except ValueError:
            try:
                parse_specific_string(f, "-f64.inf")
                return np.float64(-np.inf)
            except ValueError:
                x = read_str_decimal(f)
                optional_specific_string(f, "f64")
                return x


def read_str_bool(f):
    skip_spaces(f)
    if f.peek_char() == b"t":
        parse_specific_string(f, "true")
        return True
    elif f.peek_char() == b"f":
        parse_specific_string(f, "false")
        return False
    else:
        raise ValueError


def read_str_empty_array(f, type_name, rank):
    parse_specific_string(f, "empty")
    parse_specific_char(f, b"(")
    dims = []
    for i in range(rank):
        parse_specific_string(f, "[")
        dims += [int(parse_int(f))]
        parse_specific_string(f, "]")
    if np.prod(dims) != 0:
        raise ValueError
    parse_specific_string(f, type_name)
    parse_specific_char(f, b")")

    return tuple(dims)


def read_str_array_elems(f, elem_reader, type_name, rank):
    skip_spaces(f)
    try:
        parse_specific_char(f, b"[")
    except ValueError:
        return read_str_empty_array(f, type_name, rank)
    else:
        xs = sepBy(elem_reader, read_str_comma, f)
        skip_spaces(f)
        parse_specific_char(f, b"]")
        return xs


def read_str_array_helper(f, elem_reader, type_name, rank):
    def nested_row_reader(_):
        return read_str_array_helper(f, elem_reader, type_name, rank - 1)

    if rank == 1:
        row_reader = elem_reader
    else:
        row_reader = nested_row_reader
    return read_str_array_elems(f, row_reader, type_name, rank)


def expected_array_dims(l, rank):
    if rank > 1:
        n = len(l)
        if n == 0:
            elem = []
        else:
            elem = l[0]
        return [n] + expected_array_dims(elem, rank - 1)
    else:
        return [len(l)]


def verify_array_dims(l, dims):
    if dims[0] != len(l):
        raise ValueError
    if len(dims) > 1:
        for x in l:
            verify_array_dims(x, dims[1:])


def read_str_array(f, elem_reader, type_name, rank, bt):
    elems = read_str_array_helper(f, elem_reader, type_name, rank)
    if type(elems) == tuple:
        # Empty array
        return np.empty(elems, dtype=bt)
    else:
        dims = expected_array_dims(elems, rank)
        verify_array_dims(elems, dims)
        return np.array(elems, dtype=bt)


################################################################################

READ_BINARY_VERSION = 2

# struct format specified at
# https://docs.python.org/2/library/struct.html#format-characters


def mk_bin_scalar_reader(t):
    def bin_reader(f):
        fmt = FUTHARK_PRIMTYPES[t]["bin_format"]
        size = FUTHARK_PRIMTYPES[t]["size"]
        tf = FUTHARK_PRIMTYPES[t]["numpy_type"]
        return tf(struct.unpack("<" + fmt, f.get_chars(size))[0])

    return bin_reader


read_bin_i8 = mk_bin_scalar_reader("i8")
read_bin_i16 = mk_bin_scalar_reader("i16")
read_bin_i32 = mk_bin_scalar_reader("i32")
read_bin_i64 = mk_bin_scalar_reader("i64")

read_bin_u8 = mk_bin_scalar_reader("u8")
read_bin_u16 = mk_bin_scalar_reader("u16")
read_bin_u32 = mk_bin_scalar_reader("u32")
read_bin_u64 = mk_bin_scalar_reader("u64")

read_bin_f16 = mk_bin_scalar_reader("f16")
read_bin_f32 = mk_bin_scalar_reader("f32")
read_bin_f64 = mk_bin_scalar_reader("f64")

read_bin_bool = mk_bin_scalar_reader("bool")


def read_is_binary(f):
    skip_spaces(f)
    c = f.get_char()
    if c == b"b":
        bin_version = read_bin_u8(f)
        if bin_version != READ_BINARY_VERSION:
            panic(
                1,
                "binary-input: File uses version %i, but I only understand version %i.\n",
                bin_version,
                READ_BINARY_VERSION,
            )
        return True
    else:
        f.unget_char(c)
        return False


FUTHARK_PRIMTYPES = {
    "i8": {
        "binname": b"  i8",
        "size": 1,
        "bin_reader": read_bin_i8,
        "str_reader": read_str_i8,
        "bin_format": "b",
        "numpy_type": np.int8,
    },
    "i16": {
        "binname": b" i16",
        "size": 2,
        "bin_reader": read_bin_i16,
        "str_reader": read_str_i16,
        "bin_format": "h",
        "numpy_type": np.int16,
    },
    "i32": {
        "binname": b" i32",
        "size": 4,
        "bin_reader": read_bin_i32,
        "str_reader": read_str_i32,
        "bin_format": "i",
        "numpy_type": np.int32,
    },
    "i64": {
        "binname": b" i64",
        "size": 8,
        "bin_reader": read_bin_i64,
        "str_reader": read_str_i64,
        "bin_format": "q",
        "numpy_type": np.int64,
    },
    "u8": {
        "binname": b"  u8",
        "size": 1,
        "bin_reader": read_bin_u8,
        "str_reader": read_str_u8,
        "bin_format": "B",
        "numpy_type": np.uint8,
    },
    "u16": {
        "binname": b" u16",
        "size": 2,
        "bin_reader": read_bin_u16,
        "str_reader": read_str_u16,
        "bin_format": "H",
        "numpy_type": np.uint16,
    },
    "u32": {
        "binname": b" u32",
        "size": 4,
        "bin_reader": read_bin_u32,
        "str_reader": read_str_u32,
        "bin_format": "I",
        "numpy_type": np.uint32,
    },
    "u64": {
        "binname": b" u64",
        "size": 8,
        "bin_reader": read_bin_u64,
        "str_reader": read_str_u64,
        "bin_format": "Q",
        "numpy_type": np.uint64,
    },
    "f16": {
        "binname": b" f16",
        "size": 2,
        "bin_reader": read_bin_f16,
        "str_reader": read_str_f16,
        "bin_format": "e",
        "numpy_type": np.float16,
    },
    "f32": {
        "binname": b" f32",
        "size": 4,
        "bin_reader": read_bin_f32,
        "str_reader": read_str_f32,
        "bin_format": "f",
        "numpy_type": np.float32,
    },
    "f64": {
        "binname": b" f64",
        "size": 8,
        "bin_reader": read_bin_f64,
        "str_reader": read_str_f64,
        "bin_format": "d",
        "numpy_type": np.float64,
    },
    "bool": {
        "binname": b"bool",
        "size": 1,
        "bin_reader": read_bin_bool,
        "str_reader": read_str_bool,
        "bin_format": "b",
        "numpy_type": bool,
    },
}


def read_bin_read_type(f):
    read_binname = f.get_chars(4)

    for k, v in FUTHARK_PRIMTYPES.items():
        if v["binname"] == read_binname:
            return k
    panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname)


def numpy_type_to_type_name(t):
    for k, v in FUTHARK_PRIMTYPES.items():
        if v["numpy_type"] == t:
            return k
    raise Exception(f"Unknown Numpy type: {t}")


def read_bin_ensure_scalar(f, expected_type):
    dims = read_bin_i8(f)

    if dims != 0:
        panic(
            1,
            "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
            dims,
        )

    bin_type = read_bin_read_type(f)
    if bin_type != expected_type:
        panic(
            1,
            "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
            expected_type,
            bin_type,
        )


# ------------------------------------------------------------------------------
# General interface for reading Primitive Futhark Values
# ------------------------------------------------------------------------------


def read_scalar(f, ty):
    if read_is_binary(f):
        read_bin_ensure_scalar(f, ty)
        return FUTHARK_PRIMTYPES[ty]["bin_reader"](f)
    return FUTHARK_PRIMTYPES[ty]["str_reader"](f)


def read_array(f, expected_type, rank):
    if not read_is_binary(f):
        str_reader = FUTHARK_PRIMTYPES[expected_type]["str_reader"]
        return read_str_array(
            f,
            str_reader,
            expected_type,
            rank,
            FUTHARK_PRIMTYPES[expected_type]["numpy_type"],
        )

    bin_rank = read_bin_u8(f)

    if bin_rank != rank:
        panic(
            1,
            "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
            rank,
            bin_rank,
        )

    bin_type_enum = read_bin_read_type(f)
    if expected_type != bin_type_enum:
        panic(
            1,
            "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
            rank,
            expected_type,
            bin_rank,
            bin_type_enum,
        )

    shape = []
    elem_count = 1
    for i in range(rank):
        bin_size = read_bin_i64(f)
        elem_count *= bin_size
        shape.append(bin_size)

    bin_fmt = FUTHARK_PRIMTYPES[bin_type_enum]["bin_format"]

    # We first read the expected number of types into a bytestring,
    # then use np.frombuffer.  This is because np.fromfile does not
    # work on things that are insufficiently file-like, like a network
    # stream.
    bytes = f.get_chars(elem_count * FUTHARK_PRIMTYPES[expected_type]["size"])
    arr = np.frombuffer(bytes, dtype=FUTHARK_PRIMTYPES[bin_type_enum]["numpy_type"])
    arr.shape = shape

    return arr.copy()  # To ensure it is writeable.


input_reader = ReaderInput(sys.stdin.buffer)

import re


def read_value(type_desc, reader=input_reader):
    """Read a value of the given type.  The type is a string
    representation of the Futhark type."""
    m = re.match(r"((?:\[\])*)([a-z0-9]+)$", type_desc)
    if m:
        dims = int(len(m.group(1)) / 2)
        basetype = m.group(2)
    assert m and basetype in FUTHARK_PRIMTYPES, f"Unknown type: {type_desc}"
    if dims > 0:
        return read_array(reader, basetype, dims)
    else:
        return read_scalar(reader, basetype)


def end_of_input(entry, f=input_reader):
    skip_spaces(f)
    if f.get_char() != b"":
        panic(1, 'Expected EOF on stdin after reading input for "%s".', entry)


def write_value_text(v, out=sys.stdout):
    if type(v) == np.uint8:
        out.write("%uu8" % v)
    elif type(v) == np.uint16:
        out.write("%uu16" % v)
    elif type(v) == np.uint32:
        out.write("%uu32" % v)
    elif type(v) == np.uint64:
        out.write("%uu64" % v)
    elif type(v) == np.int8:
        out.write("%di8" % v)
    elif type(v) == np.int16:
        out.write("%di16" % v)
    elif type(v) == np.int32:
        out.write("%di32" % v)
    elif type(v) == np.int64:
        out.write("%di64" % v)
    elif type(v) in [bool, np.bool_]:
        if v:
            out.write("true")
        else:
            out.write("false")
    elif type(v) == np.float16:
        if np.isnan(v):
            out.write("f16.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f16.inf")
            else:
                out.write("-f16.inf")
        else:
            out.write("%.6ff16" % v)
    elif type(v) == np.float32:
        if np.isnan(v):
            out.write("f32.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f32.inf")
            else:
                out.write("-f32.inf")
        else:
            out.write("%.6ff32" % v)
    elif type(v) == np.float64:
        if np.isnan(v):
            out.write("f64.nan")
        elif np.isinf(v):
            if v >= 0:
                out.write("f64.inf")
            else:
                out.write("-f64.inf")
        else:
            out.write("%.6ff64" % v)
    elif type(v) == np.ndarray:
        if np.prod(v.shape) == 0:
            tname = numpy_type_to_type_name(v.dtype)
            out.write("empty({}{})".format("".join([f"[{d}]" for d in v.shape]), tname))
        else:
            first = True
            out.write("[")
            for x in v:
                if not first:
                    out.write(", ")
                first = False
                write_value(x, out=out)
            out.write("]")
    else:
        raise Exception(f"Cannot print value of type {type(v)}: {v}")


type_strs = {
    np.dtype("int8"): b"  i8",
    np.dtype("int16"): b" i16",
    np.dtype("int32"): b" i32",
    np.dtype("int64"): b" i64",
    np.dtype("uint8"): b"  u8",
    np.dtype("uint16"): b" u16",
    np.dtype("uint32"): b" u32",
    np.dtype("uint64"): b" u64",
    np.dtype("float16"): b" f16",
    np.dtype("float32"): b" f32",
    np.dtype("float64"): b" f64",
    np.dtype("bool"): b"bool",
}


def construct_binary_value(v):
    t = v.dtype
    shape = v.shape

    elems = 1
    for d in shape:
        elems *= d

    num_bytes = 1 + 1 + 1 + 4 + len(shape) * 8 + elems * t.itemsize
    bytes = bytearray(num_bytes)
    bytes[0] = np.int8(ord("b"))
    bytes[1] = 2
    bytes[2] = np.int8(len(shape))
    bytes[3:7] = type_strs[t]

    for i in range(len(shape)):
        bytes[7 + i * 8 : 7 + (i + 1) * 8] = np.int64(shape[i]).tobytes()

    bytes[7 + len(shape) * 8 :] = np.ascontiguousarray(v).tobytes()

    return bytes


def write_value_binary(v, out=sys.stdout):
    out = out.buffer
    out.write(construct_binary_value(v))


def write_value(v, out=sys.stdout, binary=False):
    if binary:
        return write_value_binary(v, out=out)
    else:
        return write_value_text(v, out=out)


# End of values.py.
# Start of memory.py.

import ctypes as ct


def allocateMem(size):
    return np.empty(size, dtype=np.byte)


# Copy an array if its is not-None.  This is important for treating
# Numpy arrays as flat memory, but has some overhead.
def normaliseArray(x):
    if (x.base is x) or (x.base is None):
        return x
    else:
        return x.copy()


def unwrapArray(x):
    return x.ravel().view(np.byte)


def indexArray(x, offset, bt):
    return x.view(bt)[offset]


def writeScalarArray(x, offset, v):
    x.view(type(v))[offset] = v


# An opaque Futhark value.
class opaque:
    def __init__(self, desc, *payload):
        self.data = payload
        self.desc = desc

    def __repr__(self):
        return f"<opaque Futhark value of type {self.desc}>"


# LMAD stuff


def lmad_contiguous_search(checked, expected, strides, shape, used):
    for i in range(len(strides)):
        for j in range(len(strides)):
            if not used[j] and strides[j] == expected and strides[j] >= 0:
                used[j] = True
                if checked + 1 == len(strides) or lmad_contiguous_search(
                    checked + 1, expected * shape[j], strides, shape, used
                ):
                    return True
                used[j] = False
    return False


def lmad_contiguous(strides, shape):
    used = len(strides) * [False]
    return lmad_contiguous_search(0, 1, strides, shape, used)


def lmad_memcpyable(dst_strides, src_strides, shape):
    if not lmad_contiguous(dst_strides, shape):
        return False
    for i in range(len(dst_strides)):
        if dst_strides[i] != src_strides[i] and shape[i] != 1:
            return False
    return True


def lmad_is_tr(strides, shape):
    r = len(shape)
    for i in range(1, r):
        n = 1
        m = 1
        ok = True
        expected = 1
        # Check strides before 'i'.
        for j in range(i - 1, -1, -1):
            ok = ok and strides[j] == expected
            expected *= shape[j]
            n *= shape[j]
        # Check strides after 'i'.
        for j in range(r - 1, i - 1, -1):
            ok = ok and strides[j] == expected
            expected *= shape[j]
            m *= shape[j]
        if ok:
            return (n, m)
    return None


def lmad_map_tr(dst_strides, src_strides, shape):
    r = len(dst_strides)
    rowmajor_strides = [0] * r
    rowmajor_strides[r - 1] = 1

    for i in range(r - 2, -1, -1):
        rowmajor_strides[i] = rowmajor_strides[i + 1] * shape[i + 1]

    # map_r will be the number of mapped dimensions on top.
    map_r = 0
    k = 1
    for i in range(r):
        if dst_strides[i] != rowmajor_strides[i] or src_strides[i] != rowmajor_strides[i]:
            break
        else:
            k *= shape[i]
            map_r += 1

    if rowmajor_strides[map_r:] == dst_strides[map_r:]:
        r = lmad_is_tr(src_strides[map_r:], shape[map_r:])
        if r is not None:
            (n, m) = r
            return (k, n, m)
    elif rowmajor_strides[map_r:] == src_strides[map_r:]:
        r = lmad_is_tr(dst_strides[map_r:], shape[map_r:])
        if r is not None:
            (n, m) = r
            return (k, m, n)  # Sic!
    return None


def lmad_copy_elements(pt, dst, dst_offset, dst_strides, src, src_offset, src_strides, shape):
    if len(shape) == 1:
        for i in range(shape[0]):
            writeScalarArray(
                dst,
                dst_offset + i * dst_strides[0],
                indexArray(src, src_offset + i * src_strides[0], pt),
            )
    else:
        for i in range(shape[0]):
            lmad_copy_elements(
                pt,
                dst,
                dst_offset + i * dst_strides[0],
                dst_strides[1:],
                src,
                src_offset + i * src_strides[0],
                src_strides[1:],
                shape[1:],
            )


def lmad_copy(pt, dst, dst_offset, dst_strides, src, src_offset, src_strides, shape):
    if lmad_memcpyable(dst_strides, src_strides, shape):
        dst[
            dst_offset * ct.sizeof(pt) : dst_offset * ct.sizeof(pt) + np.prod(shape) * ct.sizeof(pt)
        ] = src[
            src_offset * ct.sizeof(pt) : src_offset * ct.sizeof(pt) + np.prod(shape) * ct.sizeof(pt)
        ]
    else:
        lmad_copy_elements(
            pt,
            dst,
            dst_offset,
            dst_strides,
            src,
            src_offset,
            src_strides,
            shape,
        )


# End of memory.py.
# Start of panic.py.


def panic(exitcode, fmt, *args):
    sys.stderr.write("%s: " % sys.argv[0])
    sys.stderr.write(fmt % args)
    sys.stderr.write("\n")
    sys.exit(exitcode)


# End of panic.py.
# Start of tuning.py


def read_tuning_file(kvs, f):
    for line in f.read().splitlines():
        size, value = line.split("=")
        kvs[size] = int(value)
    return kvs


# End of tuning.py.
# Start of scalar.py.

import numpy as np
import math
import struct


def intlit(t, x):
    if t == np.int8:
        return np.int8(x)
    elif t == np.int16:
        return np.int16(x)
    elif t == np.int32:
        return np.int32(x)
    else:
        return np.int64(x)


def signed(x):
    if type(x) == np.uint8:
        return np.int8(x)
    elif type(x) == np.uint16:
        return np.int16(x)
    elif type(x) == np.uint32:
        return np.int32(x)
    else:
        return np.int64(x)


def unsigned(x):
    if type(x) == np.int8:
        return np.uint8(x)
    elif type(x) == np.int16:
        return np.uint16(x)
    elif type(x) == np.int32:
        return np.uint32(x)
    else:
        return np.uint64(x)


def shlN(x, y):
    return x << y


def ashrN(x, y):
    return x >> y


# Python is so slow that we just make all the unsafe operations safe,
# always.


def sdivN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return x // y


def sdiv_upN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return (x + y - intlit(type(x), 1)) // y


def smodN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return x % y


def udivN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed(unsigned(x) // unsigned(y))


def udiv_upN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed((unsigned(x) + unsigned(y) - unsigned(intlit(type(x), 1))) // unsigned(y))


def umodN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return signed(unsigned(x) % unsigned(y))


def squotN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return np.floor_divide(np.abs(x), np.abs(y)) * np.sign(x) * np.sign(y)


def sremN(x, y):
    if y == 0:
        return intlit(type(x), 0)
    else:
        return np.remainder(np.abs(x), np.abs(y)) * np.sign(x)


def sminN(x, y):
    return min(x, y)


def smaxN(x, y):
    return max(x, y)


def uminN(x, y):
    return signed(min(unsigned(x), unsigned(y)))


def umaxN(x, y):
    return signed(max(unsigned(x), unsigned(y)))


def fminN(x, y):
    return np.fmin(x, y)


def fmaxN(x, y):
    return np.fmax(x, y)


def powN(x, y):
    return x**y


def fpowN(x, y):
    return x**y


def sleN(x, y):
    return x <= y


def sltN(x, y):
    return x < y


def uleN(x, y):
    return unsigned(x) <= unsigned(y)


def ultN(x, y):
    return unsigned(x) < unsigned(y)


def lshr8(x, y):
    return np.int8(np.uint8(x) >> np.uint8(y))


def lshr16(x, y):
    return np.int16(np.uint16(x) >> np.uint16(y))


def lshr32(x, y):
    return np.int32(np.uint32(x) >> np.uint32(y))


def lshr64(x, y):
    return np.int64(np.uint64(x) >> np.uint64(y))


def sext_T_i8(x):
    return np.int8(x)


def sext_T_i16(x):
    return np.int16(x)


def sext_T_i32(x):
    return np.int32(x)


def sext_T_i64(x):
    return np.int64(x)


def itob_T_bool(x):
    return bool(x)


def btoi_bool_i8(x):
    return np.int8(x)


def btoi_bool_i16(x):
    return np.int16(x)


def btoi_bool_i32(x):
    return np.int32(x)


def btoi_bool_i64(x):
    return np.int64(x)


def ftob_T_bool(x):
    return bool(x)


def btof_bool_f16(x):
    return np.float16(x)


def btof_bool_f32(x):
    return np.float32(x)


def btof_bool_f64(x):
    return np.float64(x)


def zext_i8_i8(x):
    return np.int8(np.uint8(x))


def zext_i8_i16(x):
    return np.int16(np.uint8(x))


def zext_i8_i32(x):
    return np.int32(np.uint8(x))


def zext_i8_i64(x):
    return np.int64(np.uint8(x))


def zext_i16_i8(x):
    return np.int8(np.uint16(x))


def zext_i16_i16(x):
    return np.int16(np.uint16(x))


def zext_i16_i32(x):
    return np.int32(np.uint16(x))


def zext_i16_i64(x):
    return np.int64(np.uint16(x))


def zext_i32_i8(x):
    return np.int8(np.uint32(x))


def zext_i32_i16(x):
    return np.int16(np.uint32(x))


def zext_i32_i32(x):
    return np.int32(np.uint32(x))


def zext_i32_i64(x):
    return np.int64(np.uint32(x))


def zext_i64_i8(x):
    return np.int8(np.uint64(x))


def zext_i64_i16(x):
    return np.int16(np.uint64(x))


def zext_i64_i32(x):
    return np.int32(np.uint64(x))


def zext_i64_i64(x):
    return np.int64(np.uint64(x))


sdiv8 = sdiv16 = sdiv32 = sdiv64 = sdivN
sdiv_up8 = sdiv1_up6 = sdiv_up32 = sdiv_up64 = sdiv_upN
sdiv_safe8 = sdiv1_safe6 = sdiv_safe32 = sdiv_safe64 = sdivN
sdiv_up_safe8 = sdiv_up1_safe6 = sdiv_up_safe32 = sdiv_up_safe64 = sdiv_upN
smod8 = smod16 = smod32 = smod64 = smodN
smod_safe8 = smod_safe16 = smod_safe32 = smod_safe64 = smodN
udiv8 = udiv16 = udiv32 = udiv64 = udivN
udiv_up8 = udiv_up16 = udiv_up32 = udiv_up64 = udivN
udiv_safe8 = udiv_safe16 = udiv_safe32 = udiv_safe64 = udiv_upN
udiv_up_safe8 = udiv_up_safe16 = udiv_up_safe32 = udiv_up_safe64 = udiv_upN
umod8 = umod16 = umod32 = umod64 = umodN
umod_safe8 = umod_safe16 = umod_safe32 = umod_safe64 = umodN
squot8 = squot16 = squot32 = squot64 = squotN
squot_safe8 = squot_safe16 = squot_safe32 = squot_safe64 = squotN
srem8 = srem16 = srem32 = srem64 = sremN
srem_safe8 = srem_safe16 = srem_safe32 = srem_safe64 = sremN

shl8 = shl16 = shl32 = shl64 = shlN
ashr8 = ashr16 = ashr32 = ashr64 = ashrN
smax8 = smax16 = smax32 = smax64 = smaxN
smin8 = smin16 = smin32 = smin64 = sminN
umax8 = umax16 = umax32 = umax64 = umaxN
umin8 = umin16 = umin32 = umin64 = uminN
pow8 = pow16 = pow32 = pow64 = powN
fpow16 = fpow32 = fpow64 = fpowN
fmax16 = fmax32 = fmax64 = fmaxN
fmin16 = fmin32 = fmin64 = fminN
sle8 = sle16 = sle32 = sle64 = sleN
slt8 = slt16 = slt32 = slt64 = sltN
ule8 = ule16 = ule32 = ule64 = uleN
ult8 = ult16 = ult32 = ult64 = ultN
sext_i8_i8 = sext_i16_i8 = sext_i32_i8 = sext_i64_i8 = sext_T_i8
sext_i8_i16 = sext_i16_i16 = sext_i32_i16 = sext_i64_i16 = sext_T_i16
sext_i8_i32 = sext_i16_i32 = sext_i32_i32 = sext_i64_i32 = sext_T_i32
sext_i8_i64 = sext_i16_i64 = sext_i32_i64 = sext_i64_i64 = sext_T_i64
itob_i8_bool = itob_i16_bool = itob_i32_bool = itob_i64_bool = itob_T_bool
ftob_f16_bool = ftob_f32_bool = ftob_f64_bool = ftob_T_bool


def clz_T(x):
    n = np.int32(0)
    bits = x.itemsize * 8
    for i in range(bits):
        if x < 0:
            break
        n += np.int32(1)
        x <<= np.int8(1)
    return n


def ctz_T(x):
    n = np.int32(0)
    bits = x.itemsize * 8
    for i in range(bits):
        if (x & 1) == 1:
            break
        n += np.int32(1)
        x >>= np.int8(1)
    return n


def popc_T(x):
    c = np.int32(0)
    while x != 0:
        x &= x - np.int8(1)
        c += np.int32(1)
    return c


futhark_popc8 = futhark_popc16 = futhark_popc32 = futhark_popc64 = popc_T
futhark_clzz8 = futhark_clzz16 = futhark_clzz32 = futhark_clzz64 = clz_T
futhark_ctzz8 = futhark_ctzz16 = futhark_ctzz32 = futhark_ctzz64 = ctz_T


def ssignum(x):
    return np.sign(x)


def usignum(x):
    if x < 0:
        return ssignum(-x)
    else:
        return ssignum(x)


def sitofp_T_f32(x):
    return np.float32(x)


sitofp_i8_f32 = sitofp_i16_f32 = sitofp_i32_f32 = sitofp_i64_f32 = sitofp_T_f32


def sitofp_T_f64(x):
    return np.float64(x)


sitofp_i8_f64 = sitofp_i16_f64 = sitofp_i32_f64 = sitofp_i64_f64 = sitofp_T_f64


def uitofp_T_f32(x):
    return np.float32(unsigned(x))


uitofp_i8_f32 = uitofp_i16_f32 = uitofp_i32_f32 = uitofp_i64_f32 = uitofp_T_f32


def uitofp_T_f64(x):
    return np.float64(unsigned(x))


uitofp_i8_f64 = uitofp_i16_f64 = uitofp_i32_f64 = uitofp_i64_f64 = uitofp_T_f64


def fptosi_T_i8(x):
    if np.isnan(x) or np.isinf(x):
        return np.int8(0)
    else:
        return np.int8(np.trunc(x))


fptosi_f16_i8 = fptosi_f32_i8 = fptosi_f64_i8 = fptosi_T_i8


def fptosi_T_i16(x):
    if np.isnan(x) or np.isinf(x):
        return np.int16(0)
    else:
        return np.int16(np.trunc(x))


fptosi_f16_i16 = fptosi_f32_i16 = fptosi_f64_i16 = fptosi_T_i16


def fptosi_T_i32(x):
    if np.isnan(x) or np.isinf(x):
        return np.int32(0)
    else:
        return np.int32(np.trunc(x))


fptosi_f16_i32 = fptosi_f32_i32 = fptosi_f64_i32 = fptosi_T_i32


def fptosi_T_i64(x):
    if np.isnan(x) or np.isinf(x):
        return np.int64(0)
    else:
        return np.int64(np.trunc(x))


fptosi_f16_i64 = fptosi_f32_i64 = fptosi_f64_i64 = fptosi_T_i64


def fptoui_T_i8(x):
    if np.isnan(x) or np.isinf(x):
        return np.int8(0)
    else:
        return np.int8(np.trunc(x))


fptoui_f16_i8 = fptoui_f32_i8 = fptoui_f64_i8 = fptoui_T_i8


def fptoui_T_i16(x):
    if np.isnan(x) or np.isinf(x):
        return np.int16(0)
    else:
        return np.int16(np.trunc(x))


fptoui_f16_i16 = fptoui_f32_i16 = fptoui_f64_i16 = fptoui_T_i16


def fptoui_T_i32(x):
    if np.isnan(x) or np.isinf(x):
        return np.int32(0)
    else:
        return np.int32(np.trunc(x))


fptoui_f16_i32 = fptoui_f32_i32 = fptoui_f64_i32 = fptoui_T_i32


def fptoui_T_i64(x):
    if np.isnan(x) or np.isinf(x):
        return np.int64(0)
    else:
        return np.int64(np.trunc(x))


fptoui_f16_i64 = fptoui_f32_i64 = fptoui_f64_i64 = fptoui_T_i64


def fpconv_f16_f32(x):
    return np.float32(x)


def fpconv_f16_f64(x):
    return np.float64(x)


def fpconv_f32_f16(x):
    return np.float16(x)


def fpconv_f32_f64(x):
    return np.float64(x)


def fpconv_f64_f16(x):
    return np.float16(x)


def fpconv_f64_f32(x):
    return np.float32(x)


def futhark_umul_hi8(a, b):
    return np.int8((np.uint64(np.uint8(a)) * np.uint64(np.uint8(b))) >> np.uint64(8))


def futhark_umul_hi16(a, b):
    return np.int16((np.uint64(np.uint16(a)) * np.uint64(np.uint16(b))) >> np.uint64(16))


def futhark_umul_hi32(a, b):
    return np.int32((np.uint64(np.uint32(a)) * np.uint64(np.uint32(b))) >> np.uint64(32))


def futhark_umul_hi64(a, b):
    return np.int64(np.uint64(int(np.uint64(a)) * int(np.uint64(b)) >> 64))


def futhark_smul_hi8(a, b):
    return np.int8((np.int64(a) * np.int64(b)) >> np.int64(8))


def futhark_smul_hi16(a, b):
    return np.int16((np.int64(a) * np.int64(b)) >> np.int64(16))


def futhark_smul_hi32(a, b):
    return np.int32((np.int64(a) * np.int64(b)) >> np.int64(32))


def futhark_smul_hi64(a, b):
    return np.int64(int(a) * int(b) >> 64)


def futhark_umad_hi8(a, b, c):
    return futhark_umul_hi8(a, b) + c


def futhark_umad_hi16(a, b, c):
    return futhark_umul_hi16(a, b) + c


def futhark_umad_hi32(a, b, c):
    return futhark_umul_hi32(a, b) + c


def futhark_umad_hi64(a, b, c):
    return futhark_umul_hi64(a, b) + c


def futhark_smad_hi8(a, b, c):
    return futhark_smul_hi8(a, b) + c


def futhark_smad_hi16(a, b, c):
    return futhark_smul_hi16(a, b) + c


def futhark_smad_hi32(a, b, c):
    return futhark_smul_hi32(a, b) + c


def futhark_smad_hi64(a, b, c):
    return futhark_smul_hi64(a, b) + c


def futhark_log64(x):
    return np.float64(np.log(x))


def futhark_log2_64(x):
    return np.float64(np.log2(x))


def futhark_log10_64(x):
    return np.float64(np.log10(x))


def futhark_log1p_64(x):
    return np.float64(np.log1p(x))


def futhark_sqrt64(x):
    return np.sqrt(x)


def futhark_cbrt64(x):
    return np.cbrt(x)


def futhark_exp64(x):
    return np.exp(x)


def futhark_cos64(x):
    return np.cos(x)


def futhark_sin64(x):
    return np.sin(x)


def futhark_tan64(x):
    return np.tan(x)


def futhark_acos64(x):
    return np.arccos(x)


def futhark_asin64(x):
    return np.arcsin(x)


def futhark_atan64(x):
    return np.arctan(x)


def futhark_cosh64(x):
    return np.cosh(x)


def futhark_sinh64(x):
    return np.sinh(x)


def futhark_tanh64(x):
    return np.tanh(x)


def futhark_acosh64(x):
    return np.arccosh(x)


def futhark_asinh64(x):
    return np.arcsinh(x)


def futhark_atanh64(x):
    return np.arctanh(x)


def futhark_atan2_64(x, y):
    return np.arctan2(x, y)


def futhark_hypot64(x, y):
    return np.hypot(x, y)


def futhark_gamma64(x):
    return np.float64(math.gamma(x))


def futhark_lgamma64(x):
    return np.float64(math.lgamma(x))


def futhark_erf64(x):
    return np.float64(math.erf(x))


def futhark_erfc64(x):
    return np.float64(math.erfc(x))


def futhark_round64(x):
    return np.round(x)


def futhark_ceil64(x):
    return np.ceil(x)


def futhark_floor64(x):
    return np.floor(x)


def futhark_nextafter64(x, y):
    return np.nextafter(x, y)


def futhark_isnan64(x):
    return np.isnan(x)


def futhark_isinf64(x):
    return np.isinf(x)


def futhark_to_bits64(x):
    s = struct.pack(">d", x)
    return np.int64(struct.unpack(">q", s)[0])


def futhark_from_bits64(x):
    s = struct.pack(">q", x)
    return np.float64(struct.unpack(">d", s)[0])


def futhark_log32(x):
    return np.float32(np.log(x))


def futhark_log2_32(x):
    return np.float32(np.log2(x))


def futhark_log10_32(x):
    return np.float32(np.log10(x))


def futhark_log1p_32(x):
    return np.float32(np.log1p(x))


def futhark_sqrt32(x):
    return np.float32(np.sqrt(x))


def futhark_cbrt32(x):
    return np.float32(np.cbrt(x))


def futhark_exp32(x):
    return np.exp(x)


def futhark_cos32(x):
    return np.cos(x)


def futhark_sin32(x):
    return np.sin(x)


def futhark_tan32(x):
    return np.tan(x)


def futhark_acos32(x):
    return np.arccos(x)


def futhark_asin32(x):
    return np.arcsin(x)


def futhark_atan32(x):
    return np.arctan(x)


def futhark_cosh32(x):
    return np.cosh(x)


def futhark_sinh32(x):
    return np.sinh(x)


def futhark_tanh32(x):
    return np.tanh(x)


def futhark_acosh32(x):
    return np.arccosh(x)


def futhark_asinh32(x):
    return np.arcsinh(x)


def futhark_atanh32(x):
    return np.arctanh(x)


def futhark_atan2_32(x, y):
    return np.arctan2(x, y)


def futhark_hypot32(x, y):
    return np.hypot(x, y)


def futhark_gamma32(x):
    return np.float32(math.gamma(x))


def futhark_lgamma32(x):
    return np.float32(math.lgamma(x))


def futhark_erf32(x):
    return np.float32(math.erf(x))


def futhark_erfc32(x):
    return np.float32(math.erfc(x))


def futhark_round32(x):
    return np.round(x)


def futhark_ceil32(x):
    return np.ceil(x)


def futhark_floor32(x):
    return np.floor(x)


def futhark_nextafter32(x, y):
    return np.nextafter(x, y)


def futhark_isnan32(x):
    return np.isnan(x)


def futhark_isinf32(x):
    return np.isinf(x)


def futhark_to_bits32(x):
    s = struct.pack(">f", x)
    return np.int32(struct.unpack(">l", s)[0])


def futhark_from_bits32(x):
    s = struct.pack(">l", x)
    return np.float32(struct.unpack(">f", s)[0])


def futhark_log16(x):
    return np.float16(np.log(x))


def futhark_log2_16(x):
    return np.float16(np.log2(x))


def futhark_log10_16(x):
    return np.float16(np.log10(x))


def futhark_log1p_16(x):
    return np.float16(np.log1p(x))


def futhark_sqrt16(x):
    return np.float16(np.sqrt(x))


def futhark_cbrt16(x):
    return np.float16(np.cbrt(x))


def futhark_exp16(x):
    return np.exp(x)


def futhark_cos16(x):
    return np.cos(x)


def futhark_sin16(x):
    return np.sin(x)


def futhark_tan16(x):
    return np.tan(x)


def futhark_acos16(x):
    return np.arccos(x)


def futhark_asin16(x):
    return np.arcsin(x)


def futhark_atan16(x):
    return np.arctan(x)


def futhark_cosh16(x):
    return np.cosh(x)


def futhark_sinh16(x):
    return np.sinh(x)


def futhark_tanh16(x):
    return np.tanh(x)


def futhark_acosh16(x):
    return np.arccosh(x)


def futhark_asinh16(x):
    return np.arcsinh(x)


def futhark_atanh16(x):
    return np.arctanh(x)


def futhark_atan2_16(x, y):
    return np.arctan2(x, y)


def futhark_hypot16(x, y):
    return np.hypot(x, y)


def futhark_gamma16(x):
    return np.float16(math.gamma(x))


def futhark_lgamma16(x):
    return np.float16(math.lgamma(x))


def futhark_erf16(x):
    return np.float16(math.erf(x))


def futhark_erfc16(x):
    return np.float16(math.erfc(x))


def futhark_round16(x):
    return np.round(x)


def futhark_ceil16(x):
    return np.ceil(x)


def futhark_floor16(x):
    return np.floor(x)


def futhark_nextafter16(x, y):
    return np.nextafter(x, y)


def futhark_isnan16(x):
    return np.isnan(x)


def futhark_isinf16(x):
    return np.isinf(x)


def futhark_to_bits16(x):
    s = struct.pack(">e", x)
    return np.int16(struct.unpack(">H", s)[0])


def futhark_from_bits16(x):
    s = struct.pack(">H", np.uint16(x))
    return np.float16(struct.unpack(">e", s)[0])


def futhark_lerp16(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_lerp32(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_lerp64(v0, v1, t):
    return v0 + (v1 - v0) * t


def futhark_ldexp16(x, y):
    return np.ldexp(x, y)


def futhark_ldexp32(x, y):
    return np.ldexp(x, y)


def futhark_ldexp64(x, y):
    return np.ldexp(x, y)


def futhark_mad16(a, b, c):
    return a * b + c


def futhark_mad32(a, b, c):
    return a * b + c


def futhark_mad64(a, b, c):
    return a * b + c


def futhark_fma16(a, b, c):
    return a * b + c


def futhark_fma32(a, b, c):
    return a * b + c


def futhark_fma64(a, b, c):
    return a * b + c


futhark_copysign16 = futhark_copysign32 = futhark_copysign64 = np.copysign

# End of scalar.py.
# Start of server.py

import sys
import time
import shlex  # For string splitting


class Server:
    def __init__(self, ctx):
        self._ctx = ctx
        self._vars = {}

    class Failure(BaseException):
        def __init__(self, msg):
            self.msg = msg

    def _get_arg(self, args, i):
        if i < len(args):
            return args[i]
        else:
            raise self.Failure("Insufficient command args")

    def _get_entry_point(self, entry):
        if entry in self._ctx.entry_points:
            return self._ctx.entry_points[entry]
        else:
            raise self.Failure("Unknown entry point: %s" % entry)

    def _check_var(self, vname):
        if not vname in self._vars:
            raise self.Failure("Unknown variable: %s" % vname)

    def _check_new_var(self, vname):
        if vname in self._vars:
            raise self.Failure("Variable already exists: %s" % vname)

    def _get_var(self, vname):
        self._check_var(vname)
        return self._vars[vname]

    def _cmd_inputs(self, args):
        entry = self._get_arg(args, 0)
        for t in self._get_entry_point(entry)[1]:
            print(t)

    def _cmd_outputs(self, args):
        entry = self._get_arg(args, 0)
        for t in self._get_entry_point(entry)[2]:
            print(t)

    def _cmd_dummy(self, args):
        pass

    def _cmd_free(self, args):
        for vname in args:
            self._check_var(vname)
            del self._vars[vname]

    def _cmd_rename(self, args):
        oldname = self._get_arg(args, 0)
        newname = self._get_arg(args, 1)
        self._check_var(oldname)
        self._check_new_var(newname)
        self._vars[newname] = self._vars[oldname]
        del self._vars[oldname]

    def _cmd_call(self, args):
        entry = self._get_entry_point(self._get_arg(args, 0))
        entry_fname = entry[0]
        num_ins = len(entry[1])
        num_outs = len(entry[2])
        exp_len = 1 + num_outs + num_ins

        if len(args) != exp_len:
            raise self.Failure("Invalid argument count, expected %d" % exp_len)

        out_vnames = args[1 : num_outs + 1]

        for out_vname in out_vnames:
            self._check_new_var(out_vname)

        in_vnames = args[1 + num_outs :]
        ins = [self._get_var(in_vname) for in_vname in in_vnames]

        try:
            (runtime, vals) = getattr(self._ctx, entry_fname)(*ins)
        except Exception as e:
            raise self.Failure(str(e))

        print("runtime: %d" % runtime)

        if num_outs == 1:
            self._vars[out_vnames[0]] = vals
        else:
            for out_vname, val in zip(out_vnames, vals):
                self._vars[out_vname] = val

    def _store_val(self, f, value):
        # In case we are using the PyOpenCL backend, we first
        # need to convert OpenCL arrays to ordinary NumPy
        # arrays.  We do this in a nasty way.
        if isinstance(value, opaque):
            for component in value.data:
                self._store_val(f, component)
        elif (
            isinstance(value, np.number)
            or isinstance(value, bool)
            or isinstance(value, np.bool_)
            or isinstance(value, np.ndarray)
        ):
            # Ordinary NumPy value.
            f.write(construct_binary_value(value))
        else:
            # Assuming PyOpenCL array.
            f.write(construct_binary_value(value.get()))

    def _cmd_store(self, args):
        fname = self._get_arg(args, 0)

        with open(fname, "wb") as f:
            for i in range(1, len(args)):
                self._store_val(f, self._get_var(args[i]))

    def _restore_val(self, reader, typename):
        if typename in self._ctx.opaques:
            vs = []
            for t in self._ctx.opaques[typename]:
                vs += [read_value(t, reader)]
            return opaque(typename, *vs)
        else:
            return read_value(typename, reader)

    def _cmd_restore(self, args):
        if len(args) % 2 == 0:
            raise self.Failure("Invalid argument count")

        fname = args[0]
        args = args[1:]

        with open(fname, "rb") as f:
            reader = ReaderInput(f)
            while args != []:
                vname = args[0]
                typename = args[1]
                args = args[2:]

                if vname in self._vars:
                    raise self.Failure("Variable already exists: %s" % vname)

                try:
                    self._vars[vname] = self._restore_val(reader, typename)
                except ValueError:
                    raise self.Failure(
                        "Failed to restore variable %s.\n"
                        "Possibly malformed data in %s.\n" % (vname, fname)
                    )

            skip_spaces(reader)
            if reader.get_char() != b"":
                raise self.Failure("Expected EOF after reading values")

    def _cmd_types(self, args):
        for k in self._ctx.opaques.keys():
            print(k)

    def _cmd_entry_points(self, args):
        for k in self._ctx.entry_points.keys():
            print(k)

    _commands = {
        "inputs": _cmd_inputs,
        "outputs": _cmd_outputs,
        "call": _cmd_call,
        "restore": _cmd_restore,
        "store": _cmd_store,
        "free": _cmd_free,
        "rename": _cmd_rename,
        "clear": _cmd_dummy,
        "pause_profiling": _cmd_dummy,
        "unpause_profiling": _cmd_dummy,
        "report": _cmd_dummy,
        "types": _cmd_types,
        "entry_points": _cmd_entry_points,
    }

    def _process_line(self, line):
        lex = shlex.shlex(line)
        lex.quotes = '"'
        lex.whitespace_split = True
        lex.commenters = ""
        words = list(lex)
        if words == []:
            raise self.Failure("Empty line")
        else:
            cmd = words[0]
            args = words[1:]
            if cmd in self._commands:
                self._commands[cmd](self, args)
            else:
                raise self.Failure("Unknown command: %s" % cmd)

    def run(self):
        while True:
            print("%%% OK", flush=True)
            line = sys.stdin.readline()
            if line == "":
                return
            try:
                self._process_line(line)
            except self.Failure as e:
                print("%%% FAILURE")
                print(e.msg)


# End of server.py
class entropy:
    entry_points = {
        "byte_histogram": ("byte_histogram", ["[]u8"], ["[]i64"]),
        "chunked_entropy": ("chunked_entropy", ["i64", "[]u8"], ["[]u8"]),
        "entropy": ("entropy", ["[]u8"], ["f32"]),
    }
    opaques = {}

    def __init__(
        self,
        build_options=build_options,
        command_queue=None,
        interactive=False,
        platform_pref=preferred_platform,
        device_pref=preferred_device,
        default_group_size=default_group_size,
        default_num_groups=default_num_groups,
        default_tile_size=default_tile_size,
        default_reg_tile_size=default_reg_tile_size,
        default_threshold=default_threshold,
        sizes=sizes,
    ):
        size_heuristics = [
            ("NVIDIA CUDA", cl.device_type.GPU, "lockstep_width", lambda device: np.int32(32)),
            (
                "AMD Accelerated Parallel Processing",
                cl.device_type.GPU,
                "lockstep_width",
                lambda device: np.int32(32),
            ),
            ("", cl.device_type.GPU, "lockstep_width", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.GPU,
                "num_groups",
                lambda device: (
                    np.int32(4) * device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS"))
                ),
            ),
            ("", cl.device_type.GPU, "group_size", lambda device: np.int32(256)),
            ("", cl.device_type.GPU, "tile_size", lambda device: np.int32(16)),
            ("", cl.device_type.GPU, "reg_tile_size", lambda device: np.int32(4)),
            ("", cl.device_type.GPU, "threshold", lambda device: np.int32(32768)),
            ("", cl.device_type.CPU, "lockstep_width", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.CPU,
                "num_groups",
                lambda device: device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS")),
            ),
            ("", cl.device_type.CPU, "group_size", lambda device: np.int32(32)),
            ("", cl.device_type.CPU, "tile_size", lambda device: np.int32(4)),
            ("", cl.device_type.CPU, "reg_tile_size", lambda device: np.int32(1)),
            (
                "",
                cl.device_type.CPU,
                "threshold",
                lambda device: device.get_info(getattr(cl.device_info, "MAX_COMPUTE_UNITS")),
            ),
        ]
        self.global_failure_args_max = 3
        self.failure_msgs = [
            "Index [{}:{}] out of bounds for array of shape [{}].\n-> #0  entropy.fut:13:44-83\n   #1  /prelude/functional.fut:9:44-45\n   #2  entropy.fut:13:8-87\n   #3  entropy.fut:11:1-13:87\n",
            "Index [{}:{}] out of bounds for array of shape [{}].\n-> #0  entropy.fut:13:44-83\n   #1  /prelude/functional.fut:9:44-45\n   #2  entropy.fut:13:8-87\n   #3  entropy.fut:11:1-13:87\n",
        ]
        constants = [
            (
                "entropyzisegred_nonseg_6334_dim1",
                lambda: self.sizes["entropy.segred_tblock_size_6326"],
            ),
            (
                "entropyzisegred_nonseg_6334zisegred_tblock_sizze_6327",
                lambda: self.sizes["entropy.segred_tblock_size_6326"],
            ),
            ("entropyzisegred_nonseg_6334zichunk_sizze_6982", lambda: np.int64(1)),
            (
                "entropyzisegred_large_6887_dim1",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            (
                "entropyzisegred_large_6887ziseghist_tblock_sizze_6311",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            ("entropyzisegred_large_6887zichunk_sizze_6888", lambda: np.int64(1)),
            (
                "entropyzisegred_small_6887_dim1",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            (
                "entropyzisegred_small_6887ziseghist_tblock_sizze_6311",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            (
                "entropyziseghist_global_6318_dim1",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            (
                "entropyziseghist_global_6318ziseghist_tblock_sizze_6311",
                lambda: self.sizes["entropy.seghist_tblock_size_6310"],
            ),
            ("entropyziseghist_local_6318_dim1", lambda: self.max_thread_block_size),
            (
                "entropyziseghist_local_6318zimax_tblock_sizze_6811",
                lambda: self.max_thread_block_size,
            ),
            (
                "chunked_entropyzisegmap_6674_dim1",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6444"],
            ),
            (
                "chunked_entropyzisegmap_6674zisegmap_tblock_sizze_6670",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6444"],
            ),
            (
                "chunked_entropyzisegred_large_6656_dim1",
                lambda: self.sizes["chunked_entropy.segred_tblock_size_6460"],
            ),
            (
                "chunked_entropyzisegred_large_6656zisegred_tblock_sizze_6650",
                lambda: self.sizes["chunked_entropy.segred_tblock_size_6460"],
            ),
            ("chunked_entropyzisegred_large_6656zichunk_sizze_6819", lambda: np.int64(1)),
            (
                "chunked_entropyzisegred_small_6656_dim1",
                lambda: self.sizes["chunked_entropy.segred_tblock_size_6460"],
            ),
            (
                "chunked_entropyzisegred_small_6656zisegred_tblock_sizze_6650",
                lambda: self.sizes["chunked_entropy.segred_tblock_size_6460"],
            ),
            (
                "chunked_entropyzisegmap_6632_dim1",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6510"],
            ),
            (
                "chunked_entropyzisegmap_6632zisegmap_tblock_sizze_6626",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6510"],
            ),
            (
                "chunked_entropyzisegmap_6593_dim1",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6564"],
            ),
            (
                "chunked_entropyzisegmap_6593zisegmap_tblock_sizze_6587",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6564"],
            ),
            (
                "chunked_entropyzisegmap_6394_dim1",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6340"],
            ),
            (
                "chunked_entropyzisegmap_6394zisegmap_tblock_sizze_6390",
                lambda: self.sizes["chunked_entropy.segmap_tblock_size_6340"],
            ),
            (
                "byte_histogramzisegred_large_6887_dim1",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            (
                "byte_histogramzisegred_large_6887ziseghist_tblock_sizze_6295",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            ("byte_histogramzisegred_large_6887zichunk_sizze_6888", lambda: np.int64(1)),
            (
                "byte_histogramzisegred_small_6887_dim1",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            (
                "byte_histogramzisegred_small_6887ziseghist_tblock_sizze_6295",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            (
                "byte_histogramziseghist_global_6302_dim1",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            (
                "byte_histogramziseghist_global_6302ziseghist_tblock_sizze_6295",
                lambda: self.sizes["byte_histogram.seghist_tblock_size_6294"],
            ),
            ("byte_histogramziseghist_local_6302_dim1", lambda: self.max_thread_block_size),
            (
                "byte_histogramziseghist_local_6302zimax_tblock_sizze_6811",
                lambda: self.max_thread_block_size,
            ),
        ]
        program = initialise_opencl_object(
            self,
            program_src=fut_opencl_src,
            build_options=build_options,
            command_queue=command_queue,
            interactive=interactive,
            platform_pref=platform_pref,
            device_pref=device_pref,
            default_group_size=default_group_size,
            default_num_groups=default_num_groups,
            default_tile_size=default_tile_size,
            default_reg_tile_size=default_reg_tile_size,
            default_threshold=default_threshold,
            size_heuristics=size_heuristics,
            required_types=["i8", "i32", "i64", "f32", "bool", "unit"],
            user_sizes=sizes,
            all_sizes={
                "builtin#replicate_i32.tblock_size_6865": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "builtin#replicate_i64.tblock_size_6789": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "byte_histogram.seghist_num_tblocks_6296": {"class": "grid_size", "value": None},
                "byte_histogram.seghist_tblock_size_6294": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.segmap_num_tblocks_6512": {"class": "grid_size", "value": None},
                "chunked_entropy.segmap_tblock_size_6340": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.segmap_tblock_size_6444": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.segmap_tblock_size_6510": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.segmap_tblock_size_6564": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.segred_num_tblocks_6462": {"class": "grid_size", "value": None},
                "chunked_entropy.segred_tblock_size_6460": {
                    "class": "thread_block_size",
                    "value": None,
                },
                "chunked_entropy.suff_outer_par_0": {"class": "threshold(def, )", "value": None},
                "entropy.seghist_num_tblocks_6312": {"class": "grid_size", "value": None},
                "entropy.seghist_tblock_size_6310": {"class": "thread_block_size", "value": None},
                "entropy.segred_num_tblocks_6328": {"class": "grid_size", "value": None},
                "entropy.segred_tblock_size_6326": {"class": "thread_block_size", "value": None},
            },
            constants=constants,
        )
        self.builtinzhreplicate_i32zireplicate_6861_var = (
            program.builtinzhreplicate_i32zireplicate_6861
        )
        self.builtinzhreplicate_i64zireplicate_6785_var = (
            program.builtinzhreplicate_i64zireplicate_6785
        )
        self.byte_histogramziseghist_global_6302_var = program.byte_histogramziseghist_global_6302
        self.byte_histogramziseghist_local_6302_var = program.byte_histogramziseghist_local_6302
        self.byte_histogramzisegred_large_6887_var = program.byte_histogramzisegred_large_6887
        self.byte_histogramzisegred_small_6887_var = program.byte_histogramzisegred_small_6887
        self.chunked_entropyzisegmap_6394_var = program.chunked_entropyzisegmap_6394
        self.chunked_entropyzisegmap_6593_var = program.chunked_entropyzisegmap_6593
        self.chunked_entropyzisegmap_6632_var = program.chunked_entropyzisegmap_6632
        self.chunked_entropyzisegmap_6674_var = program.chunked_entropyzisegmap_6674
        self.chunked_entropyzisegred_large_6656_var = program.chunked_entropyzisegred_large_6656
        self.chunked_entropyzisegred_small_6656_var = program.chunked_entropyzisegred_small_6656
        self.entropyziseghist_global_6318_var = program.entropyziseghist_global_6318
        self.entropyziseghist_local_6318_var = program.entropyziseghist_local_6318
        self.entropyzisegred_large_6887_var = program.entropyzisegred_large_6887
        self.entropyzisegred_nonseg_6334_var = program.entropyzisegred_nonseg_6334
        self.entropyzisegred_small_6887_var = program.entropyzisegred_small_6887
        self.constants = {}
        self.constants["counters_mem_6924"] = opencl_alloc(
            self, np.int64(81920), 'self.constants["counters_mem_6924"]'
        )
        self.futhark_builtinzhreplicate_i32(
            self.constants["counters_mem_6924"], np.int64(20480), np.int32(0)
        )
        self.constants["counters_mem_6924"] = opencl_alloc(
            self, np.int64(81920), 'self.constants["counters_mem_6924"]'
        )
        self.futhark_builtinzhreplicate_i32(
            self.constants["counters_mem_6924"], np.int64(20480), np.int32(0)
        )
        self.constants["counters_mem_6983"] = opencl_alloc(
            self, np.int64(80), 'self.constants["counters_mem_6983"]'
        )
        self.futhark_builtinzhreplicate_i32(
            self.constants["counters_mem_6983"], np.int64(20), np.int32(0)
        )
        self.constants["counters_mem_6854"] = opencl_alloc(
            self, np.int64(81920), 'self.constants["counters_mem_6854"]'
        )
        self.futhark_builtinzhreplicate_i32(
            self.constants["counters_mem_6854"], np.int64(20480), np.int32(0)
        )

    def futhark_builtinzhreplicate_i32(self, mem_6856, num_elems_6857, val_6858):
        replicate_n_6860 = num_elems_6857
        tblock_sizze_6865 = self.sizes["builtin#replicate_i32.tblock_size_6865"]
        virt_num_tblocks_6866 = sdiv_up64(replicate_n_6860, tblock_sizze_6865)
        num_tblocks_6867 = smin64(virt_num_tblocks_6866, np.int64(1048576))
        if (1 * (np.int64(num_tblocks_6867) * np.int64(tblock_sizze_6865))) != 0:
            self.builtinzhreplicate_i32zireplicate_6861_var.set_args(
                cl.LocalMemory(max(np.int64(0), 1)),
                ct.c_int64(num_elems_6857),
                ct.c_int32(val_6858),
                ct.c_int64(replicate_n_6860),
                ct.c_int64(virt_num_tblocks_6866),
                ct.c_int64(num_tblocks_6867),
                mem_6856,
            )
            cl.enqueue_nd_range_kernel(
                self.queue,
                self.builtinzhreplicate_i32zireplicate_6861_var,
                ((np.int64(num_tblocks_6867) * np.int64(tblock_sizze_6865)),),
                (np.int64(tblock_sizze_6865),),
            )
            if synchronous:
                sync(self)
        return ()

    def futhark_builtinzhreplicate_i64(self, mem_6780, num_elems_6781, val_6782):
        replicate_n_6784 = num_elems_6781
        tblock_sizze_6789 = self.sizes["builtin#replicate_i64.tblock_size_6789"]
        virt_num_tblocks_6790 = sdiv_up64(replicate_n_6784, tblock_sizze_6789)
        num_tblocks_6791 = smin64(virt_num_tblocks_6790, np.int64(1048576))
        if (1 * (np.int64(num_tblocks_6791) * np.int64(tblock_sizze_6789))) != 0:
            self.builtinzhreplicate_i64zireplicate_6785_var.set_args(
                cl.LocalMemory(max(np.int64(0), 1)),
                ct.c_int64(num_elems_6781),
                ct.c_int64(val_6782),
                ct.c_int64(replicate_n_6784),
                ct.c_int64(virt_num_tblocks_6790),
                ct.c_int64(num_tblocks_6791),
                mem_6780,
            )
            cl.enqueue_nd_range_kernel(
                self.queue,
                self.builtinzhreplicate_i64zireplicate_6785_var,
                ((np.int64(num_tblocks_6791) * np.int64(tblock_sizze_6789)),),
                (np.int64(tblock_sizze_6789),),
            )
            if synchronous:
                sync(self)
        return ()

    def futhark_entry_byte_histogram(self, xs_mem_6743, n_5761):
        mem_6744 = opencl_alloc(self, np.int64(2048), "mem_6744")
        self.futhark_builtinzhreplicate_i64(mem_6744, np.int64(256), np.int64(0))
        seghist_tblock_sizze_6295 = self.sizes["byte_histogram.seghist_tblock_size_6294"]
        max_num_tblocks_6800 = self.sizes["byte_histogram.seghist_num_tblocks_6296"]
        num_tblocks_6297 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(sdiv_up64(n_5761, seghist_tblock_sizze_6295), max_num_tblocks_6800),
            )
        )
        h_6804 = np.int64(2048)
        seg_h_6805 = np.int64(2048)
        if seg_h_6805 == np.int64(0):
            pass
        else:
            hist_H_6806 = np.int64(256)
            hist_el_sizze_6807 = sdiv_up64(h_6804, hist_H_6806)
            hist_N_6808 = n_5761
            hist_RF_6809 = np.int32(1)
            hist_L_6810 = self.max_shared_memory
            max_tblock_sizze_6811 = self.max_thread_block_size
            num_tblocks_6812 = sdiv_up64(
                sext_i32_i64(sext_i64_i32(num_tblocks_6297 * seghist_tblock_sizze_6295)),
                max_tblock_sizze_6811,
            )
            hist_m_prime_6813 = sitofp_i64_f64(
                smin64(
                    squot64(hist_L_6810, hist_el_sizze_6807),
                    sdiv_up64(hist_N_6808, num_tblocks_6812),
                )
            ) / sitofp_i64_f64(hist_H_6806)
            hist_M0_6814 = smax64(
                np.int64(1), smin64(fptosi_f64_i64(hist_m_prime_6813), max_tblock_sizze_6811)
            )
            hist_Nout_6815 = np.int64(1)
            hist_Nin_6816 = n_5761
            work_asymp_M_max_6817 = squot64(
                (hist_Nout_6815 * hist_N_6808), ((np.int64(2) * num_tblocks_6812) * hist_H_6806)
            )
            hist_M_6818 = sext_i64_i32(smin64(hist_M0_6814, work_asymp_M_max_6817))
            hist_C_6819 = sdiv_up64(
                max_tblock_sizze_6811, sext_i32_i64(smax32(np.int32(1), hist_M_6818))
            )
            local_mem_needed_6820 = hist_el_sizze_6807 * sext_i32_i64(hist_M_6818)
            hist_S_6821 = sext_i64_i32(
                sdiv_up64(((hist_H_6806 * local_mem_needed_6820) + np.int64(1)), hist_L_6810)
            )
            if sle64(hist_H_6806, hist_Nin_6816) and (
                sle64(local_mem_needed_6820, hist_L_6810)
                and (
                    sle32(hist_S_6821, np.int32(3))
                    and (
                        sle64(hist_C_6819, max_tblock_sizze_6811)
                        and slt32(np.int32(0), hist_M_6818)
                    )
                )
            ):
                num_subhistos_6801 = num_tblocks_6812
                if num_subhistos_6801 == np.int64(1):
                    defunc_0_map_res_subhistos_mem_6802 = mem_6744
                else:
                    defunc_0_map_res_subhistos_mem_6802 = opencl_alloc(
                        self,
                        ((num_subhistos_6801 * np.int64(256)) * np.int64(8)),
                        "defunc_0_map_res_subhistos_mem_6802",
                    )
                    self.futhark_builtinzhreplicate_i64(
                        defunc_0_map_res_subhistos_mem_6802,
                        (num_subhistos_6801 * np.int64(256)),
                        np.int64(0),
                    )
                    lmad_copy_gpu2gpu(
                        self,
                        ct.c_int64,
                        defunc_0_map_res_subhistos_mem_6802,
                        np.int64(0),
                        [np.int64(1)],
                        mem_6744,
                        np.int64(0),
                        [np.int64(1)],
                        [np.int64(256)],
                    )
                chk_i_6822 = np.int32(0)
                one_7017 = np.int32(1)
                for counter_7016 in range(hist_S_6821):
                    num_segments_6823 = np.int64(1)
                    hist_H_chk_6824 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6821))
                    histo_sizze_6825 = hist_H_chk_6824
                    init_per_thread_6826 = sext_i64_i32(
                        sdiv_up64(
                            (sext_i32_i64(hist_M_6818) * histo_sizze_6825), max_tblock_sizze_6811
                        )
                    )
                    if (1 * (np.int64(num_tblocks_6812) * self.max_thread_block_size)) != 0:
                        self.byte_histogramziseghist_local_6302_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        (np.int64(8) * (hist_M_6818 * hist_H_chk_6824))
                                        + srem64(
                                            (
                                                np.int64(8)
                                                - srem64(
                                                    (np.int64(8) * (hist_M_6818 * hist_H_chk_6824)),
                                                    np.int64(8),
                                                )
                                            ),
                                            np.int64(8),
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(n_5761),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(num_tblocks_6812),
                            ct.c_int32(hist_M_6818),
                            ct.c_int32(chk_i_6822),
                            ct.c_int64(num_segments_6823),
                            ct.c_int64(hist_H_chk_6824),
                            ct.c_int64(histo_sizze_6825),
                            ct.c_int32(init_per_thread_6826),
                            xs_mem_6743,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramziseghist_local_6302_var,
                            ((np.int64(num_tblocks_6812) * self.max_thread_block_size),),
                            (self.max_thread_block_size,),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_6822 += one_7017
            else:
                hist_H_6858 = np.int64(256)
                hist_RF_6859 = (np.float64(0.0) + sitofp_i32_f64(np.int64(1))) / np.float64(1.0)
                hist_el_sizze_6860 = np.int32(8)
                hist_C_max_6861 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_tblocks_6297 * seghist_tblock_sizze_6295)),
                    (sitofp_i32_f64(hist_H_6858) / np.float64(2.0)),
                )
                hist_M_min_6862 = smax32(
                    np.int32(1),
                    sext_i64_i32(
                        fptosi_f64_i64(
                            sitofp_i32_f64(
                                sext_i64_i32(num_tblocks_6297 * seghist_tblock_sizze_6295)
                            )
                            / hist_C_max_6861
                        )
                    ),
                )
                L2_sizze_6863 = self.max_cache
                hist_RACE_exp_6864 = fmax64(
                    np.float64(1.0),
                    (
                        (np.float64(0.75) * hist_RF_6859)
                        / (np.float64(64.0) / sitofp_i32_f64(hist_el_sizze_6860))
                    ),
                )
                if slt64(n_5761, hist_H_6858):
                    hist_S_6865 = np.int32(1)
                else:
                    hist_S_6865 = sext_i64_i32(
                        sdiv_up64(
                            (
                                (sext_i32_i64(hist_M_min_6862) * hist_H_6858)
                                * sext_i32_i64(hist_el_sizze_6860)
                            ),
                            fptosi_f64_i64(
                                (np.float64(0.4) * sitofp_i32_f64(L2_sizze_6863))
                                * hist_RACE_exp_6864
                            ),
                        )
                    )
                hist_H_chk_6866 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6865))
                hist_k_max_6867 = fmin64(
                    (
                        (
                            np.float64(0.4)
                            * (sitofp_i32_f64(L2_sizze_6863) / sitofp_i32_f64(np.int32(8)))
                        )
                        * hist_RACE_exp_6864
                    ),
                    sitofp_i32_f64(n_5761),
                ) / sitofp_i32_f64(sext_i64_i32(num_tblocks_6297 * seghist_tblock_sizze_6295))
                hist_u_6868 = np.int64(2)
                hist_C_6869 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_tblocks_6297 * seghist_tblock_sizze_6295)),
                    (sitofp_i32_f64(hist_u_6868 * hist_H_chk_6866) / hist_k_max_6867),
                )
                hist_M_6870 = np.int32(1)
                num_subhistos_6801 = sext_i32_i64(hist_M_6870)
                if hist_M_6870 == np.int32(1):
                    defunc_0_map_res_subhistos_mem_6802 = mem_6744
                else:
                    if num_subhistos_6801 == np.int64(1):
                        defunc_0_map_res_subhistos_mem_6802 = mem_6744
                    else:
                        defunc_0_map_res_subhistos_mem_6802 = opencl_alloc(
                            self,
                            ((num_subhistos_6801 * np.int64(256)) * np.int64(8)),
                            "defunc_0_map_res_subhistos_mem_6802",
                        )
                        self.futhark_builtinzhreplicate_i64(
                            defunc_0_map_res_subhistos_mem_6802,
                            (num_subhistos_6801 * np.int64(256)),
                            np.int64(0),
                        )
                        lmad_copy_gpu2gpu(
                            self,
                            ct.c_int64,
                            defunc_0_map_res_subhistos_mem_6802,
                            np.int64(0),
                            [np.int64(1)],
                            mem_6744,
                            np.int64(0),
                            [np.int64(1)],
                            [np.int64(256)],
                        )
                chk_i_6871 = np.int32(0)
                one_7019 = np.int32(1)
                for counter_7018 in range(hist_S_6865):
                    hist_H_chk_6872 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6865))
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6297)
                            * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                        )
                    ) != 0:
                        self.byte_histogramziseghist_global_6302_var.set_args(
                            cl.LocalMemory(max(np.int64(0), 1)),
                            self.global_failure,
                            ct.c_int64(n_5761),
                            ct.c_int64(num_tblocks_6297),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int32(chk_i_6871),
                            ct.c_int64(hist_H_chk_6872),
                            xs_mem_6743,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramziseghist_global_6302_var,
                            (
                                (
                                    np.int64(num_tblocks_6297)
                                    * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                                ),
                            ),
                            (self.sizes["byte_histogram.seghist_tblock_size_6294"],),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_6871 += one_7019
            if num_subhistos_6801 == np.int64(1):
                mem_6744 = defunc_0_map_res_subhistos_mem_6802
            else:
                chunk_sizze_6888 = np.int64(1)
                if slt64(
                    (num_subhistos_6801 * np.int64(2)),
                    (seghist_tblock_sizze_6295 * chunk_sizze_6888),
                ):
                    segment_sizze_nonzzero_6889 = smax64(np.int64(1), num_subhistos_6801)
                    num_threads_6890 = seghist_tblock_sizze_6295 * seghist_tblock_sizze_6295
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6297)
                            * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                        )
                    ) != 0:
                        self.byte_histogramzisegred_small_6887_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        (np.int64(8) * seghist_tblock_sizze_6295)
                                        + srem64(
                                            (
                                                np.int64(8)
                                                - srem64(
                                                    (np.int64(8) * seghist_tblock_sizze_6295),
                                                    np.int64(8),
                                                )
                                            ),
                                            np.int64(8),
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(num_tblocks_6297),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(segment_sizze_nonzzero_6889),
                            mem_6744,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramzisegred_small_6887_var,
                            (
                                (
                                    np.int64(num_tblocks_6297)
                                    * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                                ),
                            ),
                            (self.sizes["byte_histogram.seghist_tblock_size_6294"],),
                        )
                        if synchronous:
                            sync(self)
                else:
                    blocks_per_segment_6918 = sdiv_up64(
                        num_tblocks_6297, smax64(np.int64(1), np.int64(256))
                    )
                    q_6919 = sdiv_up64(
                        num_subhistos_6801,
                        ((seghist_tblock_sizze_6295 * blocks_per_segment_6918) * chunk_sizze_6888),
                    )
                    num_virtblocks_6920 = blocks_per_segment_6918 * np.int64(256)
                    threads_per_segment_6921 = blocks_per_segment_6918 * seghist_tblock_sizze_6295
                    segred_tmp_mem_6922 = opencl_alloc(
                        self, (np.int64(8) * num_virtblocks_6920), "segred_tmp_mem_6922"
                    )
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6297)
                            * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                        )
                    ) != 0:
                        self.byte_histogramzisegred_large_6887_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        np.int32(8)
                                        + (
                                            (np.int64(8) * seghist_tblock_sizze_6295)
                                            + srem64(
                                                (
                                                    np.int64(8)
                                                    - srem64(
                                                        (np.int64(8) * seghist_tblock_sizze_6295),
                                                        np.int64(8),
                                                    )
                                                ),
                                                np.int64(8),
                                            )
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(num_tblocks_6297),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(blocks_per_segment_6918),
                            ct.c_int64(q_6919),
                            ct.c_int64(num_virtblocks_6920),
                            ct.c_int64(threads_per_segment_6921),
                            mem_6744,
                            defunc_0_map_res_subhistos_mem_6802,
                            segred_tmp_mem_6922,
                            self.constants["counters_mem_6924"],
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.byte_histogramzisegred_large_6887_var,
                            (
                                (
                                    np.int64(num_tblocks_6297)
                                    * self.sizes["byte_histogram.seghist_tblock_size_6294"]
                                ),
                            ),
                            (self.sizes["byte_histogram.seghist_tblock_size_6294"],),
                        )
                        if synchronous:
                            sync(self)
        mem_out_6779 = mem_6744
        return mem_out_6779

    def futhark_entry_chunked_entropy(self, xs_mem_6743, n_6040, chunk_sizze_6041):
        zzero_6185 = chunk_sizze_6041 == np.int64(0)
        nonzzero_6186 = not (zzero_6185)
        nonzzero_cert_6187 = True
        assert (
            nonzzero_6186
        ), "Error: {}\n\nBacktrace:\n-> #0  entropy.fut:12:9-23\n   #1  entropy.fut:11:1-13:87\n".format(
            "division by zero"
        )
        dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188 = sdiv64(n_6040, chunk_sizze_6041)
        bounds_invalid_upwards_6189 = slt64(
            dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, np.int64(0)
        )
        valid_6190 = not (bounds_invalid_upwards_6189)
        range_valid_c_6191 = True
        assert valid_6190, (
            "Error: %s%d%s%d%s\n\nBacktrace:\n-> #0  entropy.fut:12:4-24\n   #1  entropy.fut:11:1-13:87\n"
            % (
                "Range ",
                np.int64(0),
                "..<",
                dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188,
                " is invalid.",
            )
        )
        suff_outer_par_6336 = (
            self.sizes["chunked_entropy.suff_outer_par_0"]
            <= dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
        )
        segmap_tblock_sizze_6587 = self.sizes["chunked_entropy.segmap_tblock_size_6564"]
        segmap_tblock_sizze_6626 = self.sizes["chunked_entropy.segmap_tblock_size_6510"]
        max_num_tblocks_6781 = self.sizes["chunked_entropy.segmap_num_tblocks_6512"]
        num_tblocks_6627 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(
                    sdiv_up64(
                        dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6626
                    ),
                    max_num_tblocks_6781,
                ),
            )
        )
        nest_sizze_6649 = np.int64(256) * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
        segred_tblock_sizze_6650 = self.sizes["chunked_entropy.segred_tblock_size_6460"]
        max_num_tblocks_6782 = self.sizes["chunked_entropy.segred_num_tblocks_6462"]
        num_tblocks_6651 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(sdiv_up64(nest_sizze_6649, segred_tblock_sizze_6650), max_num_tblocks_6782),
            )
        )
        segmap_tblock_sizze_6670 = self.sizes["chunked_entropy.segmap_tblock_size_6444"]
        segmap_tblock_sizze_6390 = self.sizes["chunked_entropy.segmap_tblock_size_6340"]
        binop_y_6754 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188 - np.int64(1)
        binop_x_6756 = smax64(np.int64(0), binop_y_6754)
        binop_y_6758 = np.int64(255) * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
        binop_y_6759 = smax64(np.int64(0), binop_y_6758)
        binop_y_6760 = binop_x_6756 + binop_y_6759
        binop_y_6761 = np.int64(1) + binop_y_6760
        bytes_6762 = np.int64(8) * binop_y_6761
        bytes_6765 = np.int64(4) * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
        shared_memory_capacity_6920 = self.max_shared_memory
        if suff_outer_par_6336 and sle64(np.int64(0), shared_memory_capacity_6920):
            segmap_usable_groups_6391 = sdiv_up64(
                dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6390
            )
            mem_6777 = opencl_alloc(
                self, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, "mem_6777"
            )
            virt_num_tblocks_6783 = sext_i64_i32(
                sdiv_up64(
                    dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6390
                )
            )
            if (
                1
                * (
                    np.int64(segmap_usable_groups_6391)
                    * self.sizes["chunked_entropy.segmap_tblock_size_6340"]
                )
            ) != 0:
                self.chunked_entropyzisegmap_6394_var.set_args(
                    cl.LocalMemory(max(np.int64(0), 1)),
                    self.global_failure,
                    self.failure_is_an_option,
                    self.global_failure_args,
                    ct.c_int64(n_6040),
                    ct.c_int64(chunk_sizze_6041),
                    ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                    xs_mem_6743,
                    mem_6777,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_6394_var,
                    (
                        (
                            np.int64(segmap_usable_groups_6391)
                            * self.sizes["chunked_entropy.segmap_tblock_size_6340"]
                        ),
                    ),
                    (self.sizes["chunked_entropy.segmap_tblock_size_6340"],),
                )
                if synchronous:
                    sync(self)
            self.failure_is_an_option = np.int32(1)
            ext_mem_6778 = mem_6777
        else:
            segmap_usable_groups_6588 = sdiv_up64(
                dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6587
            )
            mem_6745 = opencl_alloc(self, np.int64(0), "mem_6745")
            virt_num_tblocks_6795 = sext_i64_i32(
                sdiv_up64(
                    dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6587
                )
            )
            if (
                1
                * (
                    np.int64(segmap_usable_groups_6588)
                    * self.sizes["chunked_entropy.segmap_tblock_size_6564"]
                )
            ) != 0:
                self.chunked_entropyzisegmap_6593_var.set_args(
                    cl.LocalMemory(max(np.int64(0), 1)),
                    self.global_failure,
                    self.failure_is_an_option,
                    self.global_failure_args,
                    ct.c_int64(n_6040),
                    ct.c_int64(chunk_sizze_6041),
                    ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                    mem_6745,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_6593_var,
                    (
                        (
                            np.int64(segmap_usable_groups_6588)
                            * self.sizes["chunked_entropy.segmap_tblock_size_6564"]
                        ),
                    ),
                    (self.sizes["chunked_entropy.segmap_tblock_size_6564"],),
                )
                if synchronous:
                    sync(self)
            self.failure_is_an_option = np.int32(1)
            mem_6763 = opencl_alloc(self, bytes_6762, "mem_6763")
            virt_num_tblocks_6804 = sext_i64_i32(
                sdiv_up64(
                    dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6626
                )
            )
            if (
                1
                * (
                    np.int64(num_tblocks_6627)
                    * self.sizes["chunked_entropy.segmap_tblock_size_6510"]
                )
            ) != 0:
                self.chunked_entropyzisegmap_6632_var.set_args(
                    cl.LocalMemory(max(np.int64(0), 1)),
                    self.global_failure,
                    ct.c_int64(chunk_sizze_6041),
                    ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                    ct.c_int64(num_tblocks_6627),
                    ct.c_int32(virt_num_tblocks_6804),
                    xs_mem_6743,
                    mem_6745,
                    mem_6763,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_6632_var,
                    (
                        (
                            np.int64(num_tblocks_6627)
                            * self.sizes["chunked_entropy.segmap_tblock_size_6510"]
                        ),
                    ),
                    (self.sizes["chunked_entropy.segmap_tblock_size_6510"],),
                )
                if synchronous:
                    sync(self)
            mem_6745 = None
            mem_6766 = opencl_alloc(self, bytes_6765, "mem_6766")
            chunk_sizze_6819 = np.int64(1)
            if slt64(np.int64(512), (segred_tblock_sizze_6650 * chunk_sizze_6819)):
                segment_sizze_nonzzero_6820 = smax64(np.int64(1), np.int64(256))
                num_threads_6821 = segred_tblock_sizze_6650 * segred_tblock_sizze_6650
                if (
                    1
                    * (
                        np.int64(num_tblocks_6651)
                        * self.sizes["chunked_entropy.segred_tblock_size_6460"]
                    )
                ) != 0:
                    self.chunked_entropyzisegred_small_6656_var.set_args(
                        cl.LocalMemory(
                            max(
                                (
                                    (np.int64(4) * segred_tblock_sizze_6650)
                                    + srem64(
                                        (
                                            np.int64(8)
                                            - srem64(
                                                (np.int64(4) * segred_tblock_sizze_6650),
                                                np.int64(8),
                                            )
                                        ),
                                        np.int64(8),
                                    )
                                ),
                                1,
                            )
                        ),
                        self.global_failure,
                        ct.c_int64(chunk_sizze_6041),
                        ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                        ct.c_int64(num_tblocks_6651),
                        ct.c_int64(segment_sizze_nonzzero_6820),
                        mem_6763,
                        mem_6766,
                    )
                    cl.enqueue_nd_range_kernel(
                        self.queue,
                        self.chunked_entropyzisegred_small_6656_var,
                        (
                            (
                                np.int64(num_tblocks_6651)
                                * self.sizes["chunked_entropy.segred_tblock_size_6460"]
                            ),
                        ),
                        (self.sizes["chunked_entropy.segred_tblock_size_6460"],),
                    )
                    if synchronous:
                        sync(self)
            else:
                blocks_per_segment_6848 = sdiv_up64(
                    num_tblocks_6651,
                    smax64(np.int64(1), dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                )
                q_6849 = sdiv_up64(
                    np.int64(256),
                    ((segred_tblock_sizze_6650 * blocks_per_segment_6848) * chunk_sizze_6819),
                )
                num_virtblocks_6850 = (
                    blocks_per_segment_6848 * dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
                )
                threads_per_segment_6851 = blocks_per_segment_6848 * segred_tblock_sizze_6650
                segred_tmp_mem_6852 = opencl_alloc(
                    self, (np.int64(4) * num_virtblocks_6850), "segred_tmp_mem_6852"
                )
                if (
                    1
                    * (
                        np.int64(num_tblocks_6651)
                        * self.sizes["chunked_entropy.segred_tblock_size_6460"]
                    )
                ) != 0:
                    self.chunked_entropyzisegred_large_6656_var.set_args(
                        cl.LocalMemory(
                            max(
                                (
                                    np.int32(8)
                                    + (
                                        (np.int64(4) * segred_tblock_sizze_6650)
                                        + srem64(
                                            (
                                                np.int64(8)
                                                - srem64(
                                                    (np.int64(4) * segred_tblock_sizze_6650),
                                                    np.int64(8),
                                                )
                                            ),
                                            np.int64(8),
                                        )
                                    )
                                ),
                                1,
                            )
                        ),
                        self.global_failure,
                        ct.c_int64(chunk_sizze_6041),
                        ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                        ct.c_int64(num_tblocks_6651),
                        ct.c_int64(blocks_per_segment_6848),
                        ct.c_int64(q_6849),
                        ct.c_int64(num_virtblocks_6850),
                        ct.c_int64(threads_per_segment_6851),
                        mem_6763,
                        mem_6766,
                        segred_tmp_mem_6852,
                        self.constants["counters_mem_6854"],
                    )
                    cl.enqueue_nd_range_kernel(
                        self.queue,
                        self.chunked_entropyzisegred_large_6656_var,
                        (
                            (
                                np.int64(num_tblocks_6651)
                                * self.sizes["chunked_entropy.segred_tblock_size_6460"]
                            ),
                        ),
                        (self.sizes["chunked_entropy.segred_tblock_size_6460"],),
                    )
                    if synchronous:
                        sync(self)
            mem_6763 = None
            segmap_usable_groups_6671 = sdiv_up64(
                dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6670
            )
            mem_6768 = opencl_alloc(
                self, dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, "mem_6768"
            )
            virt_num_tblocks_6911 = sext_i64_i32(
                sdiv_up64(
                    dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188, segmap_tblock_sizze_6670
                )
            )
            if (
                1
                * (
                    np.int64(segmap_usable_groups_6671)
                    * self.sizes["chunked_entropy.segmap_tblock_size_6444"]
                )
            ) != 0:
                self.chunked_entropyzisegmap_6674_var.set_args(
                    cl.LocalMemory(max(np.int64(0), 1)),
                    self.global_failure,
                    ct.c_int64(chunk_sizze_6041),
                    ct.c_int64(dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188),
                    mem_6766,
                    mem_6768,
                )
                cl.enqueue_nd_range_kernel(
                    self.queue,
                    self.chunked_entropyzisegmap_6674_var,
                    (
                        (
                            np.int64(segmap_usable_groups_6671)
                            * self.sizes["chunked_entropy.segmap_tblock_size_6444"]
                        ),
                    ),
                    (self.sizes["chunked_entropy.segmap_tblock_size_6444"],),
                )
                if synchronous:
                    sync(self)
            mem_6766 = None
            ext_mem_6778 = mem_6768
        mem_out_6779 = ext_mem_6778
        prim_out_6780 = dzlz7bUZLZLzsZRz20Unz20Uchunk_sizzeZRz7dUzg_6188
        return (mem_out_6779, prim_out_6780)

    def futhark_entry_entropy(self, xs_mem_6743, n_5903):
        mem_6744 = opencl_alloc(self, np.int64(2048), "mem_6744")
        self.futhark_builtinzhreplicate_i64(mem_6744, np.int64(256), np.int64(0))
        seghist_tblock_sizze_6311 = self.sizes["entropy.seghist_tblock_size_6310"]
        max_num_tblocks_6800 = self.sizes["entropy.seghist_num_tblocks_6312"]
        num_tblocks_6313 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(sdiv_up64(n_5903, seghist_tblock_sizze_6311), max_num_tblocks_6800),
            )
        )
        h_6804 = np.int64(2048)
        seg_h_6805 = np.int64(2048)
        if seg_h_6805 == np.int64(0):
            pass
        else:
            hist_H_6806 = np.int64(256)
            hist_el_sizze_6807 = sdiv_up64(h_6804, hist_H_6806)
            hist_N_6808 = n_5903
            hist_RF_6809 = np.int32(1)
            hist_L_6810 = self.max_shared_memory
            max_tblock_sizze_6811 = self.max_thread_block_size
            num_tblocks_6812 = sdiv_up64(
                sext_i32_i64(sext_i64_i32(num_tblocks_6313 * seghist_tblock_sizze_6311)),
                max_tblock_sizze_6811,
            )
            hist_m_prime_6813 = sitofp_i64_f64(
                smin64(
                    squot64(hist_L_6810, hist_el_sizze_6807),
                    sdiv_up64(hist_N_6808, num_tblocks_6812),
                )
            ) / sitofp_i64_f64(hist_H_6806)
            hist_M0_6814 = smax64(
                np.int64(1), smin64(fptosi_f64_i64(hist_m_prime_6813), max_tblock_sizze_6811)
            )
            hist_Nout_6815 = np.int64(1)
            hist_Nin_6816 = n_5903
            work_asymp_M_max_6817 = squot64(
                (hist_Nout_6815 * hist_N_6808), ((np.int64(2) * num_tblocks_6812) * hist_H_6806)
            )
            hist_M_6818 = sext_i64_i32(smin64(hist_M0_6814, work_asymp_M_max_6817))
            hist_C_6819 = sdiv_up64(
                max_tblock_sizze_6811, sext_i32_i64(smax32(np.int32(1), hist_M_6818))
            )
            local_mem_needed_6820 = hist_el_sizze_6807 * sext_i32_i64(hist_M_6818)
            hist_S_6821 = sext_i64_i32(
                sdiv_up64(((hist_H_6806 * local_mem_needed_6820) + np.int64(1)), hist_L_6810)
            )
            if sle64(hist_H_6806, hist_Nin_6816) and (
                sle64(local_mem_needed_6820, hist_L_6810)
                and (
                    sle32(hist_S_6821, np.int32(3))
                    and (
                        sle64(hist_C_6819, max_tblock_sizze_6811)
                        and slt32(np.int32(0), hist_M_6818)
                    )
                )
            ):
                num_subhistos_6801 = num_tblocks_6812
                if num_subhistos_6801 == np.int64(1):
                    defunc_0_map_res_subhistos_mem_6802 = mem_6744
                else:
                    defunc_0_map_res_subhistos_mem_6802 = opencl_alloc(
                        self,
                        ((num_subhistos_6801 * np.int64(256)) * np.int64(8)),
                        "defunc_0_map_res_subhistos_mem_6802",
                    )
                    self.futhark_builtinzhreplicate_i64(
                        defunc_0_map_res_subhistos_mem_6802,
                        (num_subhistos_6801 * np.int64(256)),
                        np.int64(0),
                    )
                    lmad_copy_gpu2gpu(
                        self,
                        ct.c_int64,
                        defunc_0_map_res_subhistos_mem_6802,
                        np.int64(0),
                        [np.int64(1)],
                        mem_6744,
                        np.int64(0),
                        [np.int64(1)],
                        [np.int64(256)],
                    )
                chk_i_6822 = np.int32(0)
                one_7021 = np.int32(1)
                for counter_7020 in range(hist_S_6821):
                    num_segments_6823 = np.int64(1)
                    hist_H_chk_6824 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6821))
                    histo_sizze_6825 = hist_H_chk_6824
                    init_per_thread_6826 = sext_i64_i32(
                        sdiv_up64(
                            (sext_i32_i64(hist_M_6818) * histo_sizze_6825), max_tblock_sizze_6811
                        )
                    )
                    if (1 * (np.int64(num_tblocks_6812) * self.max_thread_block_size)) != 0:
                        self.entropyziseghist_local_6318_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        (np.int64(8) * (hist_M_6818 * hist_H_chk_6824))
                                        + srem64(
                                            (
                                                np.int64(8)
                                                - srem64(
                                                    (np.int64(8) * (hist_M_6818 * hist_H_chk_6824)),
                                                    np.int64(8),
                                                )
                                            ),
                                            np.int64(8),
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(n_5903),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(num_tblocks_6812),
                            ct.c_int32(hist_M_6818),
                            ct.c_int32(chk_i_6822),
                            ct.c_int64(num_segments_6823),
                            ct.c_int64(hist_H_chk_6824),
                            ct.c_int64(histo_sizze_6825),
                            ct.c_int32(init_per_thread_6826),
                            xs_mem_6743,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyziseghist_local_6318_var,
                            ((np.int64(num_tblocks_6812) * self.max_thread_block_size),),
                            (self.max_thread_block_size,),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_6822 += one_7021
            else:
                hist_H_6858 = np.int64(256)
                hist_RF_6859 = (np.float64(0.0) + sitofp_i32_f64(np.int64(1))) / np.float64(1.0)
                hist_el_sizze_6860 = np.int32(8)
                hist_C_max_6861 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_tblocks_6313 * seghist_tblock_sizze_6311)),
                    (sitofp_i32_f64(hist_H_6858) / np.float64(2.0)),
                )
                hist_M_min_6862 = smax32(
                    np.int32(1),
                    sext_i64_i32(
                        fptosi_f64_i64(
                            sitofp_i32_f64(
                                sext_i64_i32(num_tblocks_6313 * seghist_tblock_sizze_6311)
                            )
                            / hist_C_max_6861
                        )
                    ),
                )
                L2_sizze_6863 = self.max_cache
                hist_RACE_exp_6864 = fmax64(
                    np.float64(1.0),
                    (
                        (np.float64(0.75) * hist_RF_6859)
                        / (np.float64(64.0) / sitofp_i32_f64(hist_el_sizze_6860))
                    ),
                )
                if slt64(n_5903, hist_H_6858):
                    hist_S_6865 = np.int32(1)
                else:
                    hist_S_6865 = sext_i64_i32(
                        sdiv_up64(
                            (
                                (sext_i32_i64(hist_M_min_6862) * hist_H_6858)
                                * sext_i32_i64(hist_el_sizze_6860)
                            ),
                            fptosi_f64_i64(
                                (np.float64(0.4) * sitofp_i32_f64(L2_sizze_6863))
                                * hist_RACE_exp_6864
                            ),
                        )
                    )
                hist_H_chk_6866 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6865))
                hist_k_max_6867 = fmin64(
                    (
                        (
                            np.float64(0.4)
                            * (sitofp_i32_f64(L2_sizze_6863) / sitofp_i32_f64(np.int32(8)))
                        )
                        * hist_RACE_exp_6864
                    ),
                    sitofp_i32_f64(n_5903),
                ) / sitofp_i32_f64(sext_i64_i32(num_tblocks_6313 * seghist_tblock_sizze_6311))
                hist_u_6868 = np.int64(2)
                hist_C_6869 = fmin64(
                    sitofp_i32_f64(sext_i64_i32(num_tblocks_6313 * seghist_tblock_sizze_6311)),
                    (sitofp_i32_f64(hist_u_6868 * hist_H_chk_6866) / hist_k_max_6867),
                )
                hist_M_6870 = np.int32(1)
                num_subhistos_6801 = sext_i32_i64(hist_M_6870)
                if hist_M_6870 == np.int32(1):
                    defunc_0_map_res_subhistos_mem_6802 = mem_6744
                else:
                    if num_subhistos_6801 == np.int64(1):
                        defunc_0_map_res_subhistos_mem_6802 = mem_6744
                    else:
                        defunc_0_map_res_subhistos_mem_6802 = opencl_alloc(
                            self,
                            ((num_subhistos_6801 * np.int64(256)) * np.int64(8)),
                            "defunc_0_map_res_subhistos_mem_6802",
                        )
                        self.futhark_builtinzhreplicate_i64(
                            defunc_0_map_res_subhistos_mem_6802,
                            (num_subhistos_6801 * np.int64(256)),
                            np.int64(0),
                        )
                        lmad_copy_gpu2gpu(
                            self,
                            ct.c_int64,
                            defunc_0_map_res_subhistos_mem_6802,
                            np.int64(0),
                            [np.int64(1)],
                            mem_6744,
                            np.int64(0),
                            [np.int64(1)],
                            [np.int64(256)],
                        )
                chk_i_6871 = np.int32(0)
                one_7023 = np.int32(1)
                for counter_7022 in range(hist_S_6865):
                    hist_H_chk_6872 = sdiv_up64(np.int64(256), sext_i32_i64(hist_S_6865))
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6313)
                            * self.sizes["entropy.seghist_tblock_size_6310"]
                        )
                    ) != 0:
                        self.entropyziseghist_global_6318_var.set_args(
                            cl.LocalMemory(max(np.int64(0), 1)),
                            self.global_failure,
                            ct.c_int64(n_5903),
                            ct.c_int64(num_tblocks_6313),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int32(chk_i_6871),
                            ct.c_int64(hist_H_chk_6872),
                            xs_mem_6743,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyziseghist_global_6318_var,
                            (
                                (
                                    np.int64(num_tblocks_6313)
                                    * self.sizes["entropy.seghist_tblock_size_6310"]
                                ),
                            ),
                            (self.sizes["entropy.seghist_tblock_size_6310"],),
                        )
                        if synchronous:
                            sync(self)
                    chk_i_6871 += one_7023
            if num_subhistos_6801 == np.int64(1):
                mem_6744 = defunc_0_map_res_subhistos_mem_6802
            else:
                chunk_sizze_6888 = np.int64(1)
                if slt64(
                    (num_subhistos_6801 * np.int64(2)),
                    (seghist_tblock_sizze_6311 * chunk_sizze_6888),
                ):
                    segment_sizze_nonzzero_6889 = smax64(np.int64(1), num_subhistos_6801)
                    num_threads_6890 = seghist_tblock_sizze_6311 * seghist_tblock_sizze_6311
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6313)
                            * self.sizes["entropy.seghist_tblock_size_6310"]
                        )
                    ) != 0:
                        self.entropyzisegred_small_6887_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        (np.int64(8) * seghist_tblock_sizze_6311)
                                        + srem64(
                                            (
                                                np.int64(8)
                                                - srem64(
                                                    (np.int64(8) * seghist_tblock_sizze_6311),
                                                    np.int64(8),
                                                )
                                            ),
                                            np.int64(8),
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(num_tblocks_6313),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(segment_sizze_nonzzero_6889),
                            mem_6744,
                            defunc_0_map_res_subhistos_mem_6802,
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyzisegred_small_6887_var,
                            (
                                (
                                    np.int64(num_tblocks_6313)
                                    * self.sizes["entropy.seghist_tblock_size_6310"]
                                ),
                            ),
                            (self.sizes["entropy.seghist_tblock_size_6310"],),
                        )
                        if synchronous:
                            sync(self)
                else:
                    blocks_per_segment_6918 = sdiv_up64(
                        num_tblocks_6313, smax64(np.int64(1), np.int64(256))
                    )
                    q_6919 = sdiv_up64(
                        num_subhistos_6801,
                        ((seghist_tblock_sizze_6311 * blocks_per_segment_6918) * chunk_sizze_6888),
                    )
                    num_virtblocks_6920 = blocks_per_segment_6918 * np.int64(256)
                    threads_per_segment_6921 = blocks_per_segment_6918 * seghist_tblock_sizze_6311
                    segred_tmp_mem_6922 = opencl_alloc(
                        self, (np.int64(8) * num_virtblocks_6920), "segred_tmp_mem_6922"
                    )
                    if (
                        1
                        * (
                            np.int64(num_tblocks_6313)
                            * self.sizes["entropy.seghist_tblock_size_6310"]
                        )
                    ) != 0:
                        self.entropyzisegred_large_6887_var.set_args(
                            cl.LocalMemory(
                                max(
                                    (
                                        np.int32(8)
                                        + (
                                            (np.int64(8) * seghist_tblock_sizze_6311)
                                            + srem64(
                                                (
                                                    np.int64(8)
                                                    - srem64(
                                                        (np.int64(8) * seghist_tblock_sizze_6311),
                                                        np.int64(8),
                                                    )
                                                ),
                                                np.int64(8),
                                            )
                                        )
                                    ),
                                    1,
                                )
                            ),
                            self.global_failure,
                            ct.c_int64(num_tblocks_6313),
                            ct.c_int64(num_subhistos_6801),
                            ct.c_int64(blocks_per_segment_6918),
                            ct.c_int64(q_6919),
                            ct.c_int64(num_virtblocks_6920),
                            ct.c_int64(threads_per_segment_6921),
                            mem_6744,
                            defunc_0_map_res_subhistos_mem_6802,
                            segred_tmp_mem_6922,
                            self.constants["counters_mem_6924"],
                        )
                        cl.enqueue_nd_range_kernel(
                            self.queue,
                            self.entropyzisegred_large_6887_var,
                            (
                                (
                                    np.int64(num_tblocks_6313)
                                    * self.sizes["entropy.seghist_tblock_size_6310"]
                                ),
                            ),
                            (self.sizes["entropy.seghist_tblock_size_6310"],),
                        )
                        if synchronous:
                            sync(self)
        i64_res_6244 = sitofp_i64_f32(n_5903)
        segred_tblock_sizze_6327 = self.sizes["entropy.segred_tblock_size_6326"]
        max_num_tblocks_6981 = self.sizes["entropy.segred_num_tblocks_6328"]
        num_tblocks_6329 = sext_i64_i32(
            smax64(
                np.int64(1),
                smin64(sdiv_up64(np.int64(256), segred_tblock_sizze_6327), max_num_tblocks_6981),
            )
        )
        mem_6747 = opencl_alloc(self, np.int64(4), "mem_6747")
        chunk_sizze_6982 = np.int64(1)
        segred_tmp_mem_6985 = opencl_alloc(
            self, (np.int64(4) * num_tblocks_6329), "segred_tmp_mem_6985"
        )
        num_threads_6987 = num_tblocks_6329 * segred_tblock_sizze_6327
        if (1 * (np.int64(num_tblocks_6329) * self.sizes["entropy.segred_tblock_size_6326"])) != 0:
            self.entropyzisegred_nonseg_6334_var.set_args(
                cl.LocalMemory(
                    max(
                        (
                            np.int32(8)
                            + (
                                (np.int64(4) * segred_tblock_sizze_6327)
                                + srem64(
                                    (
                                        np.int64(8)
                                        - srem64(
                                            (np.int64(4) * segred_tblock_sizze_6327), np.int64(8)
                                        )
                                    ),
                                    np.int64(8),
                                )
                            )
                        ),
                        1,
                    )
                ),
                self.global_failure,
                ct.c_float(i64_res_6244),
                ct.c_int64(num_tblocks_6329),
                ct.c_int64(num_threads_6987),
                mem_6744,
                mem_6747,
                self.constants["counters_mem_6983"],
                segred_tmp_mem_6985,
            )
            cl.enqueue_nd_range_kernel(
                self.queue,
                self.entropyzisegred_nonseg_6334_var,
                ((np.int64(num_tblocks_6329) * self.sizes["entropy.segred_tblock_size_6326"]),),
                (self.sizes["entropy.segred_tblock_size_6326"],),
            )
            if synchronous:
                sync(self)
        mem_6744 = None
        read_res_7024 = np.empty(1, dtype=ct.c_float)
        cl.enqueue_copy(
            self.queue,
            read_res_7024,
            mem_6747,
            src_offset=(np.int64(np.int64(0)) * 4),
            is_blocking=synchronous,
        )
        sync(self)
        defunc_0_f_res_6287 = read_res_7024[0]
        mem_6747 = None
        zs_lhs_6260 = np.float32(-1.0) * defunc_0_f_res_6287
        log2_res_6262 = futhark_log2_32(i64_res_6244)
        lifted_lambda_res_6263 = zs_lhs_6260 / log2_res_6262
        prim_out_6779 = lifted_lambda_res_6263
        return prim_out_6779

    def byte_histogram(self, xs_mem_6743_ext):
        n_5761 = None
        try:
            assert (type(xs_mem_6743_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_6743_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_5761 == None:
                n_5761 = np.int64(xs_mem_6743_ext.shape[0])
            else:
                assert (
                    n_5761 == xs_mem_6743_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_6743_ext) == cl.array.Array:
                xs_mem_6743 = xs_mem_6743_ext.data
            else:
                xs_mem_6743 = opencl_alloc(self, np.int64(xs_mem_6743_ext.nbytes), "xs_mem_6743")
                if np.int64(xs_mem_6743_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_6743,
                        normaliseArray(xs_mem_6743_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_6743_ext), xs_mem_6743_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            mem_out_6779 = self.futhark_entry_byte_histogram(xs_mem_6743, n_5761)
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return cl.array.Array(self.queue, (np.int64(256),), np.int64, data=mem_out_6779)

    def chunked_entropy(self, chunk_sizze_6041_ext, xs_mem_6743_ext):
        n_6040 = None
        try:
            chunk_sizze_6041 = np.int64(ct.c_int64(chunk_sizze_6041_ext))
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "i64", type(chunk_sizze_6041_ext), chunk_sizze_6041_ext
                )
            )
        try:
            assert (type(xs_mem_6743_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_6743_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_6040 == None:
                n_6040 = np.int64(xs_mem_6743_ext.shape[0])
            else:
                assert (
                    n_6040 == xs_mem_6743_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_6743_ext) == cl.array.Array:
                xs_mem_6743 = xs_mem_6743_ext.data
            else:
                xs_mem_6743 = opencl_alloc(self, np.int64(xs_mem_6743_ext.nbytes), "xs_mem_6743")
                if np.int64(xs_mem_6743_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_6743,
                        normaliseArray(xs_mem_6743_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #1 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_6743_ext), xs_mem_6743_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            (mem_out_6779, prim_out_6780) = self.futhark_entry_chunked_entropy(
                xs_mem_6743, n_6040, chunk_sizze_6041
            )
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return cl.array.Array(self.queue, (prim_out_6780,), np.uint8, data=mem_out_6779)

    def entropy(self, xs_mem_6743_ext):
        n_5903 = None
        try:
            assert (type(xs_mem_6743_ext) in [np.ndarray, cl.array.Array]) and (
                xs_mem_6743_ext.dtype == np.uint8
            ), "Parameter has unexpected type"
            if n_5903 == None:
                n_5903 = np.int64(xs_mem_6743_ext.shape[0])
            else:
                assert (
                    n_5903 == xs_mem_6743_ext.shape[0]
                ), "Error: entry point arguments have invalid sizes."
            if type(xs_mem_6743_ext) == cl.array.Array:
                xs_mem_6743 = xs_mem_6743_ext.data
            else:
                xs_mem_6743 = opencl_alloc(self, np.int64(xs_mem_6743_ext.nbytes), "xs_mem_6743")
                if np.int64(xs_mem_6743_ext.nbytes) != 0:
                    cl.enqueue_copy(
                        self.queue,
                        xs_mem_6743,
                        normaliseArray(xs_mem_6743_ext),
                        is_blocking=synchronous,
                    )
        except (TypeError, AssertionError) as e:
            raise TypeError(
                "Argument #0 has invalid value\nFuthark type: {}\nArgument has Python type {} and value: {}\n".format(
                    "[]u8", type(xs_mem_6743_ext), xs_mem_6743_ext
                )
            )
        time_start = time.time()
        with np.errstate(divide="ignore", over="ignore", under="ignore", invalid="ignore"):
            prim_out_6779 = self.futhark_entry_entropy(xs_mem_6743, n_5903)
        runtime = int(time.time() * 1000000) - int(time_start * 1000000)
        sync(self)
        return np.float32(prim_out_6779)
